#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æ™ºèƒ½çŸ¥è¯†åº“ç³»ç»Ÿ (DeepSeekç‰ˆ)

Copyright (c) 2026 å•æ»¢

Licensed under the MIT License (Non-Commercial) or Apache License 2.0 (Non-Commercial)
See LICENSE-MIT-NC or LICENSE-APACHE-NC for details.

This software is for NON-COMMERCIAL USE ONLY.
For commercial use, please contact the copyright holder.
"""

import streamlit as st
import os
import glob
from typing import List, Dict, Any, Optional
import tempfile
from pathlib import Path
import json
from datetime import datetime
import base64
import hashlib

# API Key ç®¡ç†æ¨¡å—
CONFIG_FILE = os.path.join(".", ".deepseek_config.json")

# Prompt æ¨¡ç‰ˆç®¡ç†æ¨¡å—
PROMPT_TEMPLATES_DIR = os.path.join(".", "prompt_templates")
SUMMARY_TEMPLATES_FILE = os.path.join(PROMPT_TEMPLATES_DIR, "summary_templates.json")
ANALYSIS_TEMPLATES_FILE = os.path.join(PROMPT_TEMPLATES_DIR, "analysis_templates.json")

def ensure_templates_dir():
    """ç¡®ä¿æ¨¡ç‰ˆç›®å½•å­˜åœ¨"""
    os.makedirs(PROMPT_TEMPLATES_DIR, exist_ok=True)

def is_default_template(template_type: str, template_id: str) -> bool:
    """æ£€æŸ¥æ¨¡ç‰ˆæ˜¯å¦æ˜¯é»˜è®¤æ¨¡ç‰ˆï¼ˆä¸å¯åˆ é™¤ï¼‰
    
    Args:
        template_type: 'summary' æˆ– 'analysis'
        template_id: æ¨¡ç‰ˆID
    
    Returns:
        å¦‚æœæ˜¯é»˜è®¤æ¨¡ç‰ˆè¿”å›Trueï¼Œå¦åˆ™è¿”å›False
    """
    if template_type == "summary":
        default_template_ids = ["default", "brief", "detailed", "roadmap", "gantt"]
        return template_id in default_template_ids
    elif template_type == "analysis":
        default_template_ids = ["default", "statistical", "trend"]
        return template_id in default_template_ids
    return False

def get_default_summary_templates() -> Dict[str, Dict[str, Any]]:
    """è·å–é»˜è®¤çš„æ€»ç»“æ¨¡ç‰ˆ"""
    return {
        "default": {
            "name": "é»˜è®¤æ€»ç»“æ¨¡ç‰ˆ",
            "description": "æ ‡å‡†çš„å¤šéƒ¨åˆ†æ€»ç»“æŠ¥å‘Š",
            "template": """è¯·æ ¹æ®ä»¥ä¸‹æ–‡æ¡£å†…å®¹ï¼Œç”Ÿæˆä¸€ä»½è¯¦ç»†çš„æ€»ç»“æŠ¥å‘Šï¼š

æ–‡æ¡£å†…å®¹ï¼š
{content}

è¯·ç”ŸæˆåŒ…æ‹¬ä»¥ä¸‹éƒ¨åˆ†çš„æŠ¥å‘Šï¼š
1. æ•´ä½“å†…å®¹æ¦‚è¿°
2. æ ¸å¿ƒè¦ç‚¹æ€»ç»“
3. å…³é”®æ•°æ®/ä¿¡æ¯æå–
4. ä¸»è¦å‘ç°å’Œæ´å¯Ÿ
5. å»ºè®®å’Œä¸‹ä¸€æ­¥è¡ŒåŠ¨

æŠ¥å‘Šï¼š""",
            "created_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        },
        "brief": {
            "name": "ç®€è¦æ€»ç»“æ¨¡ç‰ˆ",
            "description": "ç®€æ´çš„è¦ç‚¹æ€»ç»“",
            "template": """è¯·æ ¹æ®ä»¥ä¸‹æ–‡æ¡£å†…å®¹ï¼Œç”Ÿæˆä¸€ä»½ç®€è¦æ€»ç»“ï¼š

æ–‡æ¡£å†…å®¹ï¼š
{content}

è¯·æä¾›ï¼š
1. æ ¸å¿ƒè¦ç‚¹ï¼ˆ3-5æ¡ï¼‰
2. å…³é”®ä¿¡æ¯
3. ä¸»è¦ç»“è®º

æ€»ç»“ï¼š""",
            "created_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        },
        "detailed": {
            "name": "è¯¦ç»†åˆ†ææ¨¡ç‰ˆ",
            "description": "æ·±å…¥åˆ†ææ–‡æ¡£å†…å®¹",
            "template": """è¯·å¯¹ä»¥ä¸‹æ–‡æ¡£å†…å®¹è¿›è¡Œæ·±å…¥åˆ†æï¼š

æ–‡æ¡£å†…å®¹ï¼š
{content}

è¯·æä¾›è¯¦ç»†åˆ†æï¼š
1. æ–‡æ¡£èƒŒæ™¯å’Œç›®çš„
2. ä¸»è¦å†…å®¹ç»“æ„
3. å…³é”®æ•°æ®å’Œäº‹å®
4. æ·±åº¦æ´å¯Ÿå’Œåˆ†æ
5. æ½œåœ¨é—®é¢˜å’Œé£é™©
6. æ”¹è¿›å»ºè®®å’Œè¡ŒåŠ¨è®¡åˆ’

åˆ†ææŠ¥å‘Šï¼š""",
            "created_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        },
        "roadmap": {
            "name": "æŠ€æœ¯è·¯çº¿å›¾æ¨¡ç‰ˆ",
            "description": "ç”Ÿæˆç¬¦å·åŒ–æŠ€æœ¯è·¯çº¿å›¾",
            "template": """è¯·æ ¹æ®æ‰€é€‰æ–‡æ¡£å†…å®¹ï¼Œåˆ¶ä½œé¡¹ç›®çš„æŠ€æœ¯è·¯çº¿å›¾ï¼ˆç”¨çº¿æ¡ç¬¦å·æ¥å°è¯•ç»„ä»¶æŠ€æœ¯è·¯çº¿å›¾ï¼‰ã€‚è¦æ±‚ï¼š
Â· ä¸»è¦é˜¶æ®µä½¿ç”¨æ–¹æ‹¬å· [] åŒ…è£¹ï¼Œé€šè¿‡å‘ä¸‹ç®­å¤´ â†“ è¿æ¥
Â· å­ä»»åŠ¡é€šè¿‡å‘å³ç®­å¤´ â†’ è¿æ¥
Â· æ”¯æŒç¼©è¿›è¡¨ç¤ºå±‚çº§å…³ç³»

æ–‡æ¡£å†…å®¹ï¼š
{content}

æŠ€æœ¯è·¯çº¿å›¾ï¼š""",
            "created_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        },
        "gantt": {
            "name": "é¡¹ç›®è¿›åº¦ç”˜ç‰¹å›¾æ¨¡ç‰ˆ",
            "description": "ç”Ÿæˆé¡¹ç›®è¿›åº¦ç”˜ç‰¹å›¾è¡¨æ•°æ®ï¼ˆè¡¨æ ¼æ ¼å¼ï¼‰",
            "template": """è¯·æ ¹æ®ä»¥ä¸‹æ–‡æ¡£å†…å®¹ï¼Œç”Ÿæˆä¸€ä»½è¯¦ç»†çš„é¡¹ç›®è¿›åº¦ç”˜ç‰¹å›¾è¡¨æ•°æ®ã€‚

æ–‡æ¡£å†…å®¹ï¼š
{content}

## è¾“å‡ºæ ¼å¼è¦æ±‚

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹è¡¨æ ¼æ ¼å¼è¾“å‡ºï¼Œä½¿ç”¨åˆ¶è¡¨ç¬¦ï¼ˆTabï¼‰åˆ†éš”å„åˆ—ï¼š

```
ä»»åŠ¡ID	ä»»åŠ¡åç§°	å¼€å§‹æ—¶é—´	ç»“æŸæ—¶é—´	å·¥æœŸ(æœˆ)	å‰ç½®ä»»åŠ¡	è´£ä»»æ–¹/å¤‡æ³¨
```

## åˆ—è¯´æ˜

1. **ä»»åŠ¡ID**ï¼šä»»åŠ¡çš„å”¯ä¸€æ ‡è¯†ç¬¦
   - ä¸»è¦é˜¶æ®µï¼š1, 2, 3, 4...
   - å­ä»»åŠ¡ï¼š1.1, 1.2, 2.1, 2.2...
   - ä¸‰çº§ä»»åŠ¡ï¼š1.1.1, 1.1.2...

2. **ä»»åŠ¡åç§°**ï¼šä»»åŠ¡çš„æè¿°åç§°

3. **å¼€å§‹æ—¶é—´**ï¼šä½¿ç”¨ M+æ•°å­— æ ¼å¼
   - M0ï¼šé¡¹ç›®å¼€å§‹ï¼ˆç¬¬0ä¸ªæœˆï¼‰
   - M1ï¼šç¬¬1ä¸ªæœˆ
   - M1+0.5 æˆ– M1.5ï¼šç¬¬1.5ä¸ªæœˆ
   - ç¤ºä¾‹ï¼šM0, M0+0.5, M1, M1.5, M2

4. **ç»“æŸæ—¶é—´**ï¼šä½¿ç”¨ M+æ•°å­— æ ¼å¼ï¼ˆå¿…é¡»å¤§äºç­‰äºå¼€å§‹æ—¶é—´ï¼‰

5. **å·¥æœŸ(æœˆ)**ï¼šä»»åŠ¡æŒç»­æ—¶é—´ï¼ˆå¯é€‰ï¼Œä¼šè‡ªåŠ¨è®¡ç®—ï¼‰
   - å¯ä»¥æ˜¯å°æ•°ï¼š0.5, 1, 1.5, 2, 2.5, 3

6. **å‰ç½®ä»»åŠ¡**ï¼šä¾èµ–çš„ä»»åŠ¡IDï¼ˆå¯é€‰ï¼‰
   - å¤šä¸ªä»»åŠ¡ç”¨é€—å·æˆ–ç©ºæ ¼åˆ†éš”ï¼š1.1, 1.2 æˆ– 2.1 2.2 2.3
   - å¦‚æœæ— å‰ç½®ä»»åŠ¡ï¼Œç•™ç©º

7. **è´£ä»»æ–¹/å¤‡æ³¨**ï¼šä»»åŠ¡çš„è´£ä»»äººæˆ–å¤‡æ³¨ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰
   - æ ¼å¼ï¼šè´£ä»»æ–¹ï¼ˆå¤‡æ³¨è¯´æ˜ï¼‰
   - ç¤ºä¾‹ï¼šä¹™æ–¹ï¼ˆè¾“å‡ºã€Šéœ€æ±‚åˆ†æè¯´æ˜ä¹¦ã€‹ï¼‰
   - ç¤ºä¾‹ï¼šç”²æ–¹ã€ä¹™æ–¹
   - å¦‚æœæ— å¤‡æ³¨ï¼Œç•™ç©º

## ä»»åŠ¡å±‚çº§è¦æ±‚

- **ä¸»è¦é˜¶æ®µï¼ˆlevel 0ï¼‰**ï¼šä»»åŠ¡IDä¸ºå•ä¸ªæ•°å­—ï¼ˆ1, 2, 3...ï¼‰
- **äºŒçº§ä»»åŠ¡ï¼ˆlevel 1ï¼‰**ï¼šä»»åŠ¡IDä¸º X.Y æ ¼å¼ï¼ˆ1.1, 1.2, 2.1...ï¼‰
- **ä¸‰çº§ä»»åŠ¡ï¼ˆlevel 2ï¼‰**ï¼šä»»åŠ¡IDä¸º X.Y.Z æ ¼å¼ï¼ˆ1.1.1, 1.1.2...ï¼‰

## æ—¶é—´è§„åˆ’è¦æ±‚

1. **æ—¶é—´è¿ç»­æ€§**ï¼šç¡®ä¿ä»»åŠ¡æ—¶é—´é¡ºåºåˆç†ï¼Œå‰ç½®ä»»åŠ¡å®Œæˆåæ‰èƒ½å¼€å§‹åç»­ä»»åŠ¡
2. **æ—¶é—´é‡å **ï¼šå…è®¸å¹¶è¡Œä»»åŠ¡ï¼Œä½†éœ€æ˜ç¡®æ ‡æ³¨å‰ç½®ä¾èµ–å…³ç³»
3. **æ—¶é—´è·¨åº¦**ï¼šæ ¹æ®é¡¹ç›®å®é™…æƒ…å†µè®¾å®š
4. **é‡Œç¨‹ç¢‘**ï¼šä¸»è¦é˜¶æ®µåº”è®¾ç½®æ˜ç¡®çš„å¼€å§‹å’Œç»“æŸæ—¶é—´

## æ³¨æ„äº‹é¡¹

1. **å¿…é¡»åŒ…å«è¡¨å¤´è¡Œ**ï¼šç¬¬ä¸€è¡Œå¿…é¡»æ˜¯åˆ—æ ‡é¢˜
2. **ä½¿ç”¨åˆ¶è¡¨ç¬¦åˆ†éš”**ï¼šåˆ—ä¹‹é—´ä½¿ç”¨Tabé”®åˆ†éš”ï¼Œä¸è¦ä½¿ç”¨ç©ºæ ¼
3. **æ—¶é—´æ ¼å¼ç»Ÿä¸€**ï¼šç»Ÿä¸€ä½¿ç”¨ M+æ•°å­— æ ¼å¼
4. **ä»»åŠ¡IDå”¯ä¸€æ€§**ï¼šç¡®ä¿æ¯ä¸ªä»»åŠ¡IDå”¯ä¸€
5. **ä¾èµ–å…³ç³»æ­£ç¡®**ï¼šå‰ç½®ä»»åŠ¡IDå¿…é¡»å­˜åœ¨äºä»»åŠ¡åˆ—è¡¨ä¸­
6. **å±‚çº§ç»“æ„æ¸…æ™°**ï¼šä¸»è¦é˜¶æ®µã€äºŒçº§ä»»åŠ¡ã€ä¸‰çº§ä»»åŠ¡å±‚æ¬¡åˆ†æ˜
7. **å¤‡æ³¨ä¿¡æ¯å®Œæ•´**ï¼šå°½é‡ä¸ºæ¯ä¸ªä»»åŠ¡æä¾›è´£ä»»æ–¹å’Œå¤‡æ³¨ä¿¡æ¯

è¯·æ ¹æ®æ–‡æ¡£å†…å®¹ä¸­çš„é¡¹ç›®ä¿¡æ¯ï¼Œç”Ÿæˆå®Œæ•´çš„é¡¹ç›®è¿›åº¦ç”˜ç‰¹å›¾è¡¨æ•°æ®ã€‚""",
            "created_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        }
    }

def get_default_analysis_templates() -> Dict[str, Dict[str, Any]]:
    """è·å–é»˜è®¤çš„æ•°æ®åˆ†ææ¨¡ç‰ˆ"""
    return {
        "default": {
            "name": "é»˜è®¤åˆ†ææ¨¡ç‰ˆ",
            "description": "æ ‡å‡†çš„æ•°æ®åˆ†ææŠ¥å‘Š",
            "template": """è¯·åˆ†æä»¥ä¸‹æ–‡æ¡£é›†åˆï¼Œæä¾›æ•°æ®åˆ†æ:

æ–‡æ¡£ä¿¡æ¯ï¼š
{doc_info}

è¯·æä¾›ï¼š
1. æ–‡æ¡£å†…å®¹åˆ†å¸ƒåˆ†æ
2. æ½œåœ¨çš„æ•°æ®æ¨¡å¼å’Œè¶‹åŠ¿
3. å»ºè®®çš„æ•°æ®å¯è§†åŒ–æ–¹å¼

åˆ†æç»“æœï¼š""",
            "created_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        },
        "statistical": {
            "name": "ç»Ÿè®¡åˆ†ææ¨¡ç‰ˆ",
            "description": "ä¾§é‡äºç»Ÿè®¡æ•°æ®åˆ†æ",
            "template": """è¯·å¯¹ä»¥ä¸‹æ–‡æ¡£é›†åˆè¿›è¡Œç»Ÿè®¡åˆ†æ:

æ–‡æ¡£ä¿¡æ¯ï¼š
{doc_info}

è¯·æä¾›ï¼š
1. æ–‡æ¡£æ•°é‡ã€å¤§å°ã€ç±»å‹åˆ†å¸ƒç»Ÿè®¡
2. å†…å®¹å…³é”®è¯é¢‘ç‡åˆ†æ
3. æ–‡æ¡£é—´å…³è”æ€§åˆ†æ
4. æ•°æ®è´¨é‡è¯„ä¼°
5. ç»Ÿè®¡å›¾è¡¨å»ºè®®

ç»Ÿè®¡åˆ†æï¼š""",
            "created_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        },
        "trend": {
            "name": "è¶‹åŠ¿åˆ†ææ¨¡ç‰ˆ",
            "description": "ä¾§é‡äºè¶‹åŠ¿å’Œæ¨¡å¼è¯†åˆ«",
            "template": """è¯·åˆ†æä»¥ä¸‹æ–‡æ¡£é›†åˆä¸­çš„è¶‹åŠ¿å’Œæ¨¡å¼:

æ–‡æ¡£ä¿¡æ¯ï¼š
{doc_info}

è¯·æä¾›ï¼š
1. å†…å®¹è¶‹åŠ¿è¯†åˆ«
2. æ—¶é—´åºåˆ—æ¨¡å¼ï¼ˆå¦‚æœ‰ï¼‰
3. ä¸»é¢˜æ¼”å˜è¶‹åŠ¿
4. å¼‚å¸¸æ¨¡å¼æ£€æµ‹
5. æœªæ¥è¶‹åŠ¿é¢„æµ‹

è¶‹åŠ¿åˆ†æï¼š""",
            "created_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        }
    }

def load_templates(template_type: str) -> Dict[str, Dict[str, Any]]:
    """åŠ è½½æ¨¡ç‰ˆï¼ˆæ€»ç»“æˆ–åˆ†æï¼‰
    
    Args:
        template_type: 'summary' æˆ– 'analysis'
    
    Returns:
        æ¨¡ç‰ˆå­—å…¸
    """
    ensure_templates_dir()
    
    if template_type == "summary":
        file_path = SUMMARY_TEMPLATES_FILE
        default_templates = get_default_summary_templates()
    elif template_type == "analysis":
        file_path = ANALYSIS_TEMPLATES_FILE
        default_templates = get_default_analysis_templates()
    else:
        return {}
    
    try:
        if os.path.exists(file_path):
            with open(file_path, 'r', encoding='utf-8') as f:
                templates = json.load(f)
                # åˆå¹¶é»˜è®¤æ¨¡ç‰ˆï¼ˆå¦‚æœç”¨æˆ·æ¨¡ç‰ˆä¸­æ²¡æœ‰ï¼‰
                for key, default_template in default_templates.items():
                    if key not in templates:
                        templates[key] = default_template
                return templates
        else:
            # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ›å»ºé»˜è®¤æ¨¡ç‰ˆæ–‡ä»¶
            save_templates(template_type, default_templates)
            return default_templates
    except Exception:
        # å¦‚æœåŠ è½½å¤±è´¥ï¼Œè¿”å›é»˜è®¤æ¨¡ç‰ˆ
        return default_templates

def save_templates(template_type: str, templates: Dict[str, Dict[str, Any]]) -> bool:
    """ä¿å­˜æ¨¡ç‰ˆ
    
    Args:
        template_type: 'summary' æˆ– 'analysis'
        templates: æ¨¡ç‰ˆå­—å…¸
    
    Returns:
        æ˜¯å¦ä¿å­˜æˆåŠŸ
    """
    ensure_templates_dir()
    
    if template_type == "summary":
        file_path = SUMMARY_TEMPLATES_FILE
    elif template_type == "analysis":
        file_path = ANALYSIS_TEMPLATES_FILE
    else:
        return False
    
    try:
        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(templates, f, indent=2, ensure_ascii=False)
        return True
    except Exception as e:
        if 'st' in globals():
            st.error(f"ä¿å­˜æ¨¡ç‰ˆå¤±è´¥: {str(e)}")
        return False

def save_template(template_type: str, template_id: str, name: str, description: str, template: str) -> bool:
    """ä¿å­˜å•ä¸ªæ¨¡ç‰ˆ
    
    Args:
        template_type: 'summary' æˆ– 'analysis'
        template_id: æ¨¡ç‰ˆIDï¼ˆå¦‚æœå·²å­˜åœ¨åˆ™æ›´æ–°ï¼Œå¦åˆ™åˆ›å»ºï¼‰
        name: æ¨¡ç‰ˆåç§°
        description: æ¨¡ç‰ˆæè¿°
        template: æ¨¡ç‰ˆå†…å®¹
    
    Returns:
        æ˜¯å¦ä¿å­˜æˆåŠŸ
    """
    templates = load_templates(template_type)
    
    # ç”ŸæˆIDï¼ˆå¦‚æœæœªæä¾›æˆ–å·²å­˜åœ¨ï¼‰
    if not template_id or template_id in templates:
        # ä½¿ç”¨åç§°ç”ŸæˆIDï¼ˆç§»é™¤ç‰¹æ®Šå­—ç¬¦ï¼‰
        template_id = "".join(c if c.isalnum() or c in ('-', '_') else '_' for c in name.lower())
        # ç¡®ä¿å”¯ä¸€æ€§
        counter = 1
        original_id = template_id
        while template_id in templates:
            template_id = f"{original_id}_{counter}"
            counter += 1
    
    templates[template_id] = {
        "name": name,
        "description": description,
        "template": template,
        "created_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "updated_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    }
    
    return save_templates(template_type, templates)

def delete_template(template_type: str, template_id: str) -> bool:
    """åˆ é™¤æ¨¡ç‰ˆï¼ˆé»˜è®¤æ¨¡ç‰ˆä¸å¯åˆ é™¤ï¼‰
    
    Args:
        template_type: 'summary' æˆ– 'analysis'
        template_id: æ¨¡ç‰ˆID
    
    Returns:
        æ˜¯å¦åˆ é™¤æˆåŠŸ
    """
    # æ£€æŸ¥æ˜¯å¦æ˜¯é»˜è®¤æ¨¡ç‰ˆï¼Œé»˜è®¤æ¨¡ç‰ˆä¸å¯åˆ é™¤
    if is_default_template(template_type, template_id):
        return False
    
    templates = load_templates(template_type)
    
    if template_id in templates:
        del templates[template_id]
        return save_templates(template_type, templates)
    
    return False

def get_template(template_type: str, template_id: str) -> Optional[Dict[str, Any]]:
    """è·å–å•ä¸ªæ¨¡ç‰ˆ
    
    Args:
        template_type: 'summary' æˆ– 'analysis'
        template_id: æ¨¡ç‰ˆID
    
    Returns:
        æ¨¡ç‰ˆå­—å…¸ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è¿”å›None
    """
    templates = load_templates(template_type)
    return templates.get(template_id)

def encode_api_key(api_key: str) -> str:
    """ç®€å•çš„ç¼–ç ï¼ˆBase64ï¼‰ï¼Œä¸æ˜¯çœŸæ­£çš„åŠ å¯†ï¼Œä½†å¯ä»¥é¿å…å®Œå…¨æ˜æ–‡"""
    if not api_key:
        return ""
    # ä½¿ç”¨ Base64 ç¼–ç 
    encoded = base64.b64encode(api_key.encode('utf-8')).decode('utf-8')
    return encoded

def decode_api_key(encoded_key: str) -> str:
    """è§£ç  API key"""
    if not encoded_key:
        return ""
    try:
        decoded = base64.b64decode(encoded_key.encode('utf-8')).decode('utf-8')
        return decoded
    except Exception:
        return ""

def save_api_key(api_key: str, show_error: bool = True) -> bool:
    """ä¿å­˜ API key åˆ°æœ¬åœ°é…ç½®æ–‡ä»¶"""
    try:
        config = {
            "api_key": encode_api_key(api_key),
            "saved_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        }
        os.makedirs(os.path.dirname(CONFIG_FILE) if os.path.dirname(CONFIG_FILE) else ".", exist_ok=True)
        with open(CONFIG_FILE, 'w', encoding='utf-8') as f:
            json.dump(config, f, indent=2, ensure_ascii=False)
        return True
    except Exception as e:
        if show_error and 'st' in globals():
            st.error(f"ä¿å­˜ API key å¤±è´¥: {str(e)}")
        return False

def load_api_key() -> Optional[str]:
    """ä»æœ¬åœ°é…ç½®æ–‡ä»¶åŠ è½½ API key"""
    try:
        if os.path.exists(CONFIG_FILE):
            with open(CONFIG_FILE, 'r', encoding='utf-8') as f:
                config = json.load(f)
                api_key = decode_api_key(config.get("api_key", ""))
                if api_key:
                    return api_key
    except Exception as e:
        # é™é»˜å¤±è´¥ï¼Œå¦‚æœæ–‡ä»¶æŸåæˆ–ä¸å­˜åœ¨ï¼Œè¿”å› None
        pass
    return None

def load_embedding_model_config() -> str:
    """ä»æœ¬åœ°é…ç½®æ–‡ä»¶åŠ è½½åµŒå…¥æ¨¡å‹é…ç½®
    
    Returns:
        æ¨¡å‹åç§°ï¼Œé»˜è®¤ä¸º "BAAI/bge-small-zh-v1.5"
    """
    try:
        if os.path.exists(CONFIG_FILE):
            with open(CONFIG_FILE, 'r', encoding='utf-8') as f:
                config = json.load(f)
                model_name = config.get("embedding_model", "BAAI/bge-small-zh-v1.5")
                return model_name
    except Exception:
        pass
    return "BAAI/bge-small-zh-v1.5"

def save_embedding_model_config(model_name: str) -> bool:
    """ä¿å­˜åµŒå…¥æ¨¡å‹é…ç½®åˆ°æœ¬åœ°é…ç½®æ–‡ä»¶
    
    Args:
        model_name: æ¨¡å‹åç§°
    
    Returns:
        æ˜¯å¦ä¿å­˜æˆåŠŸ
    """
    try:
        # è¯»å–ç°æœ‰é…ç½®
        config = {}
        if os.path.exists(CONFIG_FILE):
            try:
                with open(CONFIG_FILE, 'r', encoding='utf-8') as f:
                    config = json.load(f)
            except:
                pass
        
        # æ›´æ–°åµŒå…¥æ¨¡å‹é…ç½®
        config["embedding_model"] = model_name
        config["embedding_model_updated_at"] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
        # ä¿å­˜é…ç½®
        os.makedirs(os.path.dirname(CONFIG_FILE) if os.path.dirname(CONFIG_FILE) else ".", exist_ok=True)
        with open(CONFIG_FILE, 'w', encoding='utf-8') as f:
            json.dump(config, f, indent=2, ensure_ascii=False)
        return True
    except Exception as e:
        if 'st' in globals():
            st.error(f"ä¿å­˜åµŒå…¥æ¨¡å‹é…ç½®å¤±è´¥: {str(e)}")
        return False

def download_model(model_name: str, progress_callback=None) -> bool:
    """ä¸‹è½½HuggingFaceæ¨¡å‹
    
    Args:
        model_name: æ¨¡å‹åç§°ï¼ˆå¦‚ "BAAI/bge-base-zh-v1.5"ï¼‰
        progress_callback: è¿›åº¦å›è°ƒå‡½æ•°ï¼Œæ¥æ”¶ (progress, message) å‚æ•°
    
    Returns:
        æ˜¯å¦ä¸‹è½½æˆåŠŸ
    """
    try:
        try:
            from huggingface_hub import snapshot_download
        except ImportError:
            # å¦‚æœæ²¡æœ‰huggingface_hubï¼Œå°è¯•ä½¿ç”¨transformers
            try:
                from transformers import AutoModel, AutoTokenizer
                if progress_callback:
                    progress_callback(50, f"ğŸ”„ æ­£åœ¨ä¸‹è½½æ¨¡å‹ {model_name}...")
                # ä½¿ç”¨transformersä¸‹è½½ï¼ˆä¼šè‡ªåŠ¨ç¼“å­˜ï¼‰
                AutoModel.from_pretrained(model_name)
                AutoTokenizer.from_pretrained(model_name)
                if progress_callback:
                    progress_callback(100, f"âœ… æ¨¡å‹ {model_name} ä¸‹è½½å®Œæˆï¼")
                return True
            except ImportError:
                if progress_callback:
                    progress_callback(100, f"âŒ è¯·å®‰è£… huggingface_hub æˆ– transformers: pip install huggingface_hub")
                return False
        
        if progress_callback:
            progress_callback(10, f"ğŸ”„ å¼€å§‹ä¸‹è½½æ¨¡å‹ {model_name}...")
        
        # ä½¿ç”¨huggingface_hubä¸‹è½½
        cache_dir = os.path.join(
            os.path.expanduser("~"),
            ".cache",
            "huggingface",
            "hub"
        )
        
        if progress_callback:
            progress_callback(30, f"ğŸ”„ æ­£åœ¨ä¸‹è½½æ¨¡å‹æ–‡ä»¶ï¼ˆè¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼‰...")
        
        snapshot_download(
            repo_id=model_name,
            cache_dir=cache_dir,
            local_files_only=False
        )
        
        if progress_callback:
            progress_callback(100, f"âœ… æ¨¡å‹ {model_name} ä¸‹è½½å®Œæˆï¼")
        
        return True
    except Exception as e:
        if progress_callback:
            progress_callback(100, f"âŒ ä¸‹è½½å¤±è´¥: {str(e)}")
        return False

def delete_api_key(show_error: bool = True) -> bool:
    """åˆ é™¤æœ¬åœ°ä¿å­˜çš„ API key"""
    try:
        if os.path.exists(CONFIG_FILE):
            os.remove(CONFIG_FILE)
            return True
        return False
    except Exception as e:
        if show_error and 'st' in globals():
            st.error(f"åˆ é™¤ API key å¤±è´¥: {str(e)}")
        return False

# æ–‡ä»¶è¯»å–æ¨¡å—
def read_text_file(file_path):
    """è¯»å–txtæ–‡ä»¶"""
    with open(file_path, 'r', encoding='utf-8') as f:
        return f.read()

def read_docx_file(file_path):
    """è¯»å–Wordæ–‡æ¡£ï¼ˆåŒ…æ‹¬æ®µè½å’Œè¡¨æ ¼ï¼‰"""
    try:
        from docx import Document
        doc = Document(file_path)
        text_parts = []
        
        # æå–æ®µè½æ–‡æœ¬
        for para in doc.paragraphs:
            if para.text.strip():  # åªæ·»åŠ éç©ºæ®µè½
                text_parts.append(para.text)
        
        # æå–è¡¨æ ¼å†…å®¹
        for table in doc.tables:
            table_text = []
            for row in table.rows:
                row_text = []
                for cell in row.cells:
                    cell_text = cell.text.strip()
                    if cell_text:
                        row_text.append(cell_text)
                if row_text:
                    table_text.append(' | '.join(row_text))
            if table_text:
                text_parts.append('\nè¡¨æ ¼:\n' + '\n'.join(table_text))
        
        return '\n\n'.join(text_parts) if text_parts else ""
    except ImportError:
        return "è¯·å®‰è£…python-docx: pip install python-docx"
    except Exception as e:
        return f"Wordæ–‡æ¡£è¯»å–å¤±è´¥: {str(e)}"

def read_pdf_file(file_path):
    """è¯»å–PDFæ–‡ä»¶"""
    try:
        from pypdf import PdfReader
        reader = PdfReader(file_path)
        text = ""
        for page in reader.pages:
            text += page.extract_text() + "\n"
        return text
    except Exception as e:
        return f"PDFè¯»å–å¤±è´¥: {str(e)}"

def read_excel_file(file_path):
    """è¯»å–Excelæ–‡ä»¶"""
    try:
        import pandas as pd
        excel_content = {}
        xls = pd.ExcelFile(file_path)
        for sheet_name in xls.sheet_names:
            df = pd.read_excel(file_path, sheet_name=sheet_name)
            excel_content[sheet_name] = df.to_string()
        return excel_content
    except ImportError:
        return {"é”™è¯¯": "è¯·å®‰è£…pandaså’Œopenpyxl"}

def read_markdown_file(file_path):
    """è¯»å–Markdownæ–‡ä»¶"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return f.read()
    except Exception as e:
        return f"Markdownè¯»å–å¤±è´¥: {str(e)}"

def read_javascript_file(file_path):
    """è¯»å–JavaScriptæ–‡ä»¶"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return f.read()
    except Exception as e:
        return f"JavaScriptè¯»å–å¤±è´¥: {str(e)}"

def read_json_file(file_path):
    """è¯»å–JSONæ–‡ä»¶"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = json.load(f)
            # å°†JSONæ ¼å¼åŒ–ä¸ºæ˜“è¯»çš„å­—ç¬¦ä¸²
            return json.dumps(content, ensure_ascii=False, indent=2)
    except json.JSONDecodeError as e:
        return f"JSONè§£æå¤±è´¥: {str(e)}"
    except Exception as e:
        return f"JSONè¯»å–å¤±è´¥: {str(e)}"

def process_folder(folder_path: str) -> Dict[str, Any]:
    """å¤„ç†æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰æ–‡ä»¶"""
    all_docs = {}
    
    # æ”¯æŒçš„æ–‡ä»¶ç±»å‹
    file_patterns = {
        '*.txt': ('txt', read_text_file),
        '*.docx': ('docx', read_docx_file),
        '*.pdf': ('pdf', read_pdf_file),
        '*.xlsx': ('excel', read_excel_file),
        '*.xls': ('excel', read_excel_file),
        '*.md': ('markdown', read_markdown_file),
        '*.js': ('javascript', read_javascript_file),
        '*.json': ('json', read_json_file),
    }
    
    for pattern, (file_type, reader_func) in file_patterns.items():
        for file_path in glob.glob(os.path.join(folder_path, pattern)):
            file_name = os.path.basename(file_path)
            
            # è·³è¿‡ä¸´æ—¶æ–‡ä»¶å’Œéšè—æ–‡ä»¶
            # Excel ä¸´æ—¶æ–‡ä»¶ä»¥ ~$ å¼€å¤´ï¼ŒWord ä¸´æ—¶æ–‡ä»¶ä¹Ÿå¯èƒ½ä»¥ ~$ å¼€å¤´
            if file_name.startswith('~$') or file_name.startswith('.'):
                continue
            
            try:
                content = reader_func(file_path)
                all_docs[file_name] = {
                    'path': file_path,
                    'content': content,
                    'type': file_type,
                    'size': os.path.getsize(file_path)
                }
            except Exception as e:
                all_docs[file_name] = {
                    'path': file_path,
                    'content': f"è¯»å–å¤±è´¥: {str(e)}",
                    'type': 'error',
                    'size': 0
                }
    
    return all_docs

# æœ¬åœ°å‘é‡æ•°æ®åº“æ¨¡å—ï¼ˆä¸éœ€è¦APIå¯†é’¥ï¼‰
def get_model_path(model_name: str = "BAAI/bge-small-zh-v1.5") -> str:
    """è·å–æ¨¡å‹è·¯å¾„ï¼Œä¼˜å…ˆä½¿ç”¨æœ¬åœ°è·¯å¾„
    
    Args:
        model_name: HuggingFace æ¨¡å‹åç§°æˆ–æœ¬åœ°è·¯å¾„
    
    Returns:
        æ¨¡å‹è·¯å¾„ï¼ˆæœ¬åœ°è·¯å¾„å¦‚æœå­˜åœ¨ï¼Œå¦åˆ™è¿”å›æ¨¡å‹åç§°ï¼‰
    """
    import os
    
    try:
        # å¦‚æœå·²ç»æ˜¯æœ¬åœ°è·¯å¾„ä¸”å­˜åœ¨ï¼Œç›´æ¥è¿”å›
        if os.path.exists(model_name) and os.path.isdir(model_name):
            return model_name
        
        # æ£€æŸ¥ HuggingFace ç¼“å­˜ç›®å½•
        cache_dir = os.path.join(
            os.path.expanduser("~"),
            ".cache",
            "huggingface",
            "hub"
        )
        
        # å°†æ¨¡å‹åç§°è½¬æ¢ä¸ºç¼“å­˜ç›®å½•æ ¼å¼ï¼ˆBAAI/bge-small-zh-v1.5 -> models--BAAI--bge-small-zh-v1.5ï¼‰
        cache_model_name = f"models--{model_name.replace('/', '--')}"
        cache_path = os.path.join(cache_dir, cache_model_name)
        
        # æŸ¥æ‰¾ snapshots ç›®å½•ä¸‹çš„æœ€æ–°ç‰ˆæœ¬
        if os.path.exists(cache_path):
            snapshots_dir = os.path.join(cache_path, "snapshots")
            if os.path.exists(snapshots_dir):
                try:
                    # å…ˆå°è¯•å¿«é€Ÿæ£€æŸ¥ç›®å½•æ˜¯å¦å¯è®¿é—®ï¼Œé¿å…å¡ä½
                    if not os.access(snapshots_dir, os.R_OK):
                        raise PermissionError("No read permission")
                    
                    # ä½¿ç”¨ Path å¯¹è±¡ï¼Œé€šå¸¸æ¯” os.listdir æ›´å®‰å…¨ï¼Œé¿å…åœ¨å¤§å‹ç›®å½•ä¸Šå¡ä½
                    from pathlib import Path
                    snapshots_path = Path(snapshots_dir)
                    # ä½¿ç”¨ try-except åŒ…è£¹ iterdir()ï¼Œé¿å…åœ¨æŸäº›æ–‡ä»¶ç³»ç»Ÿä¸Šå¡ä½
                    try:
                        snapshots = [d.name for d in snapshots_path.iterdir() 
                                   if d.is_dir()]
                    except (OSError, PermissionError):
                        # å¦‚æœ iterdir() å¤±è´¥ï¼Œå›é€€åˆ° os.listdirï¼Œä½†é™åˆ¶æ•°é‡
                        try:
                            all_items = os.listdir(snapshots_dir)
                            snapshots = [d for d in all_items 
                                       if os.path.isdir(os.path.join(snapshots_dir, d))]
                        except (OSError, PermissionError):
                            snapshots = []
                    
                    if snapshots:
                        # ä½¿ç”¨æœ€æ–°çš„å¿«ç…§
                        latest_snapshot = sorted(snapshots)[-1]
                        local_path = os.path.join(snapshots_dir, latest_snapshot)
                        if os.path.exists(local_path):
                            return local_path
                except (OSError, PermissionError, Exception):
                    pass  # å¿½ç•¥æ‰€æœ‰é”™è¯¯ï¼Œç»§ç»­æ£€æŸ¥å…¶ä»–è·¯å¾„
        
        # æ£€æŸ¥é¡¹ç›®ç›®å½•ä¸‹çš„ models æ–‡ä»¶å¤¹
        project_model_path = os.path.join(".", "models", model_name.replace("/", "--"))
        if os.path.exists(project_model_path):
            return project_model_path
    except Exception:
        pass  # å¦‚æœå‡ºç°ä»»ä½•é”™è¯¯ï¼Œè¿”å›åŸå§‹æ¨¡å‹åç§°
    
    # å¦‚æœéƒ½ä¸å­˜åœ¨ï¼Œè¿”å›åŸå§‹æ¨¡å‹åç§°ï¼ˆä¼šè§¦å‘ä¸‹è½½ï¼‰
    return model_name

def check_db_corrupted(db_path: str) -> bool:
    """æ£€æµ‹å‘é‡æ•°æ®åº“æ˜¯å¦æŸåï¼ˆç‰¹åˆ«æ˜¯ schema å…¼å®¹æ€§é—®é¢˜ï¼‰
    
    Args:
        db_path: å‘é‡æ•°æ®åº“è·¯å¾„
    
    Returns:
        True å¦‚æœæ•°æ®åº“æŸåï¼ŒFalse å¦‚æœæ­£å¸¸æˆ–ä¸å­˜åœ¨
    """
    if not os.path.exists(db_path):
        return False
    
    try:
        # å°è¯•åŠ è½½æ•°æ®åº“æ¥æ£€æµ‹æ˜¯å¦æŸå
        try:
            from langchain_huggingface import HuggingFaceEmbeddings
        except ImportError:
            from langchain_community.embeddings import HuggingFaceEmbeddings
        
        try:
            from langchain_chroma import Chroma
        except ImportError:
            from langchain_community.vectorstores import Chroma
        
        # åˆå§‹åŒ–åµŒå…¥æ¨¡å‹
        embedding_model = load_embedding_model_config()
        model_path = get_model_path(embedding_model)
        embeddings = HuggingFaceEmbeddings(
            model_name=model_path,
            model_kwargs={'device': 'cpu'},
            encode_kwargs={'normalize_embeddings': True}
        )
        
        # å°è¯•åŠ è½½å‘é‡æ•°æ®åº“
        vectorstore = Chroma(
            persist_directory=db_path,
            embedding_function=embeddings
        )
        
        # å°è¯•è®¿é—®æ•°æ®åº“ï¼ˆå¦‚æœ schema é”™è¯¯ä¼šåœ¨è¿™é‡Œå¤±è´¥ï¼‰
        _ = len(vectorstore)
        return False  # æ•°æ®åº“æ­£å¸¸
    except Exception as e:
        error_msg = str(e).lower()
        # åªæ£€æµ‹çœŸæ­£è¡¨ç¤ºæ•°æ®åº“æŸåçš„å…³é”®é”™è¯¯ä¿¡æ¯
        # é¿å…è¿‡äºå®½æ³›çš„åŒ¹é…ï¼Œé˜²æ­¢è¯¯åˆ¤æ­£å¸¸é”™è¯¯
        is_corrupted = (
            # Schema ç›¸å…³é”™è¯¯ï¼ˆç‰ˆæœ¬å…¼å®¹æ€§é—®é¢˜ï¼‰
            "no such column" in error_msg or
            "collections.topic" in error_msg or
            ("schema" in error_msg and ("mismatch" in error_msg or "invalid" in error_msg or "version" in error_msg)) or
            # HNSW ç´¢å¼•æŸåï¼ˆæ˜ç¡®çš„é”™è¯¯ä¿¡æ¯ï¼‰
            ("hnsw" in error_msg and ("corrupt" in error_msg or "invalid" in error_msg or "damaged" in error_msg)) or
            # ç´¢å¼•æ–‡ä»¶æŸåï¼ˆæ˜ç¡®çš„é”™è¯¯ä¿¡æ¯ï¼‰
            ("index" in error_msg and ("corrupt" in error_msg or "invalid" in error_msg or "damaged" in error_msg or "missing" in error_msg)) or
            # SQLite æ•°æ®åº“æ–‡ä»¶æŸåï¼ˆæ˜ç¡®çš„é”™è¯¯ä¿¡æ¯ï¼‰
            ("sqlite" in error_msg and ("corrupt" in error_msg or "database disk image is malformed" in error_msg or "file is encrypted" in error_msg)) or
            # æ®µæ–‡ä»¶æŸå
            ("segment" in error_msg and ("corrupt" in error_msg or "invalid" in error_msg or "damaged" in error_msg))
        )
        if is_corrupted:
            print(f"âš ï¸ æ£€æµ‹åˆ°æ•°æ®åº“æŸå: {str(e)}")
        else:
            # è®°å½•éæŸåæ€§é”™è¯¯ï¼ˆç”¨äºè°ƒè¯•ï¼‰
            print(f"â„¹ï¸ æ•°æ®åº“åŠ è½½æ—¶å‡ºç°éæŸåæ€§é”™è¯¯ï¼ˆå°†å¿½ç•¥ï¼‰: {str(e)}")
        return is_corrupted

def cleanup_corrupted_db(db_path: str, force: bool = True):
    """å½»åº•æ¸…ç†æŸåçš„å‘é‡æ•°æ®åº“ç›®å½•
    
    Args:
        db_path: å‘é‡æ•°æ®åº“è·¯å¾„
        force: æ˜¯å¦å¼ºåˆ¶æ¸…ç†ï¼ˆåŒ…æ‹¬å¤šæ¬¡å°è¯•å’Œå»¶è¿Ÿï¼‰
    
    Returns:
        bool: æ˜¯å¦æˆåŠŸæ¸…ç†
    """
    import shutil
    import time
    
    if not os.path.exists(db_path):
        return True
    
    if force:
        # å¼ºåˆ¶æ¸…ç†æ¨¡å¼ï¼šå¤šæ¬¡å°è¯•ï¼Œç¡®ä¿å½»åº•åˆ é™¤ï¼ˆWindowsä¸Šéœ€è¦æ›´é•¿æ—¶é—´ï¼‰
        import platform
        is_windows = platform.system() == 'Windows'
        max_attempts = 8 if is_windows else 5  # Windowsä¸Šå¢åŠ é‡è¯•æ¬¡æ•°
        wait_time = 2.0 if is_windows else 0.5  # Windowsä¸Šå¢åŠ ç­‰å¾…æ—¶é—´
        
        for attempt in range(max_attempts):
            try:
                # å…ˆå°è¯•æ­£å¸¸åˆ é™¤
                if os.path.exists(db_path):
                    shutil.rmtree(db_path, ignore_errors=False)
                
                # ç­‰å¾…ä¸€ä¸‹ï¼Œç¡®ä¿æ–‡ä»¶ç³»ç»Ÿæ›´æ–°ï¼ˆWindowséœ€è¦æ›´é•¿æ—¶é—´ï¼‰
                time.sleep(wait_time)
                
                # éªŒè¯æ˜¯å¦åˆ é™¤æˆåŠŸ
                if not os.path.exists(db_path):
                    print(f"[OK] å·²å½»åº•æ¸…ç†æŸåçš„å‘é‡æ•°æ®åº“ç›®å½•: {db_path}")
                    return True
                    
            except PermissionError as pe:
                # Windows ä¸Šå¯èƒ½æœ‰æ–‡ä»¶è¢«é”å®šï¼Œç­‰å¾…åé‡è¯•
                if attempt < max_attempts - 1:
                    wait_interval = wait_time * (attempt + 1)  # é€’å¢ç­‰å¾…æ—¶é—´
                    print(f"[WARN] æ–‡ä»¶è¢«é”å®šï¼Œç­‰å¾… {wait_interval:.1f} ç§’åé‡è¯• ({attempt + 1}/{max_attempts})...")
                    time.sleep(wait_interval)
                    continue
                else:
                    print(f"[ERROR] æ¸…ç†å¤±è´¥ï¼ˆæ–‡ä»¶è¢«é”å®šï¼‰: {str(pe)}")
                    print(f"   è¯·æ‰‹åŠ¨åˆ é™¤ç›®å½•: {db_path}")
                    return False
            except Exception as e:
                if attempt < max_attempts - 1:
                    wait_interval = wait_time * (attempt + 1)
                    print(f"[WARN] æ¸…ç†å¤±è´¥ï¼Œç­‰å¾… {wait_interval:.1f} ç§’åé‡è¯• ({attempt + 1}/{max_attempts}): {str(e)}")
                    time.sleep(wait_interval)
                    continue
                else:
                    print(f"[ERROR] æ¸…ç†å¤±è´¥: {str(e)}")
                    print(f"   è¯·æ‰‹åŠ¨åˆ é™¤ç›®å½•: {db_path}")
                    return False
        
        # å¦‚æœå¤šæ¬¡å°è¯•åä»ç„¶å­˜åœ¨ï¼Œå°è¯•ä½¿ç”¨ ignore_errorsï¼ˆå¿½ç•¥é”™è¯¯å¼ºåˆ¶åˆ é™¤ï¼‰
        if os.path.exists(db_path):
            try:
                print(f"[INFO] å°è¯•å¼ºåˆ¶åˆ é™¤æ¨¡å¼ï¼ˆå¿½ç•¥é”™è¯¯ï¼‰...")
                shutil.rmtree(db_path, ignore_errors=True)
                time.sleep(wait_time * 2)  # ç­‰å¾…æ›´é•¿æ—¶é—´
                if not os.path.exists(db_path):
                    print(f"[OK] å·²å¼ºåˆ¶æ¸…ç†æ•°æ®åº“ç›®å½•: {db_path}")
                    return True
            except Exception as e:
                print(f"[WARN] å¼ºåˆ¶åˆ é™¤æ¨¡å¼ä¹Ÿå¤±è´¥: {str(e)}")
        
        # æœ€åå°è¯•ï¼šé‡å‘½åç›®å½•ï¼ˆå¦‚æœæ— æ³•åˆ é™¤ï¼Œè‡³å°‘ä¸å½±å“åç»­æ“ä½œï¼‰
        if os.path.exists(db_path):
            try:
                temp_name = db_path + "_deleted_" + str(int(time.time()))
                os.rename(db_path, temp_name)
                print(f"[WARN] æ— æ³•åˆ é™¤ç›®å½•ï¼Œå·²é‡å‘½åä¸º: {temp_name}")
                print(f"   å¯ä»¥åœ¨ç¨‹åºå…³é—­åæ‰‹åŠ¨åˆ é™¤è¯¥å¤‡ä»½ç›®å½•")
                return True  # é‡å‘½åæˆåŠŸä¹Ÿç®—æˆåŠŸï¼ˆä¸å½±å“åç»­æ“ä½œï¼‰
            except Exception as e:
                print(f"âŒ æ— æ³•æ¸…ç†æˆ–é‡å‘½åç›®å½•: {str(e)}")
                print(f"   ç›®å½•å¯èƒ½è¢«å…¶ä»–è¿›ç¨‹å ç”¨ï¼Œè¯·æ‰‹åŠ¨åˆ é™¤: {db_path}")
                return False
        
        return False
    else:
        # ç®€å•æ¸…ç†æ¨¡å¼
        try:
            if os.path.exists(db_path):
                shutil.rmtree(db_path)
                print(f"[OK] å·²æ¸…ç†æ•°æ®åº“ç›®å½•: {db_path}")
                return True
        except Exception as e:
            print(f"âš ï¸ æ¸…ç†å¤±è´¥: {str(e)}")
            return False
    
    return False

def get_vector_db_path(folder_path: str) -> str:
    """æ ¹æ®æ–‡ä»¶å¤¹è·¯å¾„ç”Ÿæˆå”¯ä¸€çš„å‘é‡æ•°æ®åº“ç›®å½•è·¯å¾„
    
    Args:
        folder_path: æ–‡ä»¶å¤¹è·¯å¾„
    
    Returns:
        å‘é‡æ•°æ®åº“ç›®å½•è·¯å¾„
    """
    if not folder_path:
        # ä¸Šä¼ æ–‡ä»¶æ—¶æ²¡æœ‰æ–‡ä»¶å¤¹è·¯å¾„ï¼Œä½¿ç”¨é»˜è®¤è·¯å¾„
        return "./chroma_db"
    
    # ä½¿ç”¨è·¯å¾„çš„å“ˆå¸Œå€¼åˆ›å»ºå”¯ä¸€ç›®å½•å
    # è§„èŒƒåŒ–è·¯å¾„ï¼šä¸ normalize_path ä¿æŒä¸€è‡´ï¼Œç¡®ä¿è·¯å¾„è§„èŒƒåŒ–é€»è¾‘ç»Ÿä¸€
    try:
        # å…ˆè§„èŒƒåŒ–è·¯å¾„æ ¼å¼ï¼ˆç»Ÿä¸€æ–œæ ï¼‰
        normalized = os.path.normpath(folder_path)
        # è½¬æ¢ä¸ºç»å¯¹è·¯å¾„ï¼ˆå¦‚æœè·¯å¾„å­˜åœ¨ï¼‰
        if os.path.exists(normalized):
            normalized = os.path.abspath(normalized)
        else:
            # å¦‚æœè·¯å¾„ä¸å­˜åœ¨ï¼Œä»ç„¶è§„èŒƒåŒ–æ ¼å¼
            normalized = os.path.normpath(normalized)
        # ç»Ÿä¸€ä½¿ç”¨æ­£æ–œæ ï¼Œå¹¶è½¬æ¢ä¸ºå°å†™ï¼ˆWindowsè·¯å¾„å¤§å°å†™ä¸æ•æ„Ÿï¼‰
        normalized_path = normalized.replace('\\', '/')
        if os.name == 'nt':  # Windowsç³»ç»Ÿ
            normalized_path = normalized_path.lower()
    except Exception as e:
        # å¦‚æœè§„èŒƒåŒ–å¤±è´¥ï¼Œä½¿ç”¨åŸºæœ¬è§„èŒƒåŒ–
        print(f"âš ï¸ è·¯å¾„è§„èŒƒåŒ–å¤±è´¥: {folder_path}, é”™è¯¯: {str(e)}")
        normalized_path = os.path.normpath(folder_path).replace('\\', '/')
        if os.name == 'nt':
            normalized_path = normalized_path.lower()
    
    # ä½¿ç”¨è§„èŒƒåŒ–åçš„è·¯å¾„è®¡ç®—å“ˆå¸Œå€¼
    path_hash = hashlib.md5(normalized_path.encode('utf-8')).hexdigest()[:12]
    
    # åˆ›å»ºå®‰å…¨çš„ç›®å½•åï¼ˆç§»é™¤ç‰¹æ®Šå­—ç¬¦ï¼‰
    safe_folder_name = os.path.basename(normalized_path)
    safe_folder_name = "".join(c for c in safe_folder_name if c.isalnum() or c in (' ', '-', '_'))[:30]
    safe_folder_name = safe_folder_name.strip() or "unknown"
    
    # ç»„åˆç›®å½•åï¼šæ–‡ä»¶å¤¹å_å“ˆå¸Œå€¼
    db_dir_name = f"{safe_folder_name}_{path_hash}"
    return os.path.join("./chroma_db", db_dir_name)

def load_existing_vector_store(folder_path: str = None, progress_callback=None):
    """åŠ è½½å·²æœ‰çš„å‘é‡æ•°æ®åº“
    
    Args:
        folder_path: æ–‡ä»¶å¤¹è·¯å¾„ï¼ˆç”¨äºç¡®å®šå‘é‡æ•°æ®åº“ä½ç½®ï¼‰
        progress_callback: è¿›åº¦å›è°ƒå‡½æ•°ï¼Œæ¥æ”¶ (progress, message) å‚æ•°
    
    Returns:
        å‘é‡æ•°æ®åº“å¯¹è±¡ï¼Œå¦‚æœä¸å­˜åœ¨æˆ–åŠ è½½å¤±è´¥åˆ™è¿”å› None
    """
    try:
        # ä¼˜å…ˆä½¿ç”¨æ–°ç‰ˆæœ¬çš„åŒ…
        try:
            from langchain_huggingface import HuggingFaceEmbeddings
        except ImportError:
            from langchain_community.embeddings import HuggingFaceEmbeddings
        
        try:
            from langchain_chroma import Chroma
        except ImportError:
            from langchain_community.vectorstores import Chroma
        
        db_path = get_vector_db_path(folder_path) if folder_path else "./chroma_db"
        
        if not os.path.exists(db_path):
            return None
        
        if progress_callback:
            progress_callback(10, "ğŸ”„ æ­£åœ¨åŠ è½½å·²æœ‰å‘é‡æ•°æ®åº“...")
        
        # åˆå§‹åŒ–åµŒå…¥æ¨¡å‹ï¼ˆå¿…é¡»ä¸åˆ›å»ºæ—¶ä½¿ç”¨ç›¸åŒçš„æ¨¡å‹ï¼‰
        # ä¼˜å…ˆä½¿ç”¨æœ¬åœ°æ¨¡å‹è·¯å¾„ï¼Œé¿å…ç½‘ç»œä¸‹è½½
        embedding_model = load_embedding_model_config()
        model_path = get_model_path(embedding_model)
        embeddings = HuggingFaceEmbeddings(
            model_name=model_path,
            model_kwargs={'device': 'cpu'},
            encode_kwargs={'normalize_embeddings': True}
        )
        
        if progress_callback:
            progress_callback(50, "ğŸ”„ æ­£åœ¨åŠ è½½å‘é‡æ•°æ®åº“...")
        
        # ä»æŒä¹…åŒ–ç›®å½•åŠ è½½
        vectorstore = Chroma(
            persist_directory=db_path,
            embedding_function=embeddings
        )
        
        # éªŒè¯å‘é‡æ•°æ®åº“æ˜¯å¦å¯ç”¨ï¼ˆä½¿ç”¨æ›´æ¸©å’Œçš„éªŒè¯æ–¹æ³•ï¼‰
        # åªå¯¹çœŸæ­£çš„schemaé”™è¯¯æˆ–ç»´åº¦ä¸åŒ¹é…é”™è¯¯è¿›è¡Œæ¸…ç†ï¼Œå…¶ä»–é”™è¯¯åªè®°å½•ä½†ä¸æ¸…ç†
        try:
            # å°è¯•è·å–æ•°æ®åº“ä¸­çš„æ–‡æ¡£æ•°é‡
            doc_count = len(vectorstore)
            
            # å¦‚æœæ–‡æ¡£æ•°é‡ä¸º0ï¼Œå¯èƒ½æ˜¯ç©ºæ•°æ®åº“ï¼Œä½†ä¸ç®—æŸå
            if doc_count == 0:
                if progress_callback:
                    progress_callback(100, "âš ï¸ å‘é‡æ•°æ®åº“ä¸ºç©ºï¼Œå°†é‡æ–°åˆ›å»º...")
                return None
            
            # å°è¯•è¿›è¡Œä¸€æ¬¡ç®€å•çš„æŸ¥è¯¢æ¥éªŒè¯æ•°æ®åº“æ˜¯å¦çœŸçš„å¯ç”¨
            # ä½¿ç”¨ä¸€ä¸ªç®€å•çš„æµ‹è¯•æŸ¥è¯¢ï¼Œå¦‚æœå¤±è´¥è¯´æ˜æ•°æ®åº“æœ‰é—®é¢˜
            try:
                # å°è¯•è·å–ç¬¬ä¸€ä¸ªæ–‡æ¡£ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                results = vectorstore.similarity_search("test", k=1)
                # å¦‚æœèƒ½æ­£å¸¸è¿”å›ç»“æœï¼ˆå³ä½¿ä¸ºç©ºï¼‰ï¼Œè¯´æ˜æ•°æ®åº“å¯ç”¨
            except Exception as query_error:
                # æŸ¥è¯¢å¤±è´¥ï¼Œæ£€æŸ¥æ˜¯å¦æ˜¯schemaé”™è¯¯
                error_msg = str(query_error).lower()
                is_schema_error = (
                    "no such column" in error_msg or
                    "collections.topic" in error_msg or
                    "schema" in error_msg or
                    "dimensionality" in error_msg or
                    "dimension" in error_msg
                )
                
                if is_schema_error:
                    # Schemaé”™è¯¯æˆ–ç»´åº¦ä¸åŒ¹é…ï¼Œæ¸…ç†æ•°æ®åº“
                    if progress_callback:
                        progress_callback(100, "âš ï¸ æ£€æµ‹åˆ°æ•°æ®åº“ schema é”™è¯¯æˆ–ç»´åº¦ä¸åŒ¹é…ï¼Œæ­£åœ¨æ¸…ç†...")
                    cleanup_corrupted_db(db_path, force=True)
                    return None
                else:
                    # å…¶ä»–æŸ¥è¯¢é”™è¯¯ï¼Œå¯èƒ½æ˜¯ä¸´æ—¶æ€§é—®é¢˜ï¼Œä¸æ¸…ç†æ•°æ®åº“ï¼Œä½†è¿”å›Noneè®©è°ƒç”¨è€…é‡æ–°åˆ›å»º
                    # è®°å½•é”™è¯¯ä½†ä¸æ¸…ç†ï¼Œå› ä¸ºå¯èƒ½æ˜¯ä¸´æ—¶æ€§é—®é¢˜
                    print(f"âš ï¸ å‘é‡æ•°æ®åº“æŸ¥è¯¢å¤±è´¥ï¼ˆå¯èƒ½æ˜¯ä¸´æ—¶æ€§é—®é¢˜ï¼‰: {str(query_error)}")
                    if progress_callback:
                        progress_callback(100, "âš ï¸ å‘é‡æ•°æ®åº“æŸ¥è¯¢å¤±è´¥ï¼Œå°†é‡æ–°åˆ›å»º...")
                    return None
                    
        except Exception as verify_error:
            # len() è°ƒç”¨å¤±è´¥ï¼Œæ£€æŸ¥æ˜¯å¦æ˜¯schemaé”™è¯¯
            error_msg = str(verify_error).lower()
            is_schema_error = (
                "no such column" in error_msg or
                "collections.topic" in error_msg or
                "schema" in error_msg or
                "dimensionality" in error_msg or
                "dimension" in error_msg
            )
            
            if is_schema_error:
                # Schemaé”™è¯¯æˆ–ç»´åº¦ä¸åŒ¹é…ï¼Œæ¸…ç†æ•°æ®åº“
                if progress_callback:
                    progress_callback(100, "âš ï¸ æ£€æµ‹åˆ°æ•°æ®åº“ schema é”™è¯¯æˆ–ç»´åº¦ä¸åŒ¹é…ï¼Œæ­£åœ¨æ¸…ç†...")
                cleanup_corrupted_db(db_path, force=True)
            else:
                # å…¶ä»–é”™è¯¯ï¼ˆå¯èƒ½æ˜¯ä¸´æ—¶æ€§é—®é¢˜ï¼‰ï¼Œä¸æ¸…ç†æ•°æ®åº“ï¼Œåªè¿”å›None
                # è®°å½•é”™è¯¯ä½†ä¸æ¸…ç†ï¼Œå› ä¸ºå¯èƒ½æ˜¯ä¸´æ—¶æ€§é—®é¢˜
                print(f"âš ï¸ å‘é‡æ•°æ®åº“éªŒè¯å¤±è´¥ï¼ˆå¯èƒ½æ˜¯ä¸´æ—¶æ€§é—®é¢˜ï¼‰: {str(verify_error)}")
                if progress_callback:
                    progress_callback(100, "âš ï¸ å‘é‡æ•°æ®åº“éªŒè¯å¤±è´¥ï¼Œå°†é‡æ–°åˆ›å»º...")
            return None
        
        if progress_callback:
            progress_callback(100, "âœ… å‘é‡æ•°æ®åº“åŠ è½½å®Œæˆï¼")
        
        return vectorstore
    except Exception as e:
        # åŠ è½½å¤±è´¥ï¼Œè¿”å› None
        return None

def calculate_content_hash(content: Any) -> str:
    """è®¡ç®—æ–‡æ¡£å†…å®¹çš„å“ˆå¸Œå€¼
    
    Args:
        content: æ–‡æ¡£å†…å®¹ï¼ˆå­—ç¬¦ä¸²æˆ–å­—å…¸ï¼‰
    
    Returns:
        å†…å®¹çš„ MD5 å“ˆå¸Œå€¼
    """
    if isinstance(content, dict):
        # Excel æ–‡ä»¶ï¼šåˆå¹¶æ‰€æœ‰å·¥ä½œè¡¨å†…å®¹
        content_str = "\n".join([f"{k}:{v}" for k, v in content.items()])
    else:
        content_str = str(content)
    
    return hashlib.md5(content_str.encode('utf-8')).hexdigest()

def normalize_path(path: str) -> str:
    """è§„èŒƒåŒ–è·¯å¾„ï¼Œç”¨äºæ¯”è¾ƒ"""
    if not path:
        return ""
    # ç»Ÿä¸€ä½¿ç”¨ os.path.normpath å’Œ os.path.abspath æ¥è§„èŒƒåŒ–è·¯å¾„
    try:
        # å…ˆè§„èŒƒåŒ–è·¯å¾„æ ¼å¼ï¼ˆç»Ÿä¸€æ–œæ ï¼‰
        normalized = os.path.normpath(path)
        # è½¬æ¢ä¸ºç»å¯¹è·¯å¾„ï¼ˆå¦‚æœå¯èƒ½ï¼‰
        if os.path.exists(normalized):
            normalized = os.path.abspath(normalized)
        else:
            # å¦‚æœè·¯å¾„ä¸å­˜åœ¨ï¼Œä»ç„¶è§„èŒƒåŒ–æ ¼å¼
            normalized = os.path.normpath(normalized)
        # ç»Ÿä¸€è½¬æ¢ä¸ºå°å†™ï¼ˆWindowsè·¯å¾„å¤§å°å†™ä¸æ•æ„Ÿï¼‰
        if os.name == 'nt':  # Windows
            normalized = normalized.lower()
        return normalized
    except Exception as e:
        # å¦‚æœè§„èŒƒåŒ–å¤±è´¥ï¼Œè‡³å°‘ç»Ÿä¸€æ ¼å¼
        print(f"âš ï¸ è·¯å¾„è§„èŒƒåŒ–å¤±è´¥: {path}, é”™è¯¯: {str(e)}")
        return os.path.normpath(path).lower() if os.name == 'nt' else os.path.normpath(path)

def check_docs_changed(docs_dict: Dict[str, Any], folder_path: str) -> bool:
    """æ£€æŸ¥æ–‡æ¡£æ˜¯å¦å‘ç”Ÿå˜åŒ–ï¼ˆåŒ…æ‹¬æ¨¡å‹å˜åŒ–ï¼‰
    
    Args:
        docs_dict: å½“å‰æ–‡æ¡£å­—å…¸
        folder_path: æ–‡ä»¶å¤¹è·¯å¾„
    
    Returns:
        True å¦‚æœæ–‡æ¡£æˆ–æ¨¡å‹å‘ç”Ÿå˜åŒ–ï¼ŒFalse å¦‚æœæœªå˜åŒ–
    """
    # åˆ›å»ºæ–‡æ¡£ç­¾åæ–‡ä»¶è·¯å¾„ï¼ˆåŸºäºæ–‡ä»¶å¤¹è·¯å¾„ï¼‰
    db_path = get_vector_db_path(folder_path)
    signature_file = os.path.join(db_path, ".docs_signature.json")
    
    # æ£€æŸ¥æ•°æ®åº“ç›®å½•æ˜¯å¦å­˜åœ¨
    if not os.path.exists(db_path):
        print(f"[INFO] å‘é‡æ•°æ®åº“ç›®å½•ä¸å­˜åœ¨: {db_path}")
        return True  # æ•°æ®åº“ç›®å½•ä¸å­˜åœ¨ï¼Œè®¤ä¸ºéœ€è¦åˆ›å»º
    
    # æ£€æŸ¥ç­¾åæ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(signature_file):
        print(f"[INFO] æ–‡æ¡£ç­¾åæ–‡ä»¶ä¸å­˜åœ¨: {signature_file}")
        return True  # ç­¾åæ–‡ä»¶ä¸å­˜åœ¨ï¼Œè®¤ä¸ºæ–‡æ¡£å·²å˜åŒ–
    
    try:
        # è¯»å–ä¹‹å‰çš„ç­¾å
        with open(signature_file, 'r', encoding='utf-8') as f:
            old_signature = json.load(f)
        
        # æ£€æŸ¥åµŒå…¥æ¨¡å‹æ˜¯å¦å˜åŒ–
        current_embedding_model = load_embedding_model_config()
        old_embedding_model = old_signature.get("embedding_model", "BAAI/bge-small-zh-v1.5")
        old_embedding_dimension = old_signature.get("embedding_dimension", 384)
        current_embedding_dimension = get_embedding_model_dimension(current_embedding_model)
        
        if old_embedding_model != current_embedding_model or old_embedding_dimension != current_embedding_dimension:
            print(f"[CHANGE] åµŒå…¥æ¨¡å‹å˜åŒ–: {old_embedding_model} ({old_embedding_dimension}ç»´) -> {current_embedding_model} ({current_embedding_dimension}ç»´)")
            return True
        
        # ç”Ÿæˆå½“å‰æ–‡æ¡£ç­¾å
        # ä½¿ç”¨è§„èŒƒåŒ–åçš„è·¯å¾„ï¼Œç¡®ä¿ä¸ä¿å­˜çš„ç­¾åè·¯å¾„æ ¼å¼ä¸€è‡´
        normalized_current_folder_path = normalize_path(folder_path) if folder_path else None
        
        current_signature = {
            "folder_path": normalized_current_folder_path,  # ä½¿ç”¨è§„èŒƒåŒ–åçš„è·¯å¾„
            "file_count": len(docs_dict),
            "files": {}
        }
        
        for filename, data in docs_dict.items():
            file_path = data.get('path', '')
            
            file_info = {
                "size": data.get('size', 0),
                "type": data.get('type', '')  # æ–‡ä»¶ç±»å‹
            }
            
            # å¦‚æœæ–‡ä»¶è·¯å¾„å­˜åœ¨ä¸”æ˜¯æŒä¹…è·¯å¾„ï¼ˆéä¸´æ—¶è·¯å¾„ï¼‰ï¼Œè®°å½•å®Œæ•´è·¯å¾„å’Œä¿®æ”¹æ—¶é—´
            if file_path and os.path.exists(file_path):
                # æ£€æŸ¥æ˜¯å¦æ˜¯ä¸´æ—¶è·¯å¾„ï¼ˆä¸´æ—¶è·¯å¾„é€šå¸¸åŒ…å« temp æˆ– tmpï¼‰
                is_temp_path = 'temp' in file_path.lower() or 'tmp' in file_path.lower()
                if not is_temp_path:
                    # ä¿å­˜å®Œæ•´è·¯å¾„ï¼ˆè§„èŒƒåŒ–åï¼‰å’Œä¿®æ”¹æ—¶é—´
                    file_info["path"] = normalize_path(file_path)  # ä¿å­˜è§„èŒƒåŒ–åçš„å®Œæ•´è·¯å¾„
                    file_info["mtime"] = os.path.getmtime(file_path)
            
            current_signature["files"][filename] = file_info
        
        # æ¯”è¾ƒç­¾å - è§„èŒƒåŒ–è·¯å¾„åå†æ¯”è¾ƒ
        old_folder_path = old_signature.get("folder_path")
        current_folder_path = current_signature["folder_path"]
        
        # è§„èŒƒåŒ–è·¯å¾„è¿›è¡Œæ¯”è¾ƒï¼ˆå¤„ç† Noneã€ç©ºå­—ç¬¦ä¸²ã€è·¯å¾„æ ¼å¼å·®å¼‚ç­‰æƒ…å†µï¼‰
        old_path_norm = normalize_path(old_folder_path) if old_folder_path else ""
        current_path_norm = normalize_path(current_folder_path) if current_folder_path else ""
        
        # è·¯å¾„æ¯”è¾ƒé€»è¾‘ï¼š
        # 1. å¦‚æœä¸¤ä¸ªè·¯å¾„éƒ½ä¸ä¸ºç©ºä¸”ä¸åŒï¼Œæ‰è®¤ä¸ºè·¯å¾„å˜åŒ–
        # 2. å¦‚æœæ—§è·¯å¾„ä¸ºç©ºä½†æ–°è·¯å¾„ä¸ä¸ºç©ºï¼Œå¯èƒ½æ˜¯é¦–æ¬¡åˆ›å»ºï¼Œç»§ç»­æ£€æŸ¥æ–‡ä»¶å†…å®¹
        # 3. å¦‚æœæ—§è·¯å¾„ä¸ä¸ºç©ºä½†æ–°è·¯å¾„ä¸ºç©ºï¼Œå¯èƒ½æ˜¯è·¯å¾„ä¸¢å¤±ï¼Œç»§ç»­æ£€æŸ¥æ–‡ä»¶å†…å®¹ï¼ˆå¦‚æœæ–‡ä»¶å†…å®¹åŒ¹é…ï¼Œä»å¯ä½¿ç”¨ï¼‰
        # 4. å¦‚æœä¸¤ä¸ªè·¯å¾„éƒ½ä¸ºç©ºï¼Œç»§ç»­æ£€æŸ¥æ–‡ä»¶å†…å®¹
        if old_path_norm and current_path_norm:
            # ä¸¤ä¸ªè·¯å¾„éƒ½ä¸ä¸ºç©ºï¼Œéœ€è¦æ¯”è¾ƒ
            if old_path_norm != current_path_norm:
                print(f"[CHANGE] æ–‡ä»¶å¤¹è·¯å¾„å˜åŒ–: {old_folder_path} -> {current_folder_path}")
                return True
            # è·¯å¾„ç›¸åŒï¼Œç»§ç»­æ£€æŸ¥æ–‡ä»¶å†…å®¹
        elif not old_path_norm and current_path_norm:
            # æ—§è·¯å¾„ä¸ºç©ºä½†æ–°è·¯å¾„ä¸ä¸ºç©ºï¼Œå¯èƒ½æ˜¯é¦–æ¬¡åˆ›å»º
            # å¦‚æœæ–‡ä»¶å†…å®¹å“ˆå¸Œéƒ½åŒ¹é…ï¼Œå¯ä»¥è®¤ä¸ºæœªå˜åŒ–ï¼ˆå…¼å®¹æ—§ç‰ˆæœ¬ï¼‰
            print(f"[INFO] æ–‡ä»¶å¤¹è·¯å¾„çŠ¶æ€å˜åŒ–: æ—§è·¯å¾„ä¸ºç©º, æ–°è·¯å¾„={current_folder_path}")
            # ç»§ç»­æ£€æŸ¥æ–‡ä»¶å†…å®¹
        elif old_path_norm and not current_path_norm:
            # æ—§è·¯å¾„ä¸ä¸ºç©ºä½†æ–°è·¯å¾„ä¸ºç©ºï¼Œå¯èƒ½æ˜¯è·¯å¾„ä¸¢å¤±
            # å¦‚æœæ–‡ä»¶å†…å®¹å“ˆå¸Œéƒ½åŒ¹é…ï¼Œä»å¯ä½¿ç”¨ï¼ˆå…¼å®¹æ€§ï¼‰
            print(f"[INFO] æ–‡ä»¶å¤¹è·¯å¾„çŠ¶æ€å˜åŒ–: æ—§è·¯å¾„={old_folder_path}, æ–°è·¯å¾„ä¸ºç©º")
            # ç»§ç»­æ£€æŸ¥æ–‡ä»¶å†…å®¹
        # å¦‚æœä¸¤ä¸ªè·¯å¾„éƒ½ä¸ºç©ºï¼Œç»§ç»­æ£€æŸ¥æ–‡ä»¶å†…å®¹
        
        if old_signature.get("file_count") != current_signature["file_count"]:
            print(f"[CHANGE] æ–‡ä»¶æ•°é‡å˜åŒ–: {old_signature.get('file_count')} -> {current_signature['file_count']}")
            return True
        
        old_files = old_signature.get("files", {})
        current_files = current_signature["files"]
        
        if set(old_files.keys()) != set(current_files.keys()):
            old_keys = set(old_files.keys())
            current_keys = set(current_files.keys())
            added = current_keys - old_keys
            removed = old_keys - current_keys
            print(f"[CHANGE] æ–‡ä»¶åå˜åŒ–: æ–°å¢={added}, åˆ é™¤={removed}")
            return True
        
        # æ£€æŸ¥æ–‡ä»¶ï¼šæ–‡ä»¶åï¼ˆå®Œæ•´è·¯å¾„ï¼‰ã€å¤§å°ã€ç±»å‹ã€ä¿®æ”¹æ—¶é—´
        changed_files = []
        for filename in old_files.keys():
            if filename not in current_files:
                changed_files.append(f"{filename} (å·²åˆ é™¤)")
                return True
            
            old_info = old_files[filename]
            current_info = current_files[filename]
            
            # 1. æ£€æŸ¥æ–‡ä»¶å¤§å°
            if old_info.get("size") != current_info.get("size"):
                changed_files.append(f"{filename} (å¤§å°å˜åŒ–: {old_info.get('size')} -> {current_info.get('size')})")
                return True
            
            # 2. æ£€æŸ¥æ–‡ä»¶ç±»å‹
            if old_info.get("type") != current_info.get("type"):
                changed_files.append(f"{filename} (ç±»å‹å˜åŒ–: {old_info.get('type')} -> {current_info.get('type')})")
                return True
            
            # 3. æ£€æŸ¥æ–‡ä»¶è·¯å¾„ï¼ˆå®Œæ•´è·¯å¾„ï¼‰
            old_path = old_info.get("path")
            current_path = current_info.get("path")
            if old_path and current_path:
                # ä¸¤è€…éƒ½æœ‰è·¯å¾„ï¼Œæ¯”è¾ƒè§„èŒƒåŒ–åçš„è·¯å¾„
                if old_path != current_path:
                    changed_files.append(f"{filename} (è·¯å¾„å˜åŒ–: {old_path} -> {current_path})")
                    return True
            
            # 4. æ£€æŸ¥ä¿®æ”¹æ—¶é—´ï¼ˆå¦‚æœéƒ½å­˜åœ¨ï¼‰
            old_mtime = old_info.get("mtime")
            current_mtime = current_info.get("mtime")
            if old_mtime and current_mtime:
                # ä¿®æ”¹æ—¶é—´å·®å¼‚è¶…è¿‡1ç§’è®¤ä¸ºæ–‡ä»¶å·²å˜åŒ–
                if abs(old_mtime - current_mtime) > 1:
                    changed_files.append(f"{filename} (ä¿®æ”¹æ—¶é—´å˜åŒ–)")
                    return True
        
        if changed_files:
            print(f"[CHANGE] æ£€æµ‹åˆ°æ–‡æ¡£å˜åŒ–: {', '.join(changed_files)}")
            return True
        
        # æ–‡æ¡£æœªå˜åŒ–ï¼Œåªæ£€æŸ¥æ•°æ®åº“æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Œä¸éªŒè¯æ˜¯å¦å¯ç”¨
        # å¦‚æœæ–‡æ¡£æœªå˜åŒ–ï¼Œå³ä½¿æ•°æ®åº“æŸåï¼Œä¹Ÿä¸åº”è¯¥è‡ªåŠ¨é‡æ–°åˆ›å»º
        # æ•°æ®åº“çš„å¯ç”¨æ€§ç”± load_existing_vector_store æ¥éªŒè¯
        try:
            # åªæ£€æŸ¥æ•°æ®åº“æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            chroma_sqlite = os.path.join(db_path, "chroma.sqlite3")
            if not os.path.exists(chroma_sqlite):
                print(f"[INFO] æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨: {chroma_sqlite}")
                return True  # æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨ï¼Œéœ€è¦é‡æ–°åˆ›å»º
            
            # æ£€æŸ¥æ•°æ®åº“æ–‡ä»¶å¤§å°ï¼Œå¦‚æœä¸º0ï¼Œå¯èƒ½æŸå
            if os.path.getsize(chroma_sqlite) == 0:
                print(f"[INFO] æ•°æ®åº“æ–‡ä»¶ä¸ºç©ºï¼Œå¯èƒ½æŸå")
                return True  # æ•°æ®åº“æ–‡ä»¶ä¸ºç©ºï¼Œéœ€è¦é‡æ–°åˆ›å»º
            
            # æ–‡æ¡£æœªå˜åŒ–ä¸”æ•°æ®åº“æ–‡ä»¶å­˜åœ¨ï¼Œè¿”å› Falseï¼ˆæ–‡æ¡£æœªå˜åŒ–ï¼‰
            # æ•°æ®åº“çš„å¯ç”¨æ€§ç”± load_existing_vector_store æ¥éªŒè¯
            # å¦‚æœæ•°æ®åº“æŸåï¼Œload_existing_vector_store ä¼šè¿”å› Noneï¼Œç•Œé¢ä¼šæç¤ºä½†ä¸ä¼šè‡ªåŠ¨é‡æ–°åˆ›å»º
            print("[OK] æ–‡æ¡£æœªå˜åŒ–ï¼Œå¯ä»¥ä½¿ç”¨å·²æœ‰å‘é‡æ•°æ®åº“")
            return False
        except Exception as e:
            print(f"[WARN] éªŒè¯æ•°æ®åº“æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
            # éªŒè¯å‡ºé”™ï¼Œä¿å®ˆèµ·è§è®¤ä¸ºéœ€è¦é‡æ–°åˆ›å»º
            return True
    except Exception as e:
        # è¯»å–ç­¾åå¤±è´¥ï¼Œè®°å½•é”™è¯¯ä½†è®¤ä¸ºæ–‡æ¡£å·²å˜åŒ–
        print(f"[ERROR] è¯»å–æ–‡æ¡£ç­¾åå¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return True

def get_embedding_model_dimension(model_name: str) -> int:
    """è·å–åµŒå…¥æ¨¡å‹çš„å‘é‡ç»´åº¦
    
    Args:
        model_name: æ¨¡å‹åç§°
    
    Returns:
        å‘é‡ç»´åº¦
    """
    model_dimensions = {
        "BAAI/bge-small-zh-v1.5": 384,
        "BAAI/bge-base-zh-v1.5": 768,
        "BAAI/bge-large-zh-v1.5": 1024,
    }
    return model_dimensions.get(model_name, 384)  # é»˜è®¤384

def save_docs_signature(docs_dict: Dict[str, Any], folder_path: str):
    """ä¿å­˜æ–‡æ¡£ç­¾å
    
    Args:
        docs_dict: æ–‡æ¡£å­—å…¸
        folder_path: æ–‡ä»¶å¤¹è·¯å¾„
    """
    try:
        db_path = get_vector_db_path(folder_path)
        os.makedirs(db_path, exist_ok=True)
        signature_file = os.path.join(db_path, ".docs_signature.json")
        
        # è·å–å½“å‰ä½¿ç”¨çš„åµŒå…¥æ¨¡å‹
        embedding_model = load_embedding_model_config()
        embedding_dimension = get_embedding_model_dimension(embedding_model)
        
        # ä¿å­˜è§„èŒƒåŒ–åçš„è·¯å¾„ï¼Œç¡®ä¿è·¯å¾„æ¯”è¾ƒæ—¶ä¸€è‡´
        normalized_folder_path = normalize_path(folder_path) if folder_path else None
        
        signature = {
            "folder_path": normalized_folder_path,  # ä¿å­˜è§„èŒƒåŒ–åçš„è·¯å¾„
            "file_count": len(docs_dict),
            "files": {},
            "created_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "embedding_model": embedding_model,  # ä¿å­˜ä½¿ç”¨çš„æ¨¡å‹
            "embedding_dimension": embedding_dimension  # ä¿å­˜æ¨¡å‹ç»´åº¦
        }
        
        for filename, data in docs_dict.items():
            file_path = data.get('path', '')
            
            file_info = {
                "size": data.get('size', 0),
                "type": data.get('type', '')  # æ–‡ä»¶ç±»å‹
            }
            
            # å¦‚æœæ–‡ä»¶è·¯å¾„å­˜åœ¨ä¸”æ˜¯æŒä¹…è·¯å¾„ï¼ˆéä¸´æ—¶è·¯å¾„ï¼‰ï¼Œè®°å½•å®Œæ•´è·¯å¾„å’Œä¿®æ”¹æ—¶é—´
            if file_path and os.path.exists(file_path):
                # æ£€æŸ¥æ˜¯å¦æ˜¯ä¸´æ—¶è·¯å¾„
                is_temp_path = 'temp' in file_path.lower() or 'tmp' in file_path.lower()
                if not is_temp_path:
                    # ä¿å­˜å®Œæ•´è·¯å¾„ï¼ˆè§„èŒƒåŒ–åï¼‰å’Œä¿®æ”¹æ—¶é—´
                    file_info["path"] = normalize_path(file_path)  # ä¿å­˜è§„èŒƒåŒ–åçš„å®Œæ•´è·¯å¾„
                    file_info["mtime"] = os.path.getmtime(file_path)
            
            signature["files"][filename] = file_info
        
        with open(signature_file, 'w', encoding='utf-8') as f:
            json.dump(signature, f, indent=2, ensure_ascii=False)
    except Exception:
        pass  # ä¿å­˜ç­¾åå¤±è´¥ä¸å½±å“ä¸»æµç¨‹

class ProgressEmbeddings:
    """åŒ…è£…çš„åµŒå…¥æ¨¡å‹ç±»ï¼Œç”¨äºåœ¨ç”Ÿæˆå‘é‡æ—¶æ›´æ–°è¿›åº¦"""
    def __init__(self, embeddings, progress_callback=None, total_docs=0, start_progress=70, end_progress=85):
        self.embeddings = embeddings
        self.progress_callback = progress_callback
        self.total_docs = total_docs
        self.start_progress = start_progress
        self.end_progress = end_progress
        self.processed_docs = 0
        self.batch_size = 50  # å†…éƒ¨æ‰¹å¤„ç†å¤§å°ï¼Œç”¨äºè¿›åº¦æ›´æ–°
    
    def embed_documents(self, texts):
        """æ‰¹é‡ç”Ÿæˆå‘é‡ï¼Œå¹¶æ›´æ–°è¿›åº¦ï¼ˆå¦‚æœä¸€æ¬¡æ€§å¤„ç†æ‰€æœ‰æ–‡æ¡£ï¼Œåˆ™å†…éƒ¨åˆ†æ‰¹å¤„ç†ï¼‰"""
        total_texts = len(texts)
        
        # å¦‚æœæ–‡æ¡£æ•°é‡è¾ƒå°‘ï¼Œç›´æ¥å¤„ç†
        if total_texts <= self.batch_size:
            result = self.embeddings.embed_documents(texts)
            self.processed_docs += total_texts
            
            if self.progress_callback and self.total_docs > 0:
                progress = self.start_progress + int((self.processed_docs / self.total_docs) * (self.end_progress - self.start_progress))
                progress = min(progress, self.end_progress)
                self.progress_callback(progress, f"ğŸ”„ æ­¥éª¤ 3/4: ç”Ÿæˆå‘é‡åµŒå…¥ ({self.processed_docs}/{self.total_docs} ä¸ªæ–‡æ¡£å—)...")
            
            return result
        
        # å¦‚æœæ–‡æ¡£æ•°é‡è¾ƒå¤šï¼Œåˆ†æ‰¹å¤„ç†ä»¥æ˜¾ç¤ºè¿›åº¦
        all_embeddings = []
        num_batches = (total_texts + self.batch_size - 1) // self.batch_size
        
        for batch_idx in range(num_batches):
            start_idx = batch_idx * self.batch_size
            end_idx = min(start_idx + self.batch_size, total_texts)
            batch_texts = texts[start_idx:end_idx]
            
            # ç”Ÿæˆå½“å‰æ‰¹æ¬¡çš„å‘é‡
            batch_embeddings = self.embeddings.embed_documents(batch_texts)
            all_embeddings.extend(batch_embeddings)
            
            # æ›´æ–°è¿›åº¦
            self.processed_docs += len(batch_texts)
            if self.progress_callback and self.total_docs > 0:
                progress = self.start_progress + int((self.processed_docs / self.total_docs) * (self.end_progress - self.start_progress))
                progress = min(progress, self.end_progress)
                self.progress_callback(progress, f"ğŸ”„ æ­¥éª¤ 3/4: ç”Ÿæˆå‘é‡åµŒå…¥ ({self.processed_docs}/{self.total_docs} ä¸ªæ–‡æ¡£å—)...")
        
        return all_embeddings
    
    def embed_query(self, text):
        """å•ä¸ªæŸ¥è¯¢å‘é‡åŒ–ï¼ˆä¸æ›´æ–°è¿›åº¦ï¼‰"""
        return self.embeddings.embed_query(text)
    
    def __getattr__(self, name):
        """ä»£ç†å…¶ä»–å±æ€§å’Œæ–¹æ³•åˆ°åŸå§‹ embeddings å¯¹è±¡"""
        return getattr(self.embeddings, name)

def create_local_vector_store(docs_dict: Dict[str, Any], progress_callback=None, folder_path: str = None):
    """åˆ›å»ºæœ¬åœ°å‘é‡æ•°æ®åº“ï¼Œä½¿ç”¨å¼€æºåµŒå…¥æ¨¡å‹
    
    Args:
        docs_dict: æ–‡æ¡£å­—å…¸
        progress_callback: è¿›åº¦å›è°ƒå‡½æ•°ï¼Œæ¥æ”¶ (progress, message) å‚æ•°
        folder_path: æ–‡ä»¶å¤¹è·¯å¾„ï¼ˆç”¨äºç­¾åï¼‰
    """
    try:
        # å…¼å®¹ä¸åŒç‰ˆæœ¬çš„ langchain å¯¼å…¥
        try:
            from langchain_text_splitters import RecursiveCharacterTextSplitter
        except ImportError:
            try:
                from langchain.text_splitter import RecursiveCharacterTextSplitter
            except ImportError:
                from langchain_core.text_splitter import RecursiveCharacterTextSplitter
        
        # ä¼˜å…ˆä½¿ç”¨æ–°ç‰ˆæœ¬çš„åŒ…
        try:
            from langchain_huggingface import HuggingFaceEmbeddings
        except ImportError:
            from langchain_community.embeddings import HuggingFaceEmbeddings
        
        try:
            from langchain_chroma import Chroma
        except ImportError:
            from langchain_community.vectorstores import Chroma
        try:
            from langchain.schema import Document as LangDocument
        except ImportError:
            from langchain_core.documents import Document as LangDocument
        
        # æ­¥éª¤ 0: åœ¨å¼€å§‹å¤„ç†ä¹‹å‰ï¼Œå…ˆæ£€æµ‹å¹¶æ¸…ç†æŸåçš„æ•°æ®åº“ç›®å½•ï¼ˆé¿å…ç‰ˆæœ¬å…¼å®¹æ€§é—®é¢˜ï¼‰
        db_path = get_vector_db_path(folder_path) if folder_path else "./chroma_db"
        
        # æ£€æŸ¥ç›®å½•æƒé™ï¼ˆåœ¨åˆ›å»ºç›®å½•ä¹‹å‰ï¼‰
        parent_dir = os.path.dirname(db_path) if os.path.dirname(db_path) else "."
        if not os.path.exists(parent_dir):
            os.makedirs(parent_dir, exist_ok=True)
        if not os.access(parent_dir, os.W_OK):
            raise PermissionError(f"æ²¡æœ‰å†™å…¥æƒé™: {parent_dir}")
        
        # å¦‚æœæ•°æ®åº“ç›®å½•å·²å­˜åœ¨ï¼Œå…ˆæ£€æµ‹æ˜¯å¦æŸåæˆ–æ¨¡å‹ç»´åº¦ä¸åŒ¹é…
        # æ³¨æ„ï¼šæ­¤å‡½æ•°åªåœ¨æ–‡æ¡£å˜åŒ–æˆ–æ•°æ®åº“ä¸å­˜åœ¨æ—¶è¢«è°ƒç”¨
        # å¦‚æœæ•°æ®åº“å­˜åœ¨ä¸”æ­£å¸¸ï¼Œè°ƒç”¨è€…åº”è¯¥å·²ç»æ£€æŸ¥è¿‡æ–‡æ¡£å˜åŒ–
        if os.path.exists(db_path):
            if progress_callback:
                progress_callback(5, "ğŸ”„ æ£€æµ‹å‘é‡æ•°æ®åº“çŠ¶æ€...")
            
            # æ£€æŸ¥æ¨¡å‹ç»´åº¦æ˜¯å¦åŒ¹é…
            embedding_model = load_embedding_model_config()
            expected_dimension = get_embedding_model_dimension(embedding_model)
            
            # å°è¯•æ£€æµ‹ç°æœ‰æ•°æ®åº“çš„ç»´åº¦
            dimension_mismatch = False
            try:
                # å°è¯•åŠ è½½æ•°æ®åº“æ¥æ£€æµ‹ç»´åº¦
                try:
                    from langchain_huggingface import HuggingFaceEmbeddings
                except ImportError:
                    from langchain_community.embeddings import HuggingFaceEmbeddings
                
                try:
                    from langchain_chroma import Chroma
                except ImportError:
                    from langchain_community.vectorstores import Chroma
                
                # ä½¿ç”¨å½“å‰æ¨¡å‹åˆå§‹åŒ–
                model_path = get_model_path(embedding_model)
                test_embeddings = HuggingFaceEmbeddings(
                    model_name=model_path,
                    model_kwargs={'device': 'cpu'},
                    encode_kwargs={'normalize_embeddings': True}
                )
                
                # å°è¯•åŠ è½½å‘é‡æ•°æ®åº“
                test_vectorstore = Chroma(
                    persist_directory=db_path,
                    embedding_function=test_embeddings
                )
                
                # å°è¯•è®¿é—®æ•°æ®åº“ï¼Œå¦‚æœç»´åº¦ä¸åŒ¹é…ä¼šæŠ›å‡ºå¼‚å¸¸
                try:
                    _ = len(test_vectorstore)
                except Exception as dim_error:
                    error_msg = str(dim_error).lower()
                    if "dimension" in error_msg or "dimensionality" in error_msg:
                        dimension_mismatch = True
            except Exception:
                # å¦‚æœæ£€æµ‹å¤±è´¥ï¼Œå‡è®¾ç»´åº¦ä¸åŒ¹é…ï¼ˆå®‰å…¨èµ·è§ï¼‰
                dimension_mismatch = True
            
            # æ£€æµ‹æ•°æ®åº“æ˜¯å¦æŸåï¼ˆç‰¹åˆ«æ˜¯ schema å…¼å®¹æ€§é—®é¢˜ï¼‰
            is_corrupted = check_db_corrupted(db_path)
            
            if is_corrupted or dimension_mismatch:
                # æ•°æ®åº“æŸåæˆ–ç»´åº¦ä¸åŒ¹é…ï¼Œéœ€è¦æ¸…ç†åé‡æ–°åˆ›å»º
                if dimension_mismatch:
                    if progress_callback:
                        progress_callback(5, f"âš ï¸ æ£€æµ‹åˆ°æ¨¡å‹ç»´åº¦ä¸åŒ¹é…ï¼ˆå½“å‰æ¨¡å‹ç»´åº¦: {expected_dimension}ï¼‰ï¼Œæ­£åœ¨æ¸…ç†æ—§æ•°æ®åº“...")
                else:
                    if progress_callback:
                        progress_callback(5, "âš ï¸ æ£€æµ‹åˆ°æ•°æ®åº“æŸåï¼ˆå¯èƒ½æ˜¯ç‰ˆæœ¬å…¼å®¹æ€§é—®é¢˜ï¼‰ï¼Œæ­£åœ¨æ¸…ç†...")
                cleanup_corrupted_db(db_path, force=True)
                import time
                time.sleep(2)  # å¢åŠ ç­‰å¾…æ—¶é—´ï¼Œç¡®ä¿æ–‡ä»¶ç³»ç»Ÿå®Œå…¨æ›´æ–°
                # å†æ¬¡ç¡®è®¤ç›®å½•å·²åˆ é™¤
                if os.path.exists(db_path):
                    import shutil
                    try:
                        shutil.rmtree(db_path)
                        print(f"âœ… å¼ºåˆ¶åˆ é™¤æ•°æ®åº“ç›®å½•: {db_path}")
                    except Exception as cleanup_error:
                        print(f"âš ï¸ å¼ºåˆ¶åˆ é™¤å¤±è´¥: {str(cleanup_error)}")
                        # å¦‚æœåˆ é™¤å¤±è´¥ï¼Œé‡å‘½åç›®å½•
                        backup_name = db_path + "_backup_" + str(int(time.time()))
                        try:
                            os.rename(db_path, backup_name)
                            print(f"âš ï¸ å·²é‡å‘½åæ•°æ®åº“ç›®å½•ä¸ºå¤‡ä»½: {backup_name}")
                        except:
                            pass
            else:
                # æ•°æ®åº“æ­£å¸¸ï¼Œä½†ç”±äºæ–‡æ¡£å˜åŒ–éœ€è¦é‡æ–°åˆ›å»ºï¼Œæ¸…ç†æ—§æ•°æ®åº“
                # æ³¨æ„ï¼šè°ƒç”¨è€…åº”è¯¥å·²ç»æ£€æŸ¥è¿‡æ–‡æ¡£å˜åŒ–ï¼Œè¿™é‡Œç›´æ¥æ¸…ç†å³å¯
                if progress_callback:
                    progress_callback(5, "ğŸ“ æ£€æµ‹åˆ°æ–‡æ¡£å˜åŒ–ï¼Œæ¸…ç†æ—§å‘é‡æ•°æ®åº“...")
                cleanup_corrupted_db(db_path, force=True)
                import time
                time.sleep(0.5)  # ç­‰å¾…æ–‡ä»¶ç³»ç»Ÿæ›´æ–°
        
        # æå–æ–‡æœ¬å†…å®¹
        if progress_callback:
            progress_callback(15, "ğŸ”„ æ­¥éª¤ 1/4: æå–æ–‡æ¡£å†…å®¹...")
        
        texts = []
        total_files = len(docs_dict)
        for idx, (filename, data) in enumerate(docs_dict.items()):
            content = data['content']
            if isinstance(content, dict):  # Excelæ–‡ä»¶
                for sheet, sheet_content in content.items():
                    texts.append(f"æ–‡ä»¶: {filename} | å·¥ä½œè¡¨: {sheet}\n{sheet_content}")
            else:
                texts.append(f"æ–‡ä»¶: {filename}\n{content}")
            
            if progress_callback and total_files > 0:
                progress = 15 + int((idx + 1) / total_files * 10)
                progress_callback(progress, f"ğŸ”„ æ­¥éª¤ 1/4: æå–æ–‡æ¡£å†…å®¹... ({idx + 1}/{total_files})")
        
        # åˆ†å‰²æ–‡æœ¬
        if progress_callback:
            progress_callback(30, "ğŸ”„ æ­¥éª¤ 2/4: åˆ†å‰²æ–‡æœ¬...")
        
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200,
            length_function=len,
        )
        
        documents = []
        total_texts = len(texts)
        for i, text in enumerate(texts):
            splits = text_splitter.split_text(text)
            for split in splits:
                documents.append(LangDocument(
                    page_content=split,
                    metadata={"source": list(docs_dict.keys())[i % len(docs_dict)]}
                ))
            
            if progress_callback and total_texts > 0:
                progress = 30 + int((i + 1) / total_texts * 20)
                progress_callback(progress, f"ğŸ”„ æ­¥éª¤ 2/4: åˆ†å‰²æ–‡æœ¬... ({i + 1}/{total_texts})")
        
        # ä½¿ç”¨æœ¬åœ°åµŒå…¥æ¨¡å‹
        if progress_callback:
            progress_callback(55, "ğŸ”„ æ­¥éª¤ 3/4: åˆå§‹åŒ–åµŒå…¥æ¨¡å‹ï¼ˆé¦–æ¬¡è¿è¡Œä¼šä¸‹è½½æ¨¡å‹ï¼Œå¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼‰...")
        
        # ä¼˜å…ˆä½¿ç”¨æœ¬åœ°æ¨¡å‹è·¯å¾„ï¼Œé¿å…ç½‘ç»œä¸‹è½½
        embedding_model = load_embedding_model_config()
        model_path = get_model_path(embedding_model)
        
        try:
            embeddings = HuggingFaceEmbeddings(
                model_name=model_path,  # ä½¿ç”¨é…ç½®çš„åµŒå…¥æ¨¡å‹
                model_kwargs={'device': 'cpu'},
                encode_kwargs={'normalize_embeddings': True}
            )
        except Exception as model_error:
            error_type = type(model_error).__name__
            error_msg = str(model_error)
            raise Exception(f"åµŒå…¥æ¨¡å‹åˆå§‹åŒ–å¤±è´¥ [{error_type}]: {error_msg}\n\n"
                          f"å¯èƒ½çš„åŸå› :\n"
                          f"- æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨æˆ–æŸå\n"
                          f"- ç½‘ç»œè¿æ¥é—®é¢˜ï¼ˆæ— æ³•ä¸‹è½½æ¨¡å‹ï¼‰\n"
                          f"- æ¨¡å‹è·¯å¾„é…ç½®é”™è¯¯: {model_path}\n\n"
                          f"è§£å†³æ–¹æ¡ˆ:\n"
                          f"- æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨\n"
                          f"- ä½¿ç”¨ download_model.py æ‰‹åŠ¨ä¸‹è½½æ¨¡å‹\n"
                          f"- æ£€æŸ¥ç½‘ç»œè¿æ¥") from model_error
        
        # æ£€æŸ¥æ–‡æ¡£æ˜¯å¦ä¸ºç©º
        if not documents or len(documents) == 0:
            raise ValueError("æ²¡æœ‰å¯ç”¨çš„æ–‡æ¡£å†…å®¹ï¼Œæ— æ³•åˆ›å»ºå‘é‡æ•°æ®åº“ã€‚è¯·æ£€æŸ¥æ–‡æ¡£æ˜¯å¦ä¸ºç©ºæˆ–æ ¼å¼æ˜¯å¦æ­£ç¡®ã€‚")
        
        # ç¡®ä¿ç›®å½•ä¸å­˜åœ¨åå†åˆ›å»ºï¼ˆä¹‹å‰çš„æ¸…ç†åº”è¯¥å·²ç»åˆ é™¤äº†ç›®å½•ï¼‰
        # å¦‚æœç›®å½•ä»ç„¶å­˜åœ¨ï¼Œå¼ºåˆ¶åˆ é™¤ï¼ˆå¯èƒ½æ˜¯ç»´åº¦ä¸åŒ¹é…çš„æ—§æ•°æ®åº“ï¼‰
        if os.path.exists(db_path):
            import shutil
            import time
            
            # ä½¿ç”¨cleanup_corrupted_dbå‡½æ•°è¿›è¡Œå¼ºåŠ›æ¸…ç†
            cleanup_success = cleanup_corrupted_db(db_path, force=True)
            
            if not cleanup_success:
                # å¦‚æœæ¸…ç†å¤±è´¥ï¼Œå°è¯•é‡å‘½åä½œä¸ºå¤‡ä»½ï¼ˆé¿å…é˜»å¡åç»­æ“ä½œï¼‰
                backup_name = db_path + "_backup_" + str(int(time.time()))
                try:
                    os.rename(db_path, backup_name)
                    print(f"âš ï¸ æ— æ³•åˆ é™¤ç›®å½•ï¼Œå·²é‡å‘½åä¸ºå¤‡ä»½: {backup_name}")
                    print(f"   å¯ä»¥åœ¨ç¨‹åºå…³é—­åæ‰‹åŠ¨åˆ é™¤è¯¥å¤‡ä»½ç›®å½•")
                except Exception as rename_error:
                    # å¦‚æœé‡å‘½åä¹Ÿå¤±è´¥ï¼Œè®°å½•è­¦å‘Šä½†ä¸æŠ›å‡ºå¼‚å¸¸ï¼ˆå…è®¸ç»§ç»­åˆ›å»ºæ–°æ•°æ®åº“ï¼‰
                    print(f"âš ï¸ æ— æ³•åˆ é™¤æˆ–é‡å‘½åç›®å½•: {str(rename_error)}")
                    print(f"   ç›®å½• {db_path} å¯èƒ½è¢«å…¶ä»–è¿›ç¨‹å ç”¨")
                    print(f"   å»ºè®®ï¼šå…³é—­å…¶ä»–å¯èƒ½ä½¿ç”¨è¯¥æ•°æ®åº“çš„ç¨‹åºï¼Œç„¶åæ‰‹åŠ¨åˆ é™¤ç›®å½•")
                    # å°è¯•åˆ›å»ºä¸€ä¸ªå¸¦æ—¶é—´æˆ³çš„æ–°ç›®å½•å
                    db_path = db_path + "_new_" + str(int(time.time()))
                    print(f"   å°†ä½¿ç”¨æ–°ç›®å½•: {db_path}")
        
        # åˆ›å»ºæ–°ç›®å½•
        os.makedirs(db_path, exist_ok=True)
        
        # æ­¥éª¤ 3: é¢„ç”Ÿæˆå‘é‡åµŒå…¥ï¼ˆå¸¦è¿›åº¦æ›´æ–°ï¼Œç”¨äºæ˜¾ç¤ºè¿›åº¦å’Œé¢„çƒ­æ¨¡å‹ï¼‰
        # æ³¨æ„ï¼šChroma.from_documents ä¼šåœ¨å†…éƒ¨é‡æ–°ç”Ÿæˆå‘é‡ï¼Œä½†é¢„ç”Ÿæˆå¯ä»¥ï¼š
        # 1. æ˜¾ç¤ºè¯¦ç»†çš„è¿›åº¦æ›´æ–°
        # 2. é¢„çƒ­æ¨¡å‹ï¼ˆé¦–æ¬¡ä½¿ç”¨æ—¶ä¼šåŠ è½½æ¨¡å‹åˆ°å†…å­˜ï¼‰
        # 3. æå‰å‘ç°æ¨¡å‹é”™è¯¯
        total_docs = len(documents)
        batch_size = 50  # æ¯æ‰¹å¤„ç†50ä¸ªæ–‡æ¡£ï¼Œé¿å…å†…å­˜å ç”¨è¿‡å¤§
        
        # æ­¥éª¤ 3: ä½¿ç”¨å¸¦è¿›åº¦æ›´æ–°çš„åµŒå…¥æ¨¡å‹
        total_docs = len(documents)
        if progress_callback:
            progress_callback(70, f"ğŸ”„ æ­¥éª¤ 3/4: ç”Ÿæˆå‘é‡åµŒå…¥ï¼ˆå…± {total_docs} ä¸ªæ–‡æ¡£å—ï¼Œè¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼Œè¯·è€å¿ƒç­‰å¾…ï¼‰...")
        
        # ä½¿ç”¨åŒ…è£…çš„åµŒå…¥æ¨¡å‹ï¼Œåœ¨ç”Ÿæˆå‘é‡æ—¶è‡ªåŠ¨æ›´æ–°è¿›åº¦
        progress_embeddings = ProgressEmbeddings(
            embeddings=embeddings,
            progress_callback=progress_callback,
            total_docs=total_docs,
            start_progress=70,
            end_progress=85
        )
        
        # æ­¥éª¤ 4: åˆ›å»ºå‘é‡å­˜å‚¨ï¼ˆä½¿ç”¨å¸¦è¿›åº¦æ›´æ–°çš„åµŒå…¥æ¨¡å‹ï¼‰
        if progress_callback:
            progress_callback(85, "ğŸ”„ æ­¥éª¤ 4/4: åˆ›å»ºå‘é‡å­˜å‚¨...")
        
        # å…¼å®¹ä¸åŒç‰ˆæœ¬çš„å‚æ•°å
        max_retries = 3  # å¢åŠ é‡è¯•æ¬¡æ•°
        last_error = None
        
        for attempt in range(max_retries):
            try:
                # åœ¨åˆ›å»ºå‰å†æ¬¡ç¡®è®¤ç›®å½•æ˜¯ç©ºçš„ï¼ˆé˜²æ­¢ç»´åº¦ä¸åŒ¹é…ï¼‰
                if os.path.exists(db_path):
                    # æ£€æŸ¥ç›®å½•æ˜¯å¦ä¸ºç©º
                    try:
                        dir_contents = os.listdir(db_path)
                        if dir_contents:
                            # ç›®å½•ä¸ä¸ºç©ºï¼Œå¯èƒ½æ˜¯æ—§æ•°æ®åº“æ®‹ç•™ï¼Œå¼ºåˆ¶æ¸…ç†
                            import shutil
                            if progress_callback:
                                progress_callback(87, f"âš ï¸ æ£€æµ‹åˆ°æ—§æ•°æ®åº“æ®‹ç•™ï¼Œæ­£åœ¨æ¸…ç†ï¼ˆå°è¯• {attempt + 1}/{max_retries}ï¼‰...")
                            try:
                                shutil.rmtree(db_path)
                                os.makedirs(db_path, exist_ok=True)
                                print(f"âœ… æ¸…ç†äº†éç©ºæ•°æ®åº“ç›®å½•: {db_path}")
                                import time
                                time.sleep(1)  # ç­‰å¾…æ–‡ä»¶ç³»ç»Ÿæ›´æ–°
                            except Exception as cleanup_error:
                                print(f"âš ï¸ æ¸…ç†ç›®å½•å¤±è´¥: {str(cleanup_error)}")
                    except Exception:
                        pass  # å¦‚æœæ— æ³•åˆ—å‡ºç›®å½•ï¼Œç»§ç»­å°è¯•åˆ›å»º
                
                # å°è¯•ä½¿ç”¨ embedding å‚æ•°ï¼ˆæ ‡å‡†å‚æ•°åï¼‰
                if progress_callback:
                    progress_callback(88, f"ğŸ”„ æ­£åœ¨åˆ›å»ºå‘é‡æ•°æ®åº“ï¼ˆå°è¯• {attempt + 1}/{max_retries}ï¼‰...")
                try:
                    # ä¼˜å…ˆä½¿ç”¨ embedding å‚æ•°ï¼ˆè¿™æ˜¯æ ‡å‡†å‚æ•°åï¼‰
                    vectorstore = Chroma.from_documents(
                        documents=documents,
                        embedding=progress_embeddings,
                        persist_directory=db_path
                    )
                    break  # æˆåŠŸåˆ›å»ºï¼Œé€€å‡ºå¾ªç¯
                except TypeError as param_error:
                    # å¦‚æœ embedding å‚æ•°ä¸æ”¯æŒï¼Œå°è¯• embedding_function
                    error_msg = str(param_error).lower()
                    if "embedding" in error_msg or "unexpected keyword" in error_msg:
                        try:
                            vectorstore = Chroma.from_documents(
                                documents=documents,
                                embedding_function=progress_embeddings,
                                persist_directory=db_path
                            )
                            break  # æˆåŠŸåˆ›å»ºï¼Œé€€å‡ºå¾ªç¯
                        except TypeError:
                            # å¦‚æœä¸¤ç§å‚æ•°åéƒ½ä¸æ”¯æŒï¼ŒæŠ›å‡ºåŸå§‹é”™è¯¯
                            raise param_error
                    else:
                        raise
            except Exception as create_error:
                # æ£€æŸ¥æ˜¯å¦æ˜¯ç»´åº¦ä¸åŒ¹é…é”™è¯¯
                error_msg = str(create_error).lower()
                if "dimension" in error_msg or "dimensionality" in error_msg:
                    # ç»´åº¦ä¸åŒ¹é…ï¼Œå¼ºåˆ¶æ¸…ç†æ•°æ®åº“å¹¶é‡è¯•
                    if progress_callback:
                        progress_callback(87, f"âš ï¸ æ£€æµ‹åˆ°ç»´åº¦ä¸åŒ¹é…é”™è¯¯ï¼Œæ­£åœ¨æ¸…ç†æ—§æ•°æ®åº“å¹¶é‡è¯•ï¼ˆå°è¯• {attempt + 1}/{max_retries}ï¼‰...")
                    import shutil
                    import time
                    try:
                        if os.path.exists(db_path):
                            shutil.rmtree(db_path)
                            print(f"âœ… æ¸…ç†äº†ç»´åº¦ä¸åŒ¹é…çš„æ•°æ®åº“ç›®å½•: {db_path}")
                            time.sleep(2)  # ç­‰å¾…æ–‡ä»¶ç³»ç»Ÿæ›´æ–°
                        os.makedirs(db_path, exist_ok=True)
                    except Exception as cleanup_error:
                        print(f"âš ï¸ æ¸…ç†æ•°æ®åº“ç›®å½•å¤±è´¥: {str(cleanup_error)}")
                    
                    # å¦‚æœæ˜¯æœ€åä¸€æ¬¡å°è¯•ï¼ŒæŠ›å‡ºè¯¦ç»†é”™è¯¯
                    if attempt == max_retries - 1:
                        raise Exception(f"åˆ›å»ºå‘é‡æ•°æ®åº“å¤±è´¥ï¼šç»´åº¦ä¸åŒ¹é…\n\n"
                                      f"é”™è¯¯ä¿¡æ¯: {str(create_error)}\n\n"
                                      f"å¯èƒ½çš„åŸå› :\n"
                                      f"- æ—§å‘é‡æ•°æ®åº“ä½¿ç”¨äº†ä¸åŒç»´åº¦çš„æ¨¡å‹\n"
                                      f"- æ¨¡å‹åˆ‡æ¢åæœªæ­£ç¡®æ¸…ç†æ—§æ•°æ®åº“\n\n"
                                      f"è§£å†³æ–¹æ¡ˆ:\n"
                                      f"1. æ‰‹åŠ¨åˆ é™¤å‘é‡æ•°æ®åº“ç›®å½•: {db_path}\n"
                                      f"2. æˆ–åœ¨ä¾§è¾¹æ çš„'å‘é‡æ•°æ®åº“ç®¡ç†'ä¸­åˆ é™¤\n"
                                      f"3. ç„¶åé‡æ–°åŠ è½½æ–‡ä»¶å¤¹") from create_error
                    # å¦åˆ™ç»§ç»­é‡è¯•
                    continue
                elif isinstance(create_error, TypeError) and "multiple values for keyword argument" in str(create_error):
                    # å‚æ•°é‡å¤ä¼ é€’é”™è¯¯ï¼Œå°è¯•ä½¿ç”¨ä¸åŒçš„å‚æ•°ä¼ é€’æ–¹å¼
                    if progress_callback:
                        progress_callback(88, f"ğŸ”„ æ£€æµ‹åˆ°å‚æ•°å†²çªï¼Œå°è¯•ä½¿ç”¨æ›¿ä»£æ–¹å¼åˆ›å»ºå‘é‡æ•°æ®åº“ï¼ˆå°è¯• {attempt + 1}/{max_retries}ï¼‰...")
                    try:
                        # å°è¯•åªä½¿ç”¨ä½ç½®å‚æ•°ä¼ é€’ documentsï¼Œå…¶ä»–å‚æ•°ä½¿ç”¨å…³é”®å­—
                        vectorstore = Chroma.from_documents(
                            documents,
                            embedding=progress_embeddings,
                            persist_directory=db_path
                        )
                        break  # æˆåŠŸåˆ›å»ºï¼Œé€€å‡ºå¾ªç¯
                    except Exception as e:
                        # å¦‚æœè¿˜æ˜¯å¤±è´¥ï¼Œè®°å½•é”™è¯¯å¹¶åœ¨æœ€åä¸€æ¬¡å°è¯•æ—¶æŠ›å‡º
                        last_error = e
                        if attempt == max_retries - 1:
                            raise Exception(f"åˆ›å»ºå‘é‡æ•°æ®åº“å¤±è´¥ï¼šå‚æ•°ä¼ é€’é”™è¯¯\n\n"
                                          f"é”™è¯¯ä¿¡æ¯: {str(create_error)}\n\n"
                                          f"å¯èƒ½çš„åŸå› :\n"
                                          f"- langchain_chroma ç‰ˆæœ¬ä¸å…¼å®¹\n"
                                          f"- å‚æ•°ä¼ é€’æ–¹å¼å†²çª\n\n"
                                          f"è§£å†³æ–¹æ¡ˆ:\n"
                                          f"1. æ›´æ–° langchain-chroma: pip install --upgrade langchain-chroma\n"
                                          f"2. æ£€æŸ¥ Chroma ç‰ˆæœ¬å…¼å®¹æ€§\n"
                                          f"3. æŸ¥çœ‹å®Œæ•´é”™è¯¯ä¿¡æ¯ä»¥è·å–æ›´å¤šç»†èŠ‚") from create_error
                        continue
                else:
                    # å…¶ä»–é”™è¯¯ï¼Œè®°å½•å¹¶é‡è¯•
                    last_error = create_error
                    if attempt == max_retries - 1:
                        raise
                    continue
        else:
            # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥äº†
            if last_error:
                error_type = type(last_error).__name__
                raise Exception(f"åˆ›å»ºå‘é‡æ•°æ®åº“å¤±è´¥ï¼ˆå·²é‡è¯• {max_retries} æ¬¡ï¼‰ [{error_type}]: {str(last_error)}") from last_error
            else:
                raise Exception("åˆ›å»ºå‘é‡æ•°æ®åº“å¤±è´¥ï¼šæœªçŸ¥é”™è¯¯")
        
        if progress_callback:
            progress_callback(100, "âœ… å‘é‡æ•°æ®åº“åˆ›å»ºå®Œæˆï¼")
        
        # ä¿å­˜æ–‡æ¡£ç­¾å
        if folder_path:
            save_docs_signature(docs_dict, folder_path)
        
        return vectorstore
    except ImportError as e:
        # å¯¼å…¥é”™è¯¯ï¼Œå¯èƒ½æ˜¯ç¼ºå°‘ä¾èµ–åŒ…
        error_msg = str(e)
        if 'st' in globals():
            st.warning(f"âš ï¸ å‘é‡æ•°æ®åº“åŠŸèƒ½ä¸å¯ç”¨ï¼ˆç¼ºå°‘ä¾èµ–åŒ…ï¼‰: {error_msg}\n\nğŸ’¡ æç¤ºï¼š\n- å‘é‡æœç´¢åŠŸèƒ½å°†ä¸å¯ç”¨\n- æ–‡æ¡£é˜…è¯»å’Œé—®ç­”åŠŸèƒ½ä»å¯æ­£å¸¸ä½¿ç”¨\n- å¦‚éœ€ä½¿ç”¨å‘é‡æœç´¢ï¼Œè¯·å®‰è£…: pip install langchain-text-splitters langchain-community chromadb")
        return None
    except Exception as e:
        # å…¶ä»–é”™è¯¯ï¼Œæ˜¾ç¤ºè¯¦ç»†é”™è¯¯ä¿¡æ¯
        error_msg = str(e)
        error_type = type(e).__name__
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯ NumPy 2.0 å…¼å®¹æ€§é—®é¢˜
        is_numpy_error = ("np.float_" in error_msg or "numpy" in error_msg.lower() or 
                         "AttributeError" in error_type and "float_" in error_msg)
        
        # è®°å½•é”™è¯¯åˆ°æ§åˆ¶å°ï¼ˆç”¨äºè°ƒè¯•ï¼‰
        import traceback
        print(f"âŒ å‘é‡æ•°æ®åº“åˆ›å»ºå¤±è´¥:")
        print(f"   é”™è¯¯ç±»å‹: {error_type}")
        print(f"   é”™è¯¯ä¿¡æ¯: {error_msg}")
        print(f"   è¯¦ç»†å †æ ˆ:")
        traceback.print_exc()
        
        # ä¸å†åœ¨è¿™é‡Œç›´æ¥æ˜¾ç¤ºé”™è¯¯ï¼Œè€Œæ˜¯æŠ›å‡ºå¼‚å¸¸è®©è°ƒç”¨è€…å¤„ç†
        # è¿™æ ·è°ƒç”¨è€…å¯ä»¥ä½¿ç”¨å ä½ç¬¦ç¡®ä¿é”™è¯¯æç¤ºä¸è¾“å…¥æ¡†ç­‰å®½
        if is_numpy_error:
            # NumPy 2.0 å…¼å®¹æ€§é”™è¯¯
            error_detail = (f"âš ï¸ **å‘é‡æ•°æ®åº“åˆ›å»ºå¤±è´¥ - NumPy ç‰ˆæœ¬ä¸å…¼å®¹**\n\n"
                          f"**é”™è¯¯ç±»å‹**: `{error_type}`\n\n"
                          f"**é”™è¯¯ä¿¡æ¯**: {error_msg}\n\n"
                          f"**é—®é¢˜åŸå› **:\n"
                          f"ChromaDB ä¸å…¼å®¹ NumPy 2.0ï¼Œå½“å‰ç¯å¢ƒå¯èƒ½å®‰è£…äº† NumPy 2.0\n\n"
                          f"**è§£å†³æ–¹æ¡ˆ**:\n"
                          f"1. **é™çº§ NumPy åˆ° 1.x ç‰ˆæœ¬**ï¼ˆæ¨èï¼‰:\n"
                          f"   ```bash\n"
                          f"   poetry remove numpy\n"
                          f"   poetry add \"numpy>=1.24.0,<2.0.0\"\n"
                          f"   ```\n"
                          f"   æˆ–ä½¿ç”¨ pip:\n"
                          f"   ```bash\n"
                          f"   pip install \"numpy>=1.24.0,<2.0.0\"\n"
                          f"   ```\n\n"
                          f"2. **é‡æ–°å®‰è£…æ‰€æœ‰ä¾èµ–**:\n"
                          f"   ```bash\n"
                          f"   poetry install\n"
                          f"   ```\n\n"
                          f"3. **æ£€æŸ¥ NumPy ç‰ˆæœ¬**:\n"
                          f"   ```bash\n"
                          f"   poetry run python -c \"import numpy; print(numpy.__version__)\"\n"
                          f"   ```\n\n"
                          f"ğŸ’¡ **æç¤º**: ä¿®å¤åé‡æ–°è¿è¡Œç¨‹åºå³å¯")
        else:
            # å…¶ä»–é”™è¯¯
            error_detail = (f"âš ï¸ **å‘é‡æ•°æ®åº“åˆ›å»ºå¤±è´¥**\n\n"
                          f"**é”™è¯¯ç±»å‹**: `{error_type}`\n\n"
                          f"**é”™è¯¯ä¿¡æ¯**: {error_msg}\n\n"
                          f"**å¯èƒ½çš„åŸå› **:\n"
                          f"- æ–‡æ¡£å†…å®¹ä¸ºç©ºæˆ–æ ¼å¼ä¸æ­£ç¡®\n"
                          f"- åµŒå…¥æ¨¡å‹åŠ è½½å¤±è´¥ï¼ˆæ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–æ¨¡å‹æ–‡ä»¶ï¼‰\n"
                          f"- ChromaDB ç‰ˆæœ¬ä¸å…¼å®¹\n"
                          f"- NumPy ç‰ˆæœ¬ä¸å…¼å®¹ï¼ˆNumPy 2.0 ä¸å…¼å®¹ï¼‰\n"
                          f"- ç£ç›˜ç©ºé—´ä¸è¶³æˆ–æ²¡æœ‰å†™å…¥æƒé™\n"
                          f"- å†…å­˜ä¸è¶³ï¼ˆæ–‡æ¡£å¤ªå¤§ï¼‰\n\n"
                          f"**è§£å†³æ–¹æ¡ˆ**:\n"
                          f"1. æ£€æŸ¥æ–‡æ¡£æ˜¯å¦ä¸ºç©º\n"
                          f"2. æ£€æŸ¥æ§åˆ¶å°è¾“å‡ºçš„è¯¦ç»†é”™è¯¯ä¿¡æ¯\n"
                          f"3. å°è¯•å‡å°‘æ–‡æ¡£æ•°é‡æˆ–å¤§å°\n"
                          f"4. æ£€æŸ¥ç£ç›˜ç©ºé—´å’Œæƒé™\n"
                          f"5. å¦‚æœé—®é¢˜æŒç»­ï¼Œè¯·æŸ¥çœ‹å®Œæ•´é”™è¯¯å †æ ˆ\n\n"
                          f"ğŸ’¡ **æç¤º**: å‘é‡æœç´¢åŠŸèƒ½å°†ä¸å¯ç”¨ï¼Œä½†æ–‡æ¡£é˜…è¯»å’Œé—®ç­”åŠŸèƒ½ä»å¯æ­£å¸¸ä½¿ç”¨ï¼ˆä¼šä½¿ç”¨æ‰€æœ‰æ–‡æ¡£å†…å®¹ï¼Œå¯èƒ½è¾ƒæ…¢ï¼‰")
        
        # æŠ›å‡ºå¼‚å¸¸ï¼Œè®©è°ƒç”¨è€…ä½¿ç”¨å ä½ç¬¦æ˜¾ç¤ºé”™è¯¯
        raise Exception(error_detail)

# DeepSeek APIæ¥å£
def query_deepseek(prompt: str, api_key: str, model: str = "deepseek-chat", max_tokens: int = 2000, 
                   max_retries: int = 3, timeout: int = None):
    """è°ƒç”¨DeepSeek APIï¼Œå¸¦é‡è¯•æœºåˆ¶
    
    Args:
        prompt: æç¤ºæ–‡æœ¬
        api_key: DeepSeek APIå¯†é’¥
        model: æ¨¡å‹åç§°
        max_tokens: æœ€å¤§tokenæ•°
        max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
        timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤å€¼æˆ–ä»session_stateè·å–
    """
    import requests
    import time
    
    # ä» session_state è·å–è¶…æ—¶å’Œé‡è¯•é…ç½®ï¼ˆå¦‚æœå¯ç”¨ï¼‰
    if timeout is None:
        if 'st' in globals() and hasattr(st, 'session_state'):
            timeout = st.session_state.get('api_timeout', 60)
        else:
            timeout = 60
    
    if max_retries is None or max_retries == 3:
        if 'st' in globals() and hasattr(st, 'session_state'):
            max_retries = st.session_state.get('api_max_retries', 3)
    
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }
    
    data = {
        "model": model,
        "messages": [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„åŠ©æ‰‹ï¼Œè¯·åŸºäºæä¾›çš„æ–‡æ¡£å†…å®¹å›ç­”é—®é¢˜ã€‚"},
            {"role": "user", "content": prompt}
        ],
        "max_tokens": max_tokens,
        "temperature": 0.3
    }
    
    # é‡è¯•æœºåˆ¶
    for attempt in range(max_retries):
        try:
            # æ ¹æ®å°è¯•æ¬¡æ•°å¢åŠ è¶…æ—¶æ—¶é—´
            current_timeout = timeout + (attempt * 20)
            
            response = requests.post(
                "https://api.deepseek.com/v1/chat/completions",
                headers=headers,
                json=data,
                timeout=current_timeout
            )
            
            if response.status_code == 200:
                result = response.json()
                if "choices" in result and len(result["choices"]) > 0:
                    return result["choices"][0]["message"]["content"]
                else:
                    return "APIè¿”å›æ ¼å¼å¼‚å¸¸ï¼Œè¯·é‡è¯•"
            elif response.status_code == 401:
                return "APIå¯†é’¥æ— æ•ˆï¼Œè¯·æ£€æŸ¥æ‚¨çš„DeepSeek APIå¯†é’¥"
            elif response.status_code == 429:
                wait_time = 2 ** attempt  # æŒ‡æ•°é€€é¿ï¼š2ç§’ã€4ç§’ã€8ç§’
                if attempt < max_retries - 1:
                    time.sleep(wait_time)
                    continue
                return "APIè¯·æ±‚é¢‘ç‡è¿‡é«˜ï¼Œè¯·ç¨åå†è¯•"
            elif response.status_code == 500:
                if attempt < max_retries - 1:
                    time.sleep(2 ** attempt)
                    continue
                return "DeepSeekæœåŠ¡å™¨é”™è¯¯ï¼Œè¯·ç¨åé‡è¯•"
            elif response.status_code == 400:
                # æ£€æŸ¥æ˜¯å¦æ˜¯ä¸Šä¸‹æ–‡é•¿åº¦è¶…é™é”™è¯¯
                error_text = response.text.lower()
                if "context" in error_text and ("length" in error_text or "exceeded" in error_text or "too long" in error_text):
                    return "âŒ æ–‡æ¡£å†…å®¹è¿‡é•¿ï¼Œè¶…è¿‡äº†APIçš„ä¸Šä¸‹æ–‡çª—å£é™åˆ¶ï¼ˆ64K tokensï¼‰ã€‚\n\nå»ºè®®ï¼š\n1. å‡å°‘é€‰æ‹©çš„æ–‡æ¡£æ•°é‡\n2. æˆ–è€…ä½¿ç”¨åˆ†å—æ€»ç»“åŠŸèƒ½ï¼ˆå¦‚æœå¯ç”¨ï¼‰\n3. æˆ–è€…å…ˆå¯¹æ¯ç¯‡æ–‡æ¡£è¿›è¡Œæ‘˜è¦ï¼Œå†æ€»ç»“æ‘˜è¦å†…å®¹"
                else:
                    return f"APIè¯·æ±‚å‚æ•°é”™è¯¯ (çŠ¶æ€ç : 400): {response.text[:200]}"
            else:
                return f"APIè¯·æ±‚å¤±è´¥ (çŠ¶æ€ç : {response.status_code}): {response.text[:200]}"
                
        except requests.exceptions.Timeout:
            if attempt < max_retries - 1:
                wait_time = 2 ** attempt
                error_msg = f"è¯·æ±‚è¶…æ—¶ï¼ˆå·²å°è¯• {attempt + 1}/{max_retries} æ¬¡ï¼‰ï¼Œ{wait_time}ç§’åé‡è¯•..."
                if 'st' in globals():
                    st.warning(error_msg)
                time.sleep(wait_time)
                continue
            else:
                return f"è¯·æ±‚è¶…æ—¶ï¼ˆå·²é‡è¯• {max_retries} æ¬¡ï¼‰ã€‚å¯èƒ½çš„åŸå› ï¼š\n1. ç½‘ç»œè¿æ¥ä¸ç¨³å®š\n2. è¯·æ±‚å†…å®¹è¿‡é•¿\n3. DeepSeekæœåŠ¡å™¨å“åº”æ…¢\n\nå»ºè®®ï¼š\n- æ£€æŸ¥ç½‘ç»œè¿æ¥\n- å°è¯•å‡å°‘æ–‡æ¡£å†…å®¹\n- ç¨åé‡è¯•"
        
        except requests.exceptions.ConnectionError:
            if attempt < max_retries - 1:
                wait_time = 2 ** attempt
                error_msg = f"è¿æ¥é”™è¯¯ï¼ˆå·²å°è¯• {attempt + 1}/{max_retries} æ¬¡ï¼‰ï¼Œ{wait_time}ç§’åé‡è¯•..."
                if 'st' in globals():
                    st.warning(error_msg)
                time.sleep(wait_time)
                continue
            else:
                return "æ— æ³•è¿æ¥åˆ°DeepSeek APIæœåŠ¡å™¨ã€‚è¯·æ£€æŸ¥ï¼š\n1. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸\n2. æ˜¯å¦å¯ä»¥ä½¿ç”¨ä»£ç†è®¿é—®\n3. DeepSeekæœåŠ¡æ˜¯å¦æ­£å¸¸"
        
        except requests.exceptions.RequestException as e:
            if attempt < max_retries - 1:
                time.sleep(2 ** attempt)
                continue
            return f"ç½‘ç»œè¯·æ±‚å¼‚å¸¸: {str(e)}"
        
        except Exception as e:
            return f"è°ƒç”¨APIæ—¶å‡ºé”™: {str(e)}"
    
    return "APIè°ƒç”¨å¤±è´¥ï¼Œå·²é‡è¯•å¤šæ¬¡ä»æ— æ³•æˆåŠŸ"

def search_similar_documents(vectorstore, query: str, k: int = 4):
    """æ£€ç´¢ç›¸ä¼¼æ–‡æ¡£ç‰‡æ®µ"""
    if vectorstore is None:
        return []
    
    try:
        docs = vectorstore.similarity_search(query, k=k)
        return [(doc.page_content, doc.metadata["source"]) for doc in docs]
    except:
        return []

def answer_with_deepseek(question: str, vectorstore, docs_dict: Dict[str, Any], api_key: str):
    """ä½¿ç”¨DeepSeekå›ç­”é—®é¢˜"""
    # æ£€ç´¢ç›¸å…³æ–‡æ¡£ç‰‡æ®µ
    similar_docs = search_similar_documents(vectorstore, question)
    
    if not similar_docs:
        # å¦‚æœæ²¡æœ‰å‘é‡æ•°æ®åº“ï¼Œä½¿ç”¨æ‰€æœ‰æ–‡æ¡£å†…å®¹
        context = "\n\n".join([f"æ–‡ä»¶: {name}\nå†…å®¹: {data['content'][:2000]}..." 
                             for name, data in docs_dict.items()])
    else:
        # ä½¿ç”¨æ£€ç´¢åˆ°çš„æ–‡æ¡£ç‰‡æ®µ
        context_parts = []
        for content, source in similar_docs:
            context_parts.append(f"æ¥è‡ªæ–‡æ¡£ '{source}' çš„å†…å®¹:\n{content}")
        context = "\n\n".join(context_parts)
    
    # æ„å»ºæç¤º
    prompt = f"""åŸºäºä»¥ä¸‹æ–‡æ¡£å†…å®¹ï¼Œè¯·å›ç­”è¿™ä¸ªé—®é¢˜ï¼š{question}

ç›¸å…³æ–‡æ¡£å†…å®¹ï¼š
{context[:8000]}  # é™åˆ¶ä¸Šä¸‹æ–‡é•¿åº¦

è¯·åŸºäºä¸Šè¿°æ–‡æ¡£å†…å®¹å›ç­”ï¼Œå¦‚æœæ–‡æ¡£ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·æ˜ç¡®è¯´æ˜ã€‚"""

    return query_deepseek(prompt, api_key)

def generate_summary_deepseek(docs_dict: Dict[str, Any], api_key: str, specific_files: List[str] = None, template_id: str = "default"):
    """ä½¿ç”¨DeepSeekç”Ÿæˆæ€»ç»“æŠ¥å‘Š
    
    Args:
        docs_dict: æ–‡æ¡£å­—å…¸
        api_key: APIå¯†é’¥
        specific_files: ç‰¹å®šæ–‡ä»¶åˆ—è¡¨ï¼ˆNoneè¡¨ç¤ºæ‰€æœ‰æ–‡ä»¶ï¼‰
        template_id: ä½¿ç”¨çš„æ¨¡ç‰ˆIDï¼ˆé»˜è®¤ä¸º"default"ï¼‰
    """
    # æå–å†…å®¹
    contents = []
    if specific_files:
        for filename in specific_files:
            if filename in docs_dict:
                content = docs_dict[filename]['content']
                if isinstance(content, dict):
                    # ç§»é™¤å­—æ®µé•¿åº¦é™åˆ¶ï¼Œè®©APIè‡ªè¡Œå¤„ç†
                    content = "\n".join([f"{k}: {v}" for k, v in content.items()])
                contents.append(f"æ–‡ä»¶: {filename}\n{content}")
    else:
        for filename, data in docs_dict.items():
            content = data['content']
            if isinstance(content, dict):
                # ç§»é™¤å­—æ®µé•¿åº¦é™åˆ¶ï¼Œè®©APIè‡ªè¡Œå¤„ç†
                content = "\n".join([f"{k}: {v}" for k, v in content.items()])
            contents.append(f"æ–‡ä»¶: {filename}\n{content}")
    
    combined_content = "\n\n".join(contents)
    
    # åŠ è½½æ¨¡ç‰ˆ
    template_data = get_template("summary", template_id)
    if template_data:
        template_str = template_data.get("template", "")
        # æ›¿æ¢æ¨¡ç‰ˆä¸­çš„å ä½ç¬¦ï¼ˆç§»é™¤å­—ç¬¦é™åˆ¶ï¼Œè®©APIè‡ªè¡Œå¤„ç†ï¼‰
        prompt = template_str.format(content=combined_content)
    else:
        # å¦‚æœæ¨¡ç‰ˆä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤æ¨¡ç‰ˆ
        prompt = f"""è¯·æ ¹æ®ä»¥ä¸‹æ–‡æ¡£å†…å®¹ï¼Œç”Ÿæˆä¸€ä»½è¯¦ç»†çš„æ€»ç»“æŠ¥å‘Šï¼š

æ–‡æ¡£å†…å®¹ï¼š
{combined_content}

è¯·ç”ŸæˆåŒ…æ‹¬ä»¥ä¸‹éƒ¨åˆ†çš„æŠ¥å‘Šï¼š
1. æ•´ä½“å†…å®¹æ¦‚è¿°
2. æ ¸å¿ƒè¦ç‚¹æ€»ç»“
3. å…³é”®æ•°æ®/ä¿¡æ¯æå–
4. ä¸»è¦å‘ç°å’Œæ´å¯Ÿ
5. å»ºè®®å’Œä¸‹ä¸€æ­¥è¡ŒåŠ¨

æŠ¥å‘Šï¼š"""

    return query_deepseek(prompt, api_key, max_tokens=3000)

# æ˜¾ç¤ºç‰ˆæƒä¿¡æ¯
def show_footer():
    """åœ¨é¡µé¢åº•éƒ¨æ˜¾ç¤ºç‰ˆæƒä¿¡æ¯"""
    st.markdown("---")
    st.markdown(
        """
        <div style='text-align: center; color: #666; padding: 20px 0;'>
            <p style='margin: 5px 0;'><strong>Copyright Â© 2026 å•æ»¢</strong></p>
            <p style='margin: 5px 0;'>
                GitHub: <a href='https://github.com/lveyond' target='_blank' style='color: #1f77b4;'>@lveyond</a> | 
                QQ/WeChat: 329613507
            </p>
        </div>
        """,
        unsafe_allow_html=True
    )

# Streamlitç•Œé¢
def main():
    # æ·»åŠ è‡ªå®šä¹‰CSSæ ·å¼ï¼Œå°†è¿›åº¦æ¡å’ŒprimaryæŒ‰é’®æ”¹ä¸ºè‰ç»¿è‰²
    st.markdown("""
    <style>
    /* è¿›åº¦æ¡é¢œè‰²æ”¹ä¸ºè‰ç»¿è‰² - ä½¿ç”¨æ›´é€šç”¨çš„é€‰æ‹©å™¨ */
    .stProgress .st-bo {
        background-color: #7cb342 !important;
    }
    .stProgress > div > div > div > div {
        background-color: #7cb342 !important;
    }
    div[data-testid="stProgress"] > div > div > div > div {
        background-color: #7cb342 !important;
    }
    
    /* PrimaryæŒ‰é’®é¢œè‰²æ”¹ä¸ºè‰ç»¿è‰² - ä½¿ç”¨æ›´é€šç”¨çš„é€‰æ‹©å™¨ */
    .stButton > button[kind="primary"],
    .stButton > button[type="primary"],
    button[kind="primary"],
    button[type="primary"] {
        background-color: #7cb342 !important;
        border-color: #7cb342 !important;
        color: white !important;
    }
    
    /* PrimaryæŒ‰é’®æ‚¬åœæ•ˆæœ */
    .stButton > button[kind="primary"]:hover,
    .stButton > button[type="primary"]:hover,
    button[kind="primary"]:hover,
    button[type="primary"]:hover {
        background-color: #689f38 !important;
        border-color: #689f38 !important;
    }
    
    /* PrimaryæŒ‰é’®æ¿€æ´»æ•ˆæœ */
    .stButton > button[kind="primary"]:active,
    .stButton > button[type="primary"]:active,
    button[kind="primary"]:active,
    button[type="primary"]:active {
        background-color: #558b2f !important;
        border-color: #558b2f !important;
    }
    
    /* ä¿®å¤expanderç»„ä»¶æ¸²æŸ“æ—¶çŸ­æš‚æ˜¾ç¤ºkeyboard_arrow_rightæ–‡æœ¬çš„é—®é¢˜ */
    /* è¿™æ˜¯Streamlitå†…éƒ¨Material Iconså­—ä½“åŠ è½½æ—¶çš„ä¸´æ—¶æ˜¾ç¤ºé—®é¢˜ */
    /* ç¡®ä¿expanderæ ‡é¢˜åŒºåŸŸæ­£ç¡®æ¸²æŸ“ */
    [data-testid="stExpander"] .streamlit-expanderHeader {
        position: relative;
        overflow: hidden;
    }
    
    [data-testid="stExpander"] .streamlit-expanderHeader label {
        white-space: nowrap;
        overflow: hidden;
        text-overflow: ellipsis;
    }
    
    /* é¢„åŠ è½½Material Iconså­—ä½“ï¼Œé¿å…æ˜¾ç¤ºæ–‡æœ¬ */
    @import url('https://fonts.googleapis.com/icon?family=Material+Icons');
    
    /* ç¡®ä¿Material Iconsæ­£ç¡®æ¸²æŸ“ */
    [data-testid="stExpander"] [class*="material-icons"],
    [data-testid="stExpander"] .material-icons {
        font-family: 'Material Icons' !important;
        font-feature-settings: 'liga' !important;
        text-rendering: optimizeLegibility !important;
        -webkit-font-smoothing: antialiased !important;
        font-style: normal !important;
        font-weight: normal !important;
        letter-spacing: normal !important;
        text-transform: none !important;
        display: inline-block !important;
        white-space: nowrap !important;
        word-wrap: normal !important;
        direction: ltr !important;
    }
    
    /* éª¨æ¶å±æ ·å¼ */
    .skeleton-screen {
        position: fixed;
        top: 0;
        left: 0;
        width: 100%;
        height: 100%;
        background: #ffffff;
        z-index: 9999;
        padding: 20px;
        box-sizing: border-box;
    }
    
    .skeleton-header {
        height: 60px;
        background: linear-gradient(90deg, #f0f0f0 25%, #e0e0e0 50%, #f0f0f0 75%);
        background-size: 200% 100%;
        animation: skeleton-loading 1.5s ease-in-out infinite;
        border-radius: 8px;
        margin-bottom: 20px;
        max-width: 600px;
    }
    
    .skeleton-container {
        display: flex;
        gap: 20px;
        height: calc(100vh - 120px);
    }
    
    .skeleton-sidebar {
        width: 300px;
        background: #f8f9fa;
        border-radius: 8px;
        padding: 20px;
    }
    
    .skeleton-sidebar-item {
        height: 40px;
        background: linear-gradient(90deg, #e9ecef 25%, #dee2e6 50%, #e9ecef 75%);
        background-size: 200% 100%;
        animation: skeleton-loading 1.5s ease-in-out infinite;
        border-radius: 6px;
        margin-bottom: 15px;
    }
    
    .skeleton-sidebar-item.short {
        width: 60%;
    }
    
    .skeleton-sidebar-item.medium {
        width: 80%;
    }
    
    .skeleton-main {
        flex: 1;
        background: #ffffff;
        border-radius: 8px;
        padding: 20px;
    }
    
    .skeleton-content-block {
        height: 200px;
        background: linear-gradient(90deg, #f0f0f0 25%, #e0e0e0 50%, #f0f0f0 75%);
        background-size: 200% 100%;
        animation: skeleton-loading 1.5s ease-in-out infinite;
        border-radius: 8px;
        margin-bottom: 20px;
    }
    
    .skeleton-content-line {
        height: 20px;
        background: linear-gradient(90deg, #f0f0f0 25%, #e0e0e0 50%, #f0f0f0 75%);
        background-size: 200% 100%;
        animation: skeleton-loading 1.5s ease-in-out infinite;
        border-radius: 4px;
        margin-bottom: 10px;
    }
    
    .skeleton-content-line.short {
        width: 40%;
    }
    
    .skeleton-content-line.medium {
        width: 70%;
    }
    
    .skeleton-content-line.long {
        width: 100%;
    }
    
    @keyframes skeleton-loading {
        0% {
            background-position: 200% 0;
        }
        100% {
            background-position: -200% 0;
        }
    }
    
    .skeleton-screen.hidden {
        opacity: 0;
        transition: opacity 0.3s ease-out;
        pointer-events: none;
    }
    </style>
    <script>
    // éšè—expanderä¸­å¯èƒ½æ˜¾ç¤ºçš„keyboard_arrow_rightæ–‡æœ¬ï¼ˆMaterial IconsåŠ è½½å‰çš„ä¸´æ—¶æ˜¾ç¤ºï¼‰
    (function() {
        function hideKeyboardArrowText() {
            const expanders = document.querySelectorAll('[data-testid="stExpander"]');
            expanders.forEach(expander => {
                const elements = expander.querySelectorAll('*');
                elements.forEach(element => {
                    const text = element.textContent || element.innerText || '';
                    // å¦‚æœå…ƒç´ åªåŒ…å«keyboard_arrow_rightæ–‡æœ¬ï¼Œéšè—å®ƒ
                    if (text.trim() === 'keyboard_arrow_right') {
                        element.style.display = 'none';
                        element.style.visibility = 'hidden';
                        element.style.opacity = '0';
                        element.style.width = '0';
                        element.style.height = '0';
                        element.style.overflow = 'hidden';
                    }
                });
            });
        }
        
        // ç«‹å³æ‰§è¡Œ
        hideKeyboardArrowText();
        
        // é¡µé¢åŠ è½½å®Œæˆåæ‰§è¡Œ
        if (document.readyState === 'loading') {
            document.addEventListener('DOMContentLoaded', hideKeyboardArrowText);
        }
        
        // ä½¿ç”¨MutationObserverç›‘å¬DOMå˜åŒ–
        if (typeof MutationObserver !== 'undefined') {
            const observer = new MutationObserver(function(mutations) {
                let shouldCheck = false;
                mutations.forEach(function(mutation) {
                    if (mutation.addedNodes.length > 0) {
                        shouldCheck = true;
                    }
                });
                if (shouldCheck) {
                    setTimeout(hideKeyboardArrowText, 10);
                }
            });
            observer.observe(document.body, {
                childList: true,
                subtree: true
            });
        }
    })();
    
    // åˆ›å»ºå¹¶æ˜¾ç¤ºéª¨æ¶å±
    function showSkeletonScreen() {
        const skeleton = document.createElement('div');
        skeleton.className = 'skeleton-screen';
        skeleton.id = 'skeleton-screen';
        skeleton.innerHTML = `
            <div class="skeleton-header"></div>
            <div class="skeleton-container">
                <div class="skeleton-sidebar">
                    <div class="skeleton-sidebar-item short"></div>
                    <div class="skeleton-sidebar-item medium"></div>
                    <div class="skeleton-sidebar-item"></div>
                    <div class="skeleton-sidebar-item short"></div>
                    <div class="skeleton-sidebar-item medium"></div>
                    <div class="skeleton-sidebar-item"></div>
                    <div class="skeleton-sidebar-item short"></div>
                </div>
                <div class="skeleton-main">
                    <div class="skeleton-content-block"></div>
                    <div class="skeleton-content-line long"></div>
                    <div class="skeleton-content-line medium"></div>
                    <div class="skeleton-content-line short"></div>
                    <div class="skeleton-content-block"></div>
                    <div class="skeleton-content-line long"></div>
                    <div class="skeleton-content-line long"></div>
                </div>
            </div>
        `;
        document.body.appendChild(skeleton);
    }
    
    // éšè—éª¨æ¶å±
    function hideSkeletonScreen() {
        const skeleton = document.getElementById('skeleton-screen');
        if (skeleton) {
            skeleton.classList.add('hidden');
            setTimeout(() => {
                skeleton.remove();
            }, 300);
        }
    }
    
    // é¡µé¢åŠ è½½æ—¶æ˜¾ç¤ºéª¨æ¶å±
    (function() {
        // ç«‹å³æ˜¾ç¤ºéª¨æ¶å±
        showSkeletonScreen();
        
        // æ£€æµ‹Streamlitåº”ç”¨æ˜¯å¦å·²åŠ è½½
        function checkStreamlitLoaded() {
            const stApp = document.querySelector('[data-testid="stApp"]');
            const mainContent = document.querySelector('[data-testid="stAppViewContainer"]');
            
            // å¦‚æœStreamlitåº”ç”¨å·²åŠ è½½ä¸”ä¸»è¦å†…å®¹å·²æ¸²æŸ“
            if (stApp && mainContent && mainContent.children.length > 0) {
                // ç­‰å¾…ä¸€å°æ®µæ—¶é—´ç¡®ä¿å†…å®¹å®Œå…¨æ¸²æŸ“
                setTimeout(function() {
                    hideSkeletonScreen();
                }, 300);
                return true;
            }
            return false;
        }
        
        // ç«‹å³æ£€æŸ¥ä¸€æ¬¡
        if (!checkStreamlitLoaded()) {
            // å¦‚æœè¿˜æ²¡åŠ è½½ï¼Œç›‘å¬DOMå˜åŒ–
            const observer = new MutationObserver(function(mutations, obs) {
                if (checkStreamlitLoaded()) {
                    obs.disconnect();
                }
            });
            
            observer.observe(document.body, {
                childList: true,
                subtree: true
            });
            
            // è¶…æ—¶ä¿æŠ¤ï¼šæœ€å¤šç­‰å¾…3ç§’
            setTimeout(function() {
                observer.disconnect();
                hideSkeletonScreen();
            }, 3000);
        }
    })();
    </script>
    """, unsafe_allow_html=True)
    
    st.set_page_config(
        page_title="æ™ºèƒ½çŸ¥è¯†åº“ç³»ç»Ÿ (DeepSeekç‰ˆ)",
        page_icon="ğŸ“š",
        layout="wide"
    )
    
    st.title("ğŸ“š æ™ºèƒ½çŸ¥è¯†åº“ç³»ç»Ÿ (DeepSeekç‰ˆ)")
    st.markdown("---")
    
    # åˆå§‹åŒ–session state
    if 'docs' not in st.session_state:
        st.session_state.docs = {}
    if 'vectorstore' not in st.session_state:
        st.session_state.vectorstore = None
    if 'selected_file' not in st.session_state:
        st.session_state.selected_file = None
    if 'chat_history' not in st.session_state:
        st.session_state.chat_history = []
    if 'api_key_loaded' not in st.session_state:
        st.session_state.api_key_loaded = False
    if 'is_creating_vectorstore' not in st.session_state:
        st.session_state.is_creating_vectorstore = False
    if 'embedding_model' not in st.session_state:
        st.session_state.embedding_model = load_embedding_model_config()
    
    # ä¾§è¾¹æ 
    with st.sidebar:
        st.header("âš™ï¸ é…ç½®")
        
        # DeepSeek APIé…ç½®
        st.subheader("ğŸ”‘ DeepSeek APIè®¾ç½®")
        
        # å°è¯•ä»æœ¬åœ°åŠ è½½ API key
        saved_api_key = None
        if not st.session_state.api_key_loaded:
            saved_api_key = load_api_key()
            if saved_api_key:
                st.session_state.api_key_loaded = True
                st.session_state.saved_api_key = saved_api_key
                st.success("âœ… å·²ä»æœ¬åœ°åŠ è½½ API å¯†é’¥")
        
        # ä½¿ç”¨ä¿å­˜çš„ key æˆ–ç”¨æˆ·è¾“å…¥
        default_key = st.session_state.get('saved_api_key', '') if st.session_state.api_key_loaded else ''
        api_key_input = st.text_input(
            "DeepSeek APIå¯†é’¥", 
            value=default_key,
            type="password", 
            help="åœ¨ https://platform.deepseek.com/ è·å–APIå¯†é’¥\nğŸ’¾ å¯†é’¥ä¼šè‡ªåŠ¨ä¿å­˜åˆ°æœ¬åœ°ï¼Œä¸‹æ¬¡å¯åŠ¨æ— éœ€é‡æ–°è¾“å…¥"
        )
        
        # API key ç®¡ç†æŒ‰é’®
        col_key1, col_key2 = st.columns(2)
        with col_key1:
            if st.button("ğŸ’¾ ä¿å­˜å¯†é’¥", use_container_width=True):
                if api_key_input:
                    if save_api_key(api_key_input):
                        st.session_state.saved_api_key = api_key_input
                        st.session_state.api_key_loaded = True
                        st.success("âœ… API å¯†é’¥å·²ä¿å­˜åˆ°æœ¬åœ°")
                        st.rerun()
                else:
                    st.warning("è¯·è¾“å…¥ API å¯†é’¥")
        
        with col_key2:
            if st.button("ğŸ—‘ï¸ æ¸…é™¤å¯†é’¥", use_container_width=True):
                if delete_api_key():
                    st.session_state.saved_api_key = ""
                    st.session_state.api_key_loaded = False
                    st.success("âœ… å·²æ¸…é™¤æœ¬åœ°ä¿å­˜çš„ API å¯†é’¥")
                    st.rerun()
        
        # è‡ªåŠ¨ä¿å­˜é€»è¾‘ï¼šå¦‚æœç”¨æˆ·è¾“å…¥äº†æ–°å¯†é’¥ä¸”ä¸ä¿å­˜çš„ä¸åŒï¼Œè‡ªåŠ¨ä¿å­˜
        if api_key_input and api_key_input != st.session_state.get('saved_api_key', ''):
            # ç”¨æˆ·è¾“å…¥äº†æ–°å¯†é’¥ï¼Œè‡ªåŠ¨ä¿å­˜ï¼ˆä»…åœ¨é¦–æ¬¡è¾“å…¥æ—¶ï¼Œé™é»˜ä¿å­˜ï¼‰
            if not st.session_state.api_key_loaded or api_key_input != saved_api_key:
                if save_api_key(api_key_input, show_error=False):
                    st.session_state.saved_api_key = api_key_input
                    st.session_state.api_key_loaded = True
                    # é™é»˜ä¿å­˜ï¼Œä¸æ˜¾ç¤ºæç¤ºï¼ˆé¿å…é¢‘ç¹åˆ·æ–°ï¼‰
        
        # ä½¿ç”¨è¾“å…¥çš„ keyï¼ˆä¼˜å…ˆä½¿ç”¨æ–°è¾“å…¥çš„ï¼‰
        api_key = api_key_input if api_key_input else (st.session_state.get('saved_api_key', '') if st.session_state.api_key_loaded else '')
        
        # æ˜¾ç¤ºä¿å­˜çŠ¶æ€
        if os.path.exists(CONFIG_FILE):
            saved_time = ""
            try:
                with open(CONFIG_FILE, 'r', encoding='utf-8') as f:
                    config = json.load(f)
                    saved_time = config.get("saved_at", "")
            except:
                pass
            if saved_time:
                st.caption(f"ğŸ’¾ å¯†é’¥å·²ä¿å­˜ï¼ˆ{saved_time}ï¼‰")
            else:
                st.caption("ğŸ’¾ å¯†é’¥å·²ä¿å­˜åˆ°æœ¬åœ°")
        else:
            st.caption("ğŸ’¡ è¾“å…¥å¯†é’¥åä¼šè‡ªåŠ¨ä¿å­˜åˆ°æœ¬åœ°")
        
        # æ¨¡å‹é€‰æ‹©
        model_choice = st.selectbox(
            "é€‰æ‹©æ¨¡å‹",
            ["deepseek-chat", "deepseek-coder"],
            help="deepseek-chat: é€šç”¨å¯¹è¯æ¨¡å‹\ndeepseek-coder: ä»£ç ä¸“ç”¨æ¨¡å‹"
        )
        
        # API è¶…æ—¶å’Œé‡è¯•é…ç½®ï¼ˆé«˜çº§è®¾ç½®ï¼‰
        if 'api_timeout' not in st.session_state:
            st.session_state.api_timeout = 60
        if 'api_max_retries' not in st.session_state:
            st.session_state.api_max_retries = 3
        
        # API è¶…æ—¶å’Œé‡è¯•é…ç½®ï¼ˆé«˜çº§è®¾ç½®ï¼‰
        with st.expander("âš™ï¸ é«˜çº§è®¾ç½®ï¼ˆç½‘ç»œé—®é¢˜æ—¶å¯è°ƒæ•´ï¼‰", expanded=False):
            timeout_seconds = st.slider(
                "è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰",
                min_value=30,
                max_value=180,
                value=st.session_state.api_timeout,
                step=10,
                help="å¦‚æœç»å¸¸è¶…æ—¶ï¼Œå¯ä»¥å¢åŠ æ­¤å€¼"
            )
            max_retries = st.slider(
                "æœ€å¤§é‡è¯•æ¬¡æ•°",
                min_value=1,
                max_value=5,
                value=st.session_state.api_max_retries,
                step=1,
                help="ç½‘ç»œä¸ç¨³å®šæ—¶å¯ä»¥å¢åŠ é‡è¯•æ¬¡æ•°"
            )
            
            # ä¿å­˜åˆ° session state
            st.session_state.api_timeout = timeout_seconds
            st.session_state.api_max_retries = max_retries
        
        st.markdown("---")
        
        # åµŒå…¥æ¨¡å‹é…ç½®
        st.subheader("ğŸ¤– åµŒå…¥æ¨¡å‹è®¾ç½®")
        
        # åˆå§‹åŒ–åµŒå…¥æ¨¡å‹é…ç½®
        if 'embedding_model' not in st.session_state:
            st.session_state.embedding_model = load_embedding_model_config()
        
        # å¯ç”¨çš„åµŒå…¥æ¨¡å‹åˆ—è¡¨
        embedding_models = {
            "BAAI/bge-small-zh-v1.5": {
                "name": "bge-small-zh-v1.5",
                "description": "è½»é‡å¿«é€Ÿï¼ˆ384ç»´ï¼Œ~130MBï¼‰",
                "size": "~130MB",
                "performance": "â­â­â­"
            },
            "BAAI/bge-base-zh-v1.5": {
                "name": "bge-base-zh-v1.5",
                "description": "å¹³è¡¡æ€§èƒ½ï¼ˆ768ç»´ï¼Œ~420MBï¼‰",
                "size": "~420MB",
                "performance": "â­â­â­â­"
            },
            "BAAI/bge-large-zh-v1.5": {
                "name": "bge-large-zh-v1.5",
                "description": "æœ€ä½³æ€§èƒ½ï¼ˆ1024ç»´ï¼Œ~1.2GBï¼‰",
                "size": "~1.2GB",
                "performance": "â­â­â­â­â­"
            }
        }
        
        # æ¨¡å‹é€‰æ‹©ä¸‹æ‹‰æ¡†
        model_options = [f"{info['name']} - {info['description']}" for model_id, info in embedding_models.items()]
        current_model_index = 0
        for idx, (model_id, info) in enumerate(embedding_models.items()):
            if model_id == st.session_state.embedding_model:
                current_model_index = idx
                break
        
        selected_model_display = st.selectbox(
            "é€‰æ‹©åµŒå…¥æ¨¡å‹",
            options=model_options,
            index=current_model_index,
            help="ç”¨äºæ–‡æ¡£å‘é‡åŒ–çš„æ¨¡å‹ã€‚æ›´å¤§çš„æ¨¡å‹æ€§èƒ½æ›´å¥½ï¼Œä½†éœ€è¦æ›´å¤šå†…å­˜å’Œå­˜å‚¨ç©ºé—´ã€‚"
        )
        
        # è·å–é€‰ä¸­çš„æ¨¡å‹ID
        selected_model_id = list(embedding_models.keys())[model_options.index(selected_model_display)]
        
        # æ˜¾ç¤ºå½“å‰æ¨¡å‹ä¿¡æ¯
        current_model_info = embedding_models[selected_model_id]
        st.caption(f"ğŸ“Š æ€§èƒ½: {current_model_info['performance']} | ğŸ’¾ å¤§å°: {current_model_info['size']}")
        
        # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²ä¸‹è½½
        model_path = get_model_path(selected_model_id)
        # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å­˜åœ¨ï¼ˆæœ¬åœ°è·¯å¾„æˆ–HuggingFaceç¼“å­˜ï¼‰
        cache_dir = os.path.join(os.path.expanduser("~"), ".cache", "huggingface", "hub")
        cache_model_name = f"models--{selected_model_id.replace('/', '--')}"
        cache_path = os.path.join(cache_dir, cache_model_name)
        
        # åˆ¤æ–­æ¨¡å‹æ˜¯å¦å­˜åœ¨
        model_exists = (
            (os.path.exists(model_path) and os.path.isdir(model_path)) or  # æœ¬åœ°è·¯å¾„å­˜åœ¨
            os.path.exists(cache_path)  # HuggingFaceç¼“å­˜å­˜åœ¨
        )
        
        # å¦‚æœæ¨¡å‹ä¸å­˜åœ¨ï¼Œæ˜¾ç¤ºä¸‹è½½é€‰é¡¹
        if not model_exists and selected_model_id != "BAAI/bge-small-zh-v1.5":
            if not os.path.exists(cache_path):
                with st.expander("ğŸ“¥ ä¸‹è½½æ¨¡å‹", expanded=False):
                    st.info(f"æ¨¡å‹ {selected_model_id} å°šæœªä¸‹è½½ï¼Œé¦–æ¬¡ä½¿ç”¨éœ€è¦ä¸‹è½½ã€‚")
                    if st.button(f"â¬‡ï¸ ä¸‹è½½ {current_model_info['name']}", use_container_width=True, key=f"download_{selected_model_id}"):
                        progress_bar = st.progress(0)
                        status_text = st.empty()
                        
                        success = download_model(
                            selected_model_id,
                            progress_callback=lambda p, msg: (
                                progress_bar.progress(p / 100.0),
                                status_text.text(msg)
                            )
                        )
                        
                        if success:
                            st.success(f"âœ… æ¨¡å‹ {current_model_info['name']} ä¸‹è½½å®Œæˆï¼")
                            st.info("ğŸ’¡ è¯·åˆ·æ–°é¡µé¢åä½¿ç”¨æ–°æ¨¡å‹")
                        else:
                            st.error("âŒ ä¸‹è½½å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥")
                        
                        import time
                        time.sleep(1)
                        progress_bar.empty()
                        status_text.empty()
            else:
                st.success(f"âœ… æ¨¡å‹ {current_model_info['name']} å·²ä¸‹è½½")
        
        # ä¿å­˜æ¨¡å‹é€‰æ‹©
        if selected_model_id != st.session_state.embedding_model:
            # æ£€æŸ¥æ˜¯å¦æœ‰ç°æœ‰çš„å‘é‡æ•°æ®åº“
            has_existing_db = False
            if os.path.exists("./chroma_db"):
                try:
                    db_dirs = [d for d in os.listdir("./chroma_db") 
                              if os.path.isdir(os.path.join("./chroma_db", d))]
                    has_existing_db = len(db_dirs) > 0
                except:
                    pass
            
            if save_embedding_model_config(selected_model_id):
                st.session_state.embedding_model = selected_model_id
                st.success(f"âœ… å·²åˆ‡æ¢åˆ° {current_model_info['name']}")
                
                if has_existing_db:
                    st.warning("âš ï¸ **é‡è¦æç¤º**ï¼šåˆ‡æ¢æ¨¡å‹åï¼Œç°æœ‰çš„å‘é‡æ•°æ®åº“å°†æ— æ³•ä½¿ç”¨ï¼ˆç»´åº¦ä¸åŒ¹é…ï¼‰")
                    st.info("ğŸ’¡ **æ“ä½œå»ºè®®**ï¼š\n"
                           "1. åˆ‡æ¢æ¨¡å‹åï¼Œç³»ç»Ÿä¼šåœ¨ä¸‹æ¬¡åˆ›å»ºå‘é‡æ•°æ®åº“æ—¶è‡ªåŠ¨æ¸…ç†æ—§æ•°æ®åº“\n"
                           "2. æˆ–è€…æ‰‹åŠ¨åˆ é™¤å‘é‡æ•°æ®åº“ï¼šåœ¨ä¾§è¾¹æ çš„'å‘é‡æ•°æ®åº“ç®¡ç†'ä¸­åˆ é™¤\n"
                           "3. ç„¶åé‡æ–°åŠ è½½æ–‡ä»¶å¤¹æˆ–ä¸Šä¼ æ–‡ä»¶ï¼Œç³»ç»Ÿä¼šä½¿ç”¨æ–°æ¨¡å‹é‡æ–°åˆ›å»ºå‘é‡æ•°æ®åº“")
                else:
                    st.info("ğŸ’¡ åˆ‡æ¢æ¨¡å‹åï¼Œä¸‹æ¬¡åˆ›å»ºå‘é‡æ•°æ®åº“æ—¶å°†ä½¿ç”¨æ–°æ¨¡å‹")
                st.rerun()
        
        st.markdown("---")
        st.header("ğŸ“ æ–‡ä»¶ç®¡ç†")
        
        # æ–‡ä»¶å¤¹é€‰æ‹©
        folder_path = st.text_input("æ–‡ä»¶å¤¹è·¯å¾„", placeholder="è¾“å…¥æ–‡ä»¶å¤¹è·¯å¾„ï¼Œå¦‚: ./documents")
        
        # åœ¨åˆ—å¸ƒå±€å¤–åˆ›å»ºå ä½ç¬¦ï¼Œç¡®ä¿ä¸è¾“å…¥æ¡†ç­‰å®½
        info_placeholder = st.empty()
        progress_placeholder = st.empty()
        status_placeholder = st.empty()
        success_placeholder = st.empty()  # ç”¨äºæ˜¾ç¤ºæˆåŠŸæ¶ˆæ¯ï¼Œç¡®ä¿ç­‰å®½
        error_placeholder = st.empty()  # ç”¨äºæ˜¾ç¤ºé”™è¯¯æ¶ˆæ¯ï¼Œç¡®ä¿ç­‰å®½
        
        col1, col2 = st.columns(2)
        with col1:
            # æ£€æŸ¥æ˜¯å¦æ­£åœ¨åˆ›å»ºå‘é‡æ•°æ®åº“
            is_creating_vectorstore = st.session_state.get('is_creating_vectorstore', False)
            
            if st.button("ğŸ“‚ åŠ è½½æ–‡ä»¶å¤¹", use_container_width=True, disabled=is_creating_vectorstore):
                if folder_path and os.path.exists(folder_path) and os.path.isdir(folder_path):
                    with st.spinner("æ­£åœ¨è¯»å–æ–‡ä»¶..."):
                        st.session_state.docs = process_folder(folder_path)
                        # ä¿å­˜å½“å‰æ–‡ä»¶å¤¹è·¯å¾„
                        st.session_state.current_folder_path = folder_path
                    
                    # æ˜¾ç¤ºå·²åŠ è½½æ–‡ä»¶ä¿¡æ¯ï¼ˆåœ¨åˆ—å¸ƒå±€å¤–ï¼Œç¡®ä¿ä¸è¾“å…¥æ¡†ç­‰å®½ï¼‰
                    if st.session_state.docs:
                        info_placeholder.info(f"ğŸ“„ å·²åŠ è½½ {len(st.session_state.docs)} ä¸ªæ–‡ä»¶")
                    
                    # æ£€æŸ¥å¹¶åŠ è½½/åˆ›å»ºå‘é‡æ•°æ®åº“
                    if st.session_state.docs:
                        st.session_state.is_creating_vectorstore = True
                        # è¿›åº¦æ¡å’ŒçŠ¶æ€æ–‡æœ¬ï¼ˆåœ¨åˆ—å¸ƒå±€å¤–ï¼Œç¡®ä¿ä¸è¾“å…¥æ¡†ç­‰å®½ï¼‰
                        progress_bar = progress_placeholder.progress(0)
                        status_text = status_placeholder.empty()
                        
                        try:
                            # é¦–å…ˆå°è¯•åŠ è½½å·²æœ‰å‘é‡æ•°æ®åº“
                            status_text.text("ğŸ”„ æ­£åœ¨æ£€æŸ¥å·²æœ‰å‘é‡æ•°æ®åº“...")
                            progress_bar.progress(0.05)
                            
                            existing_vectorstore = load_existing_vector_store(
                                folder_path=folder_path,
                                progress_callback=lambda p, msg: (
                                    progress_bar.progress(p / 100.0),
                                    status_text.text(msg)
                                )
                            )
                            
                            # æ£€æŸ¥æ–‡æ¡£æ˜¯å¦å˜åŒ–
                            docs_changed = check_docs_changed(st.session_state.docs, folder_path)
                            
                            # æ ¹æ®æ–‡æ¡£å˜åŒ–å’Œæ•°æ®åº“åŠ è½½æƒ…å†µå†³å®šæ“ä½œ
                            if not docs_changed:
                                # æ–‡æ¡£æœªå˜åŒ–
                                if existing_vectorstore:
                                    # æ•°æ®åº“å¯ç”¨ï¼Œä½¿ç”¨å·²æœ‰å‘é‡æ•°æ®åº“
                                    st.session_state.vectorstore = existing_vectorstore
                                    progress_bar.progress(1.0)
                                    status_text.text("âœ… å·²åŠ è½½å·²æœ‰å‘é‡æ•°æ®åº“ï¼")
                                    success_placeholder.success("âœ… å·²åŠ è½½å·²æœ‰å‘é‡æ•°æ®åº“ï¼ˆæ–‡æ¡£æœªå˜åŒ–ï¼‰")
                                else:
                                    # æ–‡æ¡£æœªå˜åŒ–ä½†æ•°æ®åº“æ— æ³•åŠ è½½ï¼ˆå¯èƒ½æŸåï¼‰
                                    # ä¸è‡ªåŠ¨é‡æ–°åˆ›å»ºï¼Œæç¤ºç”¨æˆ·
                                    progress_bar.progress(1.0)
                                    status_text.text("âš ï¸ æ–‡æ¡£æœªå˜åŒ–ï¼Œä½†å‘é‡æ•°æ®åº“æ— æ³•åŠ è½½")
                                    warning_msg = (
                                        "âš ï¸ **æ–‡æ¡£æœªå˜åŒ–ï¼Œä½†å‘é‡æ•°æ®åº“æ— æ³•åŠ è½½**\n\n"
                                        "å¯èƒ½çš„åŸå› ï¼š\n"
                                        "- å‘é‡æ•°æ®åº“æ–‡ä»¶æŸå\n"
                                        "- æ•°æ®åº“ç‰ˆæœ¬ä¸å…¼å®¹\n\n"
                                        "**å»ºè®®**ï¼š\n"
                                        "- å¦‚æœæ•°æ®åº“æŸåï¼Œå¯ä»¥æ‰‹åŠ¨åˆ é™¤æ•°æ®åº“ç›®å½•åé‡æ–°åˆ›å»º\n"
                                        "- æˆ–è€…ç‚¹å‡»'é‡æ–°åŠ è½½'æŒ‰é’®å¼ºåˆ¶é‡æ–°åˆ›å»º"
                                    )
                                    error_placeholder.warning(warning_msg)
                                    st.session_state.vectorstore = None
                            else:
                                # æ–‡æ¡£å·²å˜åŒ–ï¼Œéœ€è¦é‡æ–°åˆ›å»º
                                if existing_vectorstore:
                                    status_text.text("ğŸ“ æ£€æµ‹åˆ°æ–‡æ¡£å˜åŒ–ï¼Œæ­£åœ¨é‡æ–°åˆ›å»ºå‘é‡æ•°æ®åº“...")
                                    progress_bar.progress(0.01)
                                
                                # ç›´æ¥è°ƒç”¨ create_local_vector_storeï¼Œè®©å®ƒè‡ªå·±ç®¡ç†æ‰€æœ‰è¿›åº¦æ›´æ–°
                                try:
                                    st.session_state.vectorstore = create_local_vector_store(
                                        st.session_state.docs,
                                        folder_path=folder_path,
                                        progress_callback=lambda p, msg: (
                                            progress_bar.progress(p / 100.0),
                                            status_text.text(msg)
                                        )
                                    )
                                    
                                    if st.session_state.vectorstore:
                                        progress_bar.progress(1.0)
                                        status_text.text("âœ… å‘é‡æ•°æ®åº“åˆ›å»ºå®Œæˆï¼")
                                        success_placeholder.success("âœ… å‘é‡æ•°æ®åº“åˆ›å»ºå®Œæˆï¼")
                                        error_placeholder.empty()  # æ¸…ç©ºé”™è¯¯æç¤º
                                    else:
                                        progress_placeholder.empty()
                                        status_placeholder.empty()
                                        # å¦‚æœåˆ›å»ºå¤±è´¥ï¼Œå·²ç»åœ¨ create_local_vector_store ä¸­æ˜¾ç¤ºäº†è­¦å‘Š
                                except Exception as create_error:
                                    # æ•è·å¼‚å¸¸ï¼Œä½¿ç”¨å ä½ç¬¦æ˜¾ç¤ºé”™è¯¯ï¼ˆç¡®ä¿ç­‰å®½ï¼‰
                                    progress_placeholder.empty()
                                    status_placeholder.empty()
                                    error_type = type(create_error).__name__
                                    error_msg = str(create_error)
                                    error_placeholder.error(f"âš ï¸ **å‘é‡æ•°æ®åº“åˆ›å»ºå¤±è´¥**\n\n"
                                                          f"**é”™è¯¯ç±»å‹**: `{error_type}`\n\n"
                                                          f"**é”™è¯¯ä¿¡æ¯**: {error_msg}")
                                    st.session_state.vectorstore = None
                        finally:
                            st.session_state.is_creating_vectorstore = False
                            # æ¸…ç†è¿›åº¦æ¡
                            import time
                            time.sleep(0.5)
                            progress_placeholder.empty()
                            status_placeholder.empty()
                else:
                    st.error("è¯·è¾“å…¥æœ‰æ•ˆçš„æ–‡ä»¶å¤¹è·¯å¾„")
        
        with col2:
            if st.button("ğŸ”„ é‡æ–°åŠ è½½", use_container_width=True, disabled=is_creating_vectorstore):
                # è·å–å½“å‰æ–‡ä»¶å¤¹è·¯å¾„
                current_folder_path = st.session_state.get('current_folder_path', None)
                
                if current_folder_path and os.path.exists(current_folder_path) and os.path.isdir(current_folder_path):
                    # å¦‚æœæœ‰å½“å‰æ–‡ä»¶å¤¹è·¯å¾„ï¼Œé‡æ–°åŠ è½½å¹¶å¼ºåˆ¶é‡æ–°åˆ›å»ºå‘é‡æ•°æ®åº“
                    st.session_state.is_creating_vectorstore = True
                    progress_bar = progress_placeholder.progress(0)
                    status_text = status_placeholder.empty()
                    
                    try:
                        # é‡æ–°è¯»å–æ–‡ä»¶
                        with st.spinner("æ­£åœ¨é‡æ–°è¯»å–æ–‡ä»¶..."):
                            st.session_state.docs = process_folder(current_folder_path)
                        
                        if st.session_state.docs:
                            info_placeholder.info(f"ğŸ“„ å·²åŠ è½½ {len(st.session_state.docs)} ä¸ªæ–‡ä»¶")
                            
                            # å¼ºåˆ¶é‡æ–°åˆ›å»ºå‘é‡æ•°æ®åº“ï¼ˆå³ä½¿æ–‡æ¡£æœªå˜åŒ–ï¼‰
                            status_text.text("ğŸ”„ æ­£åœ¨å¼ºåˆ¶é‡æ–°åˆ›å»ºå‘é‡æ•°æ®åº“...")
                            progress_bar.progress(0.01)
                            
                            # åˆ é™¤æ—§çš„æ•°æ®åº“ç›®å½•ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                            db_path = get_vector_db_path(current_folder_path)
                            if os.path.exists(db_path):
                                try:
                                    import shutil
                                    shutil.rmtree(db_path)
                                    print(f"[INFO] å·²åˆ é™¤æ—§æ•°æ®åº“ç›®å½•: {db_path}")
                                except Exception as e:
                                    print(f"[WARN] åˆ é™¤æ—§æ•°æ®åº“ç›®å½•å¤±è´¥: {str(e)}")
                            
                            # åˆ›å»ºæ–°çš„å‘é‡æ•°æ®åº“
                            try:
                                st.session_state.vectorstore = create_local_vector_store(
                                    st.session_state.docs,
                                    folder_path=current_folder_path,
                                    progress_callback=lambda p, msg: (
                                        progress_bar.progress(p / 100.0),
                                        status_text.text(msg)
                                    )
                                )
                                
                                if st.session_state.vectorstore:
                                    progress_bar.progress(1.0)
                                    status_text.text("âœ… å‘é‡æ•°æ®åº“é‡æ–°åˆ›å»ºå®Œæˆï¼")
                                    success_placeholder.success("âœ… å‘é‡æ•°æ®åº“é‡æ–°åˆ›å»ºå®Œæˆï¼")
                                    error_placeholder.empty()
                                else:
                                    progress_placeholder.empty()
                                    status_placeholder.empty()
                                    error_placeholder.error("âŒ å‘é‡æ•°æ®åº“åˆ›å»ºå¤±è´¥")
                            except Exception as create_error:
                                progress_placeholder.empty()
                                status_placeholder.empty()
                                error_type = type(create_error).__name__
                                error_msg = str(create_error)
                                error_placeholder.error(f"âš ï¸ **å‘é‡æ•°æ®åº“åˆ›å»ºå¤±è´¥**\n\n"
                                                      f"**é”™è¯¯ç±»å‹**: `{error_type}`\n\n"
                                                      f"**é”™è¯¯ä¿¡æ¯**: {error_msg}")
                                st.session_state.vectorstore = None
                    finally:
                        st.session_state.is_creating_vectorstore = False
                        import time
                        time.sleep(0.5)
                        progress_placeholder.empty()
                        status_placeholder.empty()
                else:
                    # å¦‚æœæ²¡æœ‰å½“å‰æ–‡ä»¶å¤¹è·¯å¾„ï¼Œåªæ¸…ç©ºçŠ¶æ€
                    st.session_state.docs = {}
                    st.session_state.vectorstore = None
                    st.session_state.is_creating_vectorstore = False
                    info_placeholder.empty()
                    progress_placeholder.empty()
                    status_placeholder.empty()
                    success_placeholder.empty()
                    error_placeholder.empty()
                    st.rerun()
        
        # å¦‚æœä¸åœ¨åˆ›å»ºè¿‡ç¨‹ä¸­ï¼Œæ˜¾ç¤ºå·²åŠ è½½æ–‡ä»¶ä¿¡æ¯
        if st.session_state.get('docs') and not is_creating_vectorstore:
            info_placeholder.info(f"ğŸ“„ å·²åŠ è½½ {len(st.session_state.docs)} ä¸ªæ–‡ä»¶")
        
        # æ–‡ä»¶ä¸Šä¼ 
        st.subheader("æˆ–ä¸Šä¼ æ–‡ä»¶")
        uploaded_files = st.file_uploader(
            "é€‰æ‹©æ–‡ä»¶",
            type=['txt', 'docx', 'pdf', 'xlsx', 'xls', 'md', 'js', 'json'],
            accept_multiple_files=True,
            label_visibility="collapsed"
        )
        
        # åœ¨æ–‡ä»¶ä¸Šä¼ åŒºåŸŸåˆ›å»ºå ä½ç¬¦ï¼Œç¡®ä¿ä¸ä¸Šä¼ ç»„ä»¶ç­‰å®½
        upload_info_placeholder = st.empty()
        upload_progress_placeholder = st.empty()
        upload_status_placeholder = st.empty()
        upload_success_placeholder = st.empty()  # ç”¨äºæ˜¾ç¤ºæˆåŠŸæ¶ˆæ¯ï¼Œç¡®ä¿ç­‰å®½
        upload_error_placeholder = st.empty()  # ç”¨äºæ˜¾ç¤ºé”™è¯¯æ¶ˆæ¯ï¼Œç¡®ä¿ç­‰å®½
        
        if uploaded_files and st.button("ä¸Šä¼ æ–‡ä»¶"):
            temp_dir = tempfile.mkdtemp()
            for uploaded_file in uploaded_files:
                file_path = os.path.join(temp_dir, uploaded_file.name)
                with open(file_path, "wb") as f:
                    f.write(uploaded_file.getbuffer())
                
                # è¯»å–æ–‡ä»¶
                filename = uploaded_file.name
                file_ext = filename.split('.')[-1].lower()
                
                try:
                    if file_ext == 'txt':
                        content = read_text_file(file_path)
                    elif file_ext == 'docx':
                        content = read_docx_file(file_path)
                    elif file_ext == 'pdf':
                        content = read_pdf_file(file_path)
                    elif file_ext in ['xlsx', 'xls']:
                        content = read_excel_file(file_path)
                    elif file_ext == 'md':
                        content = read_markdown_file(file_path)
                    elif file_ext == 'js':
                        content = read_javascript_file(file_path)
                    elif file_ext == 'json':
                        content = read_json_file(file_path)
                    else:
                        content = f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {file_ext}"
                    
                    st.session_state.docs[filename] = {
                        'path': file_path,
                        'content': content,
                        'type': file_ext,
                        'size': uploaded_file.size
                    }
                except Exception as e:
                    st.error(f"è¯»å–æ–‡ä»¶ {filename} å¤±è´¥: {str(e)}")
            
            # æ˜¾ç¤ºå·²ä¸Šä¼ æ–‡ä»¶ä¿¡æ¯ï¼ˆåœ¨å ä½ç¬¦ä¸­ï¼Œç¡®ä¿ä¸ä¸Šä¼ ç»„ä»¶ç­‰å®½ï¼‰
            if uploaded_files:
                upload_info_placeholder.info(f"ğŸ“„ å·²ä¸Šä¼  {len(uploaded_files)} ä¸ªæ–‡ä»¶")
            
            # æ£€æŸ¥å¹¶åŠ è½½/åˆ›å»ºå‘é‡æ•°æ®åº“ï¼ˆä¸Šä¼ æ–‡ä»¶æ—¶ folder_path ä¸º Noneï¼‰
            if st.session_state.docs:
                st.session_state.is_creating_vectorstore = True
                # è¿›åº¦æ¡å’ŒçŠ¶æ€æ–‡æœ¬ï¼ˆåœ¨å ä½ç¬¦ä¸­ï¼Œç¡®ä¿ä¸ä¸Šä¼ ç»„ä»¶ç­‰å®½ï¼‰
                progress_bar = upload_progress_placeholder.progress(0)
                status_text = upload_status_placeholder.empty()
                
                try:
                    # é¦–å…ˆå°è¯•åŠ è½½å·²æœ‰å‘é‡æ•°æ®åº“
                    status_text.text("ğŸ”„ æ­£åœ¨æ£€æŸ¥å·²æœ‰å‘é‡æ•°æ®åº“...")
                    progress_bar.progress(0.05)
                    
                    existing_vectorstore = load_existing_vector_store(
                        folder_path=None,  # ä¸Šä¼ æ–‡ä»¶æ—¶æ²¡æœ‰æ–‡ä»¶å¤¹è·¯å¾„
                        progress_callback=lambda p, msg: (
                            progress_bar.progress(p / 100.0),
                            status_text.text(msg)
                        )
                    )
                    
                    # æ£€æŸ¥æ–‡æ¡£æ˜¯å¦å˜åŒ–
                    docs_changed = check_docs_changed(st.session_state.docs, None)
                    
                    # å¦‚æœ load_existing_vector_store è¿”å›äº† vectorstoreï¼Œè¯´æ˜æ•°æ®åº“å¯ç”¨
                    # ä¸éœ€è¦å†æ¬¡éªŒè¯ï¼Œé¿å…é‡å¤éªŒè¯å¯¼è‡´çš„é—®é¢˜
                    if existing_vectorstore and not docs_changed:
                        # æ–‡æ¡£æœªå˜åŒ–ï¼Œä½¿ç”¨å·²æœ‰å‘é‡æ•°æ®åº“
                        st.session_state.vectorstore = existing_vectorstore
                        progress_bar.progress(1.0)
                        status_text.text("âœ… å·²åŠ è½½å·²æœ‰å‘é‡æ•°æ®åº“ï¼")
                        upload_success_placeholder.success("âœ… å·²åŠ è½½å·²æœ‰å‘é‡æ•°æ®åº“ï¼ˆæ–‡æ¡£æœªå˜åŒ–ï¼‰")
                    else:
                        # æ–‡æ¡£å˜åŒ–æˆ–ä¸å­˜åœ¨ï¼Œéœ€è¦é‡æ–°åˆ›å»º
                        # ç§»é™¤æ‰€æœ‰ç¡¬ç¼–ç çš„è¿›åº¦æ›´æ–°ï¼Œè®© create_local_vector_store å®Œå…¨æ§åˆ¶è¿›åº¦
                        if existing_vectorstore and docs_changed:
                            status_text.text("ğŸ“ æ£€æµ‹åˆ°æ–‡æ¡£å˜åŒ–ï¼Œæ­£åœ¨é‡æ–°åˆ›å»ºå‘é‡æ•°æ®åº“...")
                            progress_bar.progress(0.01)
                        
                        # ç›´æ¥è°ƒç”¨ create_local_vector_storeï¼Œè®©å®ƒè‡ªå·±ç®¡ç†æ‰€æœ‰è¿›åº¦æ›´æ–°
                        try:
                            st.session_state.vectorstore = create_local_vector_store(
                                st.session_state.docs,
                                folder_path=None,  # ä¸Šä¼ æ–‡ä»¶æ—¶æ²¡æœ‰æ–‡ä»¶å¤¹è·¯å¾„
                                progress_callback=lambda p, msg: (
                                    progress_bar.progress(p / 100.0),
                                    status_text.text(msg)
                                )
                            )
                            
                            if st.session_state.vectorstore:
                                progress_bar.progress(1.0)
                                status_text.text("âœ… å‘é‡æ•°æ®åº“æ›´æ–°å®Œæˆï¼")
                                upload_success_placeholder.success("âœ… å‘é‡æ•°æ®åº“æ›´æ–°å®Œæˆï¼")
                                upload_error_placeholder.empty()  # æ¸…ç©ºé”™è¯¯æç¤º
                            else:
                                upload_progress_placeholder.empty()
                                upload_status_placeholder.empty()
                        except Exception as create_error:
                            # æ•è·å¼‚å¸¸ï¼Œä½¿ç”¨å ä½ç¬¦æ˜¾ç¤ºé”™è¯¯ï¼ˆç¡®ä¿ç­‰å®½ï¼‰
                            upload_progress_placeholder.empty()
                            upload_status_placeholder.empty()
                            error_msg = str(create_error)
                            upload_error_placeholder.error(error_msg)
                            st.session_state.vectorstore = None
                finally:
                    st.session_state.is_creating_vectorstore = False
                    import time
                    time.sleep(0.5)
                    upload_progress_placeholder.empty()
                    upload_status_placeholder.empty()
        
        # å¦‚æœä¸åœ¨åˆ›å»ºè¿‡ç¨‹ä¸­ï¼Œæ˜¾ç¤ºå·²ä¸Šä¼ æ–‡ä»¶ä¿¡æ¯
        if st.session_state.get('docs') and not st.session_state.get('is_creating_vectorstore', False) and uploaded_files:
            upload_info_placeholder.info(f"ğŸ“„ å·²ä¸Šä¼  {len(uploaded_files)} ä¸ªæ–‡ä»¶")
        
        # å¦‚æœä¸åœ¨åˆ›å»ºè¿‡ç¨‹ä¸­ï¼Œæ˜¾ç¤ºå·²ä¸Šä¼ æ–‡ä»¶ä¿¡æ¯
        if st.session_state.get('docs') and not st.session_state.get('is_creating_vectorstore', False) and uploaded_files:
            upload_info_placeholder.info(f"ğŸ“„ å·²ä¸Šä¼  {len(uploaded_files)} ä¸ªæ–‡ä»¶")
        
        # æ–‡ä»¶ç»Ÿè®¡
        if st.session_state.docs:
            st.markdown("---")
            st.header("ğŸ“Š ç»Ÿè®¡ä¿¡æ¯")
            total_files = len(st.session_state.docs)
            file_types = {}
            for data in st.session_state.docs.values():
                file_type = data['type']
                file_types[file_type] = file_types.get(file_type, 0) + 1
            
            st.write(f"**æ–‡ä»¶æ€»æ•°**: {total_files}")
            for ftype, count in file_types.items():
                st.write(f"**{ftype}æ–‡ä»¶**: {count}ä¸ª")
        
        st.markdown("---")
        
        # å‘é‡æ•°æ®åº“ç®¡ç†
        if st.session_state.docs:
            with st.expander("ğŸ—‘ï¸ å‘é‡æ•°æ®åº“ç®¡ç†", expanded=False):
                col_vdb1, col_vdb2 = st.columns(2)
                
                with col_vdb1:
                    # è·å–å½“å‰æ–‡ä»¶å¤¹çš„å‘é‡æ•°æ®åº“è·¯å¾„
                    current_folder_path = st.session_state.get('current_folder_path', None)
                    if current_folder_path:
                        current_db_path = get_vector_db_path(current_folder_path)
                        if st.button("ğŸ—‘ï¸ åˆ é™¤å½“å‰å‘é‡æ•°æ®åº“", use_container_width=True):
                            import shutil
                            if os.path.exists(current_db_path):
                                try:
                                    shutil.rmtree(current_db_path)
                                    st.session_state.vectorstore = None
                                    st.success("âœ… å½“å‰å‘é‡æ•°æ®åº“å·²åˆ é™¤")
                                    st.info("ğŸ’¡ ä¸‹æ¬¡åŠ è½½ç›¸åŒæ–‡ä»¶å¤¹æ—¶ä¼šè‡ªåŠ¨é‡æ–°åˆ›å»º")
                                except Exception as e:
                                    st.error(f"åˆ é™¤å¤±è´¥: {str(e)}")
                            else:
                                st.info("å½“å‰å‘é‡æ•°æ®åº“ä¸å­˜åœ¨")
                    else:
                        if st.button("ğŸ—‘ï¸ åˆ é™¤æ‰€æœ‰å‘é‡æ•°æ®åº“", use_container_width=True):
                            import shutil
                            if os.path.exists("./chroma_db"):
                                try:
                                    shutil.rmtree("./chroma_db")
                                    st.session_state.vectorstore = None
                                    st.success("âœ… æ‰€æœ‰å‘é‡æ•°æ®åº“å·²åˆ é™¤")
                                    st.info("ğŸ’¡ ä¸‹æ¬¡åŠ è½½æ–‡æ¡£æ—¶ä¼šè‡ªåŠ¨é‡æ–°åˆ›å»º")
                                except Exception as e:
                                    st.error(f"åˆ é™¤å¤±è´¥: {str(e)}")
                            else:
                                st.info("å‘é‡æ•°æ®åº“ä¸å­˜åœ¨")
                
                with col_vdb2:
                    # æ˜¾ç¤ºæ‰€æœ‰å‘é‡æ•°æ®åº“ä¿¡æ¯
                    if os.path.exists("./chroma_db"):
                        try:
                            import shutil
                            total_size = 0
                            db_count = 0
                            for item in os.listdir("./chroma_db"):
                                item_path = os.path.join("./chroma_db", item)
                                if os.path.isdir(item_path):
                                    db_count += 1
                                    total_size += sum(f.stat().st_size for f in Path(item_path).rglob('*') if f.is_file())
                            
                            size_mb = total_size / (1024 * 1024)
                            if db_count > 0:
                                st.caption(f"ğŸ’¾ å…± {db_count} ä¸ªå‘é‡æ•°æ®åº“")
                                st.caption(f"ğŸ’¾ æ€»å¤§å°: {size_mb:.2f} MB")
                            else:
                                st.caption("ğŸ’¾ å‘é‡æ•°æ®åº“å­˜åœ¨")
                        except:
                            st.caption("ğŸ’¾ å‘é‡æ•°æ®åº“å­˜åœ¨")
                    else:
                        st.caption("ğŸ’¾ æœªåˆ›å»ºå‘é‡æ•°æ®åº“")
                
                # æ˜¾ç¤º HuggingFace ç¼“å­˜ä¿¡æ¯
                hf_cache_path = os.path.join(os.path.expanduser("~"), ".cache", "huggingface")
                if os.path.exists(hf_cache_path):
                    try:
                        hf_size = sum(f.stat().st_size for f in Path(hf_cache_path).rglob('*') if f.is_file())
                        hf_size_gb = hf_size / (1024 * 1024 * 1024)
                        st.caption(f"ğŸ¤– HuggingFace æ¨¡å‹ç¼“å­˜: {hf_size_gb:.2f} GB")
                        st.caption(f"   ä½ç½®: {hf_cache_path}")
                        st.caption("   ğŸ’¡ å¦‚éœ€æ¸…ç†ï¼Œå¯æ‰‹åŠ¨åˆ é™¤è¯¥ç›®å½•")
                    except:
                        pass
        
        st.caption("ğŸ’¡ æç¤ºï¼šä½¿ç”¨æœ¬åœ°å‘é‡æ•°æ®åº“è¿›è¡Œè¯­ä¹‰æœç´¢ï¼Œæ— éœ€APIå¯†é’¥")
    
    # ä¸»ç•Œé¢
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.header("ğŸ“„ æ–‡æ¡£æµè§ˆå™¨")
        
        if st.session_state.docs:
            # æ–‡ä»¶åˆ—è¡¨
            files = list(st.session_state.docs.keys())
            selected_file = st.selectbox(
                "é€‰æ‹©æ–‡ä»¶æµè§ˆ",
                files,
                index=0,
                key="file_selector"
            )
            
            if selected_file:
                file_info = st.session_state.docs[selected_file]
                
                # æ–‡ä»¶ä¿¡æ¯å¡ç‰‡
                st.info(f"""
                **æ–‡ä»¶ä¿¡æ¯**
                - ç±»å‹: {file_info['type'].upper()}
                - å¤§å°: {file_info['size']:,} å­—èŠ‚
                """)
                
                # å†…å®¹æ˜¾ç¤º
                with st.expander("ğŸ“‹ æŸ¥çœ‹å†…å®¹", expanded=True):
                    content = file_info['content']
                    if isinstance(content, dict):  # Excelæ–‡ä»¶
                        tab_names = list(content.keys())
                        tabs = st.tabs(tab_names)
                        for i, (sheet_name, sheet_content) in enumerate(content.items()):
                            with tabs[i]:
                                st.text_area(
                                    f"{sheet_name} å·¥ä½œè¡¨",
                                    sheet_content,
                                    height=300,
                                    key=f"excel_{selected_file}_{i}"
                                )
                    else:
                        st.text_area(
                            "æ–‡ä»¶å†…å®¹",
                            content,
                            height=400,
                            key=f"content_{selected_file}"
                        )
        
        # æ‰¹é‡æ“ä½œ
        if st.session_state.docs:
            st.markdown("---")
            st.subheader("ğŸ“ˆ æ‰¹é‡æ€»ç»“")
            
            # æ–‡æ¡£é€‰æ‹©é€‰é¡¹
            summary_mode = st.radio(
                "é€‰æ‹©æ€»ç»“èŒƒå›´",
                ["ğŸ“š æ‰€æœ‰æ–‡æ¡£", "ğŸ“„ é€‰æ‹©ç‰¹å®šæ–‡æ¡£"],
                horizontal=True,
                help="é€‰æ‹©è¦æ€»ç»“çš„æ–‡æ¡£èŒƒå›´"
            )
            
            selected_files_for_summary = []
            if summary_mode == "ğŸ“„ é€‰æ‹©ç‰¹å®šæ–‡æ¡£":
                # å¤šé€‰æ–‡æ¡£
                file_options = list(st.session_state.docs.keys())
                selected_files_for_summary = st.multiselect(
                    "é€‰æ‹©è¦æ€»ç»“çš„æ–‡æ¡£ï¼ˆå¯å¤šé€‰ï¼‰",
                    options=file_options,
                    default=[],
                    help="é€‰æ‹©è¦åŒ…å«åœ¨æ€»ç»“æŠ¥å‘Šä¸­çš„æ–‡æ¡£"
                )
                
                if not selected_files_for_summary:
                    st.info("ğŸ’¡ è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªæ–‡æ¡£")
                    summary_button_disabled = True
                else:
                    summary_button_disabled = False
                    st.info(f"âœ… å·²é€‰æ‹© {len(selected_files_for_summary)} ä¸ªæ–‡æ¡£")
            else:
                summary_button_disabled = False
                st.info(f"ğŸ“š å°†æ€»ç»“æ‰€æœ‰ {len(st.session_state.docs)} ä¸ªæ–‡æ¡£")
            
            # Promptæ¨¡ç‰ˆé€‰æ‹©å’Œç®¡ç†
            # åŠ è½½æ¨¡ç‰ˆåˆ—è¡¨
            summary_templates = load_templates("summary")
            template_options = {f"{t['name']} ({tid})": tid for tid, t in summary_templates.items()}
            
            # åˆå§‹åŒ–session state
            if 'selected_summary_template' not in st.session_state:
                st.session_state.selected_summary_template = "default"
            
            col_template1, col_template1_btn, col_template2, col_template3 = st.columns([3, 1, 1, 1])
            with col_template1:
                selected_template_display = st.selectbox(
                    "é€‰æ‹©Promptæ¨¡ç‰ˆ",
                    options=list(template_options.keys()),
                    index=list(template_options.values()).index(st.session_state.selected_summary_template) if st.session_state.selected_summary_template in template_options.values() else 0,
                    help="é€‰æ‹©ç”¨äºç”Ÿæˆæ€»ç»“çš„Promptæ¨¡ç‰ˆ"
                )
                st.session_state.selected_summary_template = template_options[selected_template_display]
            
            with col_template1_btn:
                # åˆ·æ–°æŒ‰é’®
                st.markdown("<div style='height: 27px;'></div>", unsafe_allow_html=True)
                if st.button("ğŸ”„ åˆ·æ–°", use_container_width=True, key="refresh_summary_template_btn", help="åˆ·æ–°æ¨¡æ¿åˆ—è¡¨ä»¥è·å–æœ€æ–°æ¨¡æ¿"):
                    # é‡æ–°åŠ è½½æ¨¡æ¿
                    summary_templates = load_templates("summary")
                    template_options = {f"{t['name']} ({tid})": tid for tid, t in summary_templates.items()}
                    # å¦‚æœå½“å‰é€‰ä¸­çš„æ¨¡æ¿ä¸å­˜åœ¨ï¼Œé‡ç½®ä¸ºdefault
                    if st.session_state.selected_summary_template not in template_options.values():
                        st.session_state.selected_summary_template = "default"
                    st.rerun()
            
            with col_template2:
                # æ·»åŠ å ä½ç¬¦ä»¥å¯¹é½selectboxçš„labelå’Œhelp icon
                st.markdown("<div style='height: 27px;'></div>", unsafe_allow_html=True)
                if st.button("ğŸ‘ï¸ é¢„è§ˆ", use_container_width=True, key="preview_summary_template_btn"):
                    st.session_state.show_summary_template_preview = True
            
            with col_template3:
                # æ·»åŠ å ä½ç¬¦ä»¥å¯¹é½selectboxçš„labelå’Œhelp icon
                st.markdown("<div style='height: 27px;'></div>", unsafe_allow_html=True)
                # æ£€æŸ¥é€‰ä¸­çš„æ¨¡ç‰ˆæ˜¯å¦å¯ä»¥åˆ é™¤ï¼ˆé»˜è®¤æ¨¡ç‰ˆä¸å¯åˆ é™¤ï¼‰
                can_delete = not is_default_template("summary", st.session_state.selected_summary_template)
                if st.button("ğŸ—‘ï¸ åˆ é™¤", use_container_width=True, key="delete_summary_template_btn", disabled=not can_delete):
                    if delete_template("summary", st.session_state.selected_summary_template):
                        st.success("âœ… æ¨¡ç‰ˆå·²åˆ é™¤")
                        st.session_state.selected_summary_template = "default"
                        st.rerun()
            
            # æ¨¡ç‰ˆé¢„è§ˆ
            if st.session_state.get('show_summary_template_preview', False):
                template_data = get_template("summary", st.session_state.selected_summary_template)
                if template_data:
                    with st.expander("ğŸ“‹ æ¨¡ç‰ˆé¢„è§ˆ", expanded=True):
                        st.markdown(f"**æ¨¡ç‰ˆåç§°**: {template_data.get('name', '')}")
                        st.markdown(f"**æ¨¡ç‰ˆæè¿°**: {template_data.get('description', '')}")
                        st.markdown("**æ¨¡ç‰ˆå†…å®¹**:")
                        st.code(template_data.get('template', ''), language='text')
                        if st.button("å…³é—­é¢„è§ˆ", key="close_preview_summary"):
                            st.session_state.show_summary_template_preview = False
            
            # æ¨¡ç‰ˆç®¡ç†ï¼ˆä»…ä¿ç•™åˆ›å»º/ç¼–è¾‘åŠŸèƒ½ï¼‰
            with st.expander("âš™ï¸ æ¨¡ç‰ˆç®¡ç†", expanded=False):
                st.markdown("**åˆ›å»º/ç¼–è¾‘æ¨¡ç‰ˆ**")
                new_template_name = st.text_input("æ¨¡ç‰ˆåç§°", key="new_summary_template_name")
                new_template_desc = st.text_input("æ¨¡ç‰ˆæè¿°", key="new_summary_template_desc")
                new_template_content = st.text_area(
                    "æ¨¡ç‰ˆå†…å®¹ï¼ˆä½¿ç”¨ {content} ä½œä¸ºæ–‡æ¡£å†…å®¹å ä½ç¬¦ï¼‰",
                    height=200,
                    key="new_summary_template_content",
                    help="ç¤ºä¾‹ï¼šè¯·æ ¹æ®ä»¥ä¸‹æ–‡æ¡£å†…å®¹ï¼Œç”Ÿæˆæ€»ç»“ï¼š\n\næ–‡æ¡£å†…å®¹ï¼š\n{content}\n\næ€»ç»“ï¼š"
                )
                if st.button("ğŸ’¾ ä¿å­˜æ¨¡ç‰ˆ", key="save_summary_template"):
                    if new_template_name and new_template_content:
                        if save_template("summary", "", new_template_name, new_template_desc, new_template_content):
                            st.success("âœ… æ¨¡ç‰ˆå·²ä¿å­˜")
                            st.rerun()
                    else:
                        st.warning("è¯·è¾“å…¥æ¨¡ç‰ˆåç§°å’Œå†…å®¹")
            
            # ç”ŸæˆæŠ¥å‘ŠæŒ‰é’®
            generate_summary_clicked = st.button(
                "ç”ŸæˆçŸ¥è¯†åº“æ€»ç»“æŠ¥å‘Š", 
                use_container_width=True,
                disabled=summary_button_disabled if summary_mode == "ğŸ“„ é€‰æ‹©ç‰¹å®šæ–‡æ¡£" else False
            )
            
            # å¤„ç†ç”Ÿæˆæ€»ç»“æŠ¥å‘Šçš„é€»è¾‘
            if generate_summary_clicked:
                if not api_key:
                    st.error("è¯·å…ˆè¾“å…¥DeepSeek APIå¯†é’¥")
                else:
                    # ç¡®å®šè¦æ€»ç»“çš„æ–‡æ¡£
                    if summary_mode == "ğŸ“š æ‰€æœ‰æ–‡æ¡£":
                        files_to_summarize = None  # None è¡¨ç¤ºæ‰€æœ‰æ–‡æ¡£
                        summary_title = f"æ‰€æœ‰æ–‡æ¡£æ€»ç»“ï¼ˆå…± {len(st.session_state.docs)} ä¸ªæ–‡æ¡£ï¼‰"
                    else:
                        files_to_summarize = selected_files_for_summary
                        summary_title = f"é€‰å®šæ–‡æ¡£æ€»ç»“ï¼ˆå…± {len(selected_files_for_summary)} ä¸ªæ–‡æ¡£ï¼‰"
                    
                    # è·å–é€‰ä¸­çš„æ¨¡ç‰ˆåç§°ç”¨äºæ˜¾ç¤º
                    selected_template_data = get_template("summary", st.session_state.selected_summary_template)
                    template_name = selected_template_data.get('name', 'é»˜è®¤æ¨¡ç‰ˆ') if selected_template_data else 'é»˜è®¤æ¨¡ç‰ˆ'
                    summary_title += f" - {template_name}"
                    
                    with st.spinner(f"æ­£åœ¨ç”Ÿæˆæ€»ç»“æŠ¥å‘Šï¼ˆ{summary_title}ï¼‰..."):
                        summary = generate_summary_deepseek(
                            st.session_state.docs, 
                            api_key,
                            specific_files=files_to_summarize,
                            template_id=st.session_state.selected_summary_template
                        )
                        # ç”Ÿæˆæ—¶é—´æˆ³ï¼ˆåœ¨ç”Ÿæˆæ€»ç»“æ—¶ç”Ÿæˆï¼Œç¡®ä¿åŒä¸€æ€»ç»“ä½¿ç”¨ç›¸åŒæ—¶é—´æˆ³ï¼‰
                        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                        # ä¿å­˜åˆ° session state
                        st.session_state.summary = summary
                        st.session_state.summary_title = summary_title
                        st.session_state.summary_timestamp = timestamp  # ä¿å­˜æ—¶é—´æˆ³
                        # ä¿å­˜æ–‡æ¡£åˆ—è¡¨ä¿¡æ¯ç”¨äºåç»­æ˜¾ç¤º
                        if files_to_summarize:
                            st.session_state.summary_files = files_to_summarize
                            st.session_state.summary_doc_count = len(files_to_summarize)
                        else:
                            st.session_state.summary_files = None
                            st.session_state.summary_doc_count = len(st.session_state.docs)
            
            # æ˜¾ç¤ºæ€»ç»“æŠ¥å‘Šï¼ˆç§»åˆ°æŒ‰é’®ifå—å¤–ï¼Œç¡®ä¿å§‹ç»ˆæ˜¾ç¤ºåœ¨col1ï¼‰
            if 'summary' in st.session_state and st.session_state.summary:
                st.markdown("---")
                summary_title_display = st.session_state.get('summary_title', 'æ€»ç»“æŠ¥å‘Š')
                with st.expander(f"ğŸ“Š æŸ¥çœ‹æ€»ç»“æŠ¥å‘Š - {summary_title_display}", expanded=True):
                    # æ˜¾ç¤ºæ€»ç»“çš„æ–‡æ¡£ä¿¡æ¯
                    summary_files = st.session_state.get('summary_files', None)
                    summary_doc_count = st.session_state.get('summary_doc_count', 0)
                    if summary_files:
                        st.markdown(f"**æ€»ç»“çš„æ–‡æ¡£ï¼š** {', '.join(summary_files)}")
                    else:
                        st.markdown(f"**æ€»ç»“çš„æ–‡æ¡£ï¼š** æ‰€æœ‰æ–‡æ¡£ï¼ˆå…± {summary_doc_count} ä¸ªï¼‰")
                    st.markdown("---")
                    st.write(st.session_state.summary)
                
                # ä¿å­˜æŠ¥å‘Šé€‰é¡¹
                st.markdown("#### ğŸ’¾ ä¿å­˜æŠ¥å‘Š")
                col_save1, col_save2, col_save3 = st.columns(3)
                
                # ä½¿ç”¨ç”Ÿæˆæ€»ç»“æ—¶ä¿å­˜çš„æ—¶é—´æˆ³ï¼Œå¦‚æœæ²¡æœ‰åˆ™ç”Ÿæˆæ–°çš„ï¼ˆå…¼å®¹æ—§ä»£ç ï¼‰
                timestamp = st.session_state.get('summary_timestamp', datetime.now().strftime("%Y%m%d_%H%M%S"))
                
                # ç¡®å®šæ–‡æ¡£åˆ—è¡¨ç”¨äºä¿å­˜
                summary_files = st.session_state.get('summary_files', None)
                summary_doc_count = st.session_state.get('summary_doc_count', 0)
                if summary_files:
                    doc_list = summary_files
                    doc_count = len(summary_files)
                else:
                    doc_list = list(st.session_state.docs.keys())
                    doc_count = summary_doc_count
                
                # ç”Ÿæˆ Markdown æ ¼å¼å†…å®¹
                md_summary = f"# {summary_title_display}\n\nç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\næ–‡æ¡£æ•°é‡: {doc_count}\n\n---\n\n{st.session_state.summary}"
                
                with col_save1:
                    st.download_button(
                        label="ğŸ“„ ä¿å­˜ä¸ºTXT",
                        data=st.session_state.summary,
                        file_name=f"çŸ¥è¯†åº“æ€»ç»“_{timestamp}.txt",
                        mime="text/plain",
                        use_container_width=True
                    )
                
                with col_save2:
                    st.download_button(
                        label="ğŸ“ ä¿å­˜ä¸ºMarkdown",
                        data=md_summary,
                        file_name=f"çŸ¥è¯†åº“æ€»ç»“_{timestamp}.md",
                        mime="text/markdown",
                        use_container_width=True
                    )
                
                with col_save3:
                    # JSONæ ¼å¼ï¼ˆåŒ…å«å…ƒæ•°æ®ï¼‰
                    json_data = {
                        "æ€»ç»“æ ‡é¢˜": summary_title_display,
                        "ç”Ÿæˆæ—¶é—´": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                        "æ–‡æ¡£æ•°é‡": doc_count,
                        "æ–‡æ¡£åˆ—è¡¨": doc_list,
                        "æ€»ç»“å†…å®¹": st.session_state.summary
                    }
                    st.download_button(
                        label="ğŸ“Š ä¿å­˜ä¸ºJSON",
                        data=json.dumps(json_data, ensure_ascii=False, indent=2),
                        file_name=f"çŸ¥è¯†åº“æ€»ç»“_{timestamp}.json",
                        mime="application/json",
                        use_container_width=True
                    )
                
                # è‡ªåŠ¨ä¿å­˜åˆ°æœ¬åœ°ï¼ˆå¯é€‰ï¼‰
                save_dir = os.path.join(".", "saved_reports")
                os.makedirs(save_dir, exist_ok=True)
                
                if st.checkbox("ğŸ’¾ åŒæ—¶è‡ªåŠ¨ä¿å­˜åˆ°æœ¬åœ°", value=False, key="auto_save_summary"):
                    try:
                        # ä¿å­˜TXTç‰ˆæœ¬ï¼ˆå¦‚æœæ–‡ä»¶å·²å­˜åœ¨åˆ™è¦†ç›–ï¼‰
                        txt_path = os.path.join(save_dir, f"çŸ¥è¯†åº“æ€»ç»“_{timestamp}.txt")
                        with open(txt_path, 'w', encoding='utf-8') as f:
                            f.write(st.session_state.summary)
                        
                        # ä¿å­˜Markdownç‰ˆæœ¬ï¼ˆå¦‚æœæ–‡ä»¶å·²å­˜åœ¨åˆ™è¦†ç›–ï¼‰
                        md_path = os.path.join(save_dir, f"çŸ¥è¯†åº“æ€»ç»“_{timestamp}.md")
                        with open(md_path, 'w', encoding='utf-8') as f:
                            f.write(md_summary)
                        
                        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨ï¼ˆç”¨äºæç¤ºç”¨æˆ·ï¼‰
                        file_existed = os.path.exists(txt_path) or os.path.exists(md_path)
                        if file_existed:
                            st.success(f"âœ… æŠ¥å‘Šå·²æ›´æ–°åˆ°: {save_dir}ï¼ˆå·²è¦†ç›–åŒåæ–‡ä»¶ï¼‰")
                        else:
                            st.success(f"âœ… æŠ¥å‘Šå·²ä¿å­˜åˆ°: {save_dir}")
                        st.info(f"ğŸ“ æ–‡ä»¶è·¯å¾„:\n- {txt_path}\n- {md_path}")
                    except Exception as e:
                        st.error(f"ä¿å­˜å¤±è´¥: {str(e)}")
    
    with col2:
        st.header("ğŸ¤– æ™ºèƒ½é—®ç­”")
        
        # èŠå¤©å†å²
        if st.session_state.chat_history:
            with st.expander("ğŸ—£ï¸ å¯¹è¯å†å²", expanded=False):
                # ä¿å­˜å¯¹è¯å†å²æŒ‰é’®
                col_history1, col_history2 = st.columns([3, 1])
                with col_history2:
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    
                    # ç”Ÿæˆå¯¹è¯å†å²æ–‡æœ¬
                    history_text = f"# å¯¹è¯å†å²è®°å½•\n\nç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\næ–‡æ¡£æ•°é‡: {len(st.session_state.docs)}\n\n---\n\n"
                    for i, (q, a) in enumerate(st.session_state.chat_history, 1):
                        history_text += f"## å¯¹è¯ {i}\n\n**é—®é¢˜:** {q}\n\n**å›ç­”:**\n{a}\n\n---\n\n"
                    
                    st.download_button(
                        label="ğŸ’¾ ä¿å­˜å¯¹è¯",
                        data=history_text,
                        file_name=f"å¯¹è¯å†å²_{timestamp}.md",
                        mime="text/markdown",
                        use_container_width=True
                    )
                
                # æ˜¾ç¤ºæœ€è¿‘5æ¡å¯¹è¯
                for i, (q, a) in enumerate(st.session_state.chat_history[-5:], start=len(st.session_state.chat_history)-4):  # æ˜¾ç¤ºæœ€è¿‘5æ¡
                    st.markdown(f"**Q{i}:** {q}")
                    st.markdown(f"**A{i}:** {a}")
                    st.markdown("---")
        
        # é—®é¢˜è¾“å…¥
        question = st.text_area(
            "è¾“å…¥æ‚¨çš„é—®é¢˜",
            placeholder="ä¾‹å¦‚ï¼šæ€»ç»“ä¸€ä¸‹æ–‡æ¡£çš„ä¸»è¦å†…å®¹æ˜¯ä»€ä¹ˆï¼Ÿæˆ–è€…ï¼šä»è¿™äº›æ–‡æ¡£ä¸­æ‰¾å‡ºå…³äºXXçš„ä¿¡æ¯ã€‚",
            height=100,
            key="question_input"
        )
        
        col_a, col_b, col_c = st.columns([1, 1, 2])
        
        with col_a:
            search_clicked = st.button("ğŸ” æœç´¢ç­”æ¡ˆ", type="primary", use_container_width=True)
        
        with col_b:
            if st.button("ğŸ§¹ æ¸…ç©ºå¯¹è¯", use_container_width=True):
                # æ¸…ç©ºå‰è¯¢é—®æ˜¯å¦ä¿å­˜
                if st.session_state.chat_history:
                    st.warning("âš ï¸ æ¸…ç©ºå¯¹è¯å‰å»ºè®®å…ˆä¿å­˜å¯¹è¯å†å²ï¼")
                st.session_state.chat_history = []
                st.rerun()
        
        with col_c:
            if st.button("ğŸ’¡ ç¤ºä¾‹é—®é¢˜", use_container_width=True):
                examples = [
                    "æ€»ç»“æ‰€æœ‰æ–‡æ¡£çš„æ ¸å¿ƒè¦ç‚¹",
                    "æå–æ–‡æ¡£ä¸­çš„å…³é”®æ•°æ®",
                    "åˆ—å‡ºæ‰€æœ‰æåˆ°çš„é‡è¦æ—¥æœŸ",
                    "å„æ–‡æ¡£ä¹‹é—´çš„å…³è”æ˜¯ä»€ä¹ˆï¼Ÿ"
                ]
                st.session_state.question_input = st.session_state.get("question_input", "") + examples[0]
        
        # å¤„ç†æœç´¢ç­”æ¡ˆçš„é€»è¾‘ï¼ˆç§»åˆ°åˆ—å¸ƒå±€å¤–ï¼Œä½¿å†…å®¹å æ®å…¨å®½ï¼‰
        if search_clicked:
            # æ¸…é™¤é«˜çº§åŠŸèƒ½æ˜¾ç¤ºçŠ¶æ€
            st.session_state.show_data_analysis = False
            st.session_state.show_flowchart_gen = False
            st.session_state.show_gantt_gen = False
            
            if not question:
                st.warning("è¯·è¾“å…¥é—®é¢˜")
            elif not api_key:
                st.error("è¯·è¾“å…¥DeepSeek APIå¯†é’¥")
            elif not st.session_state.docs:
                st.error("è¯·å…ˆåŠ è½½æ–‡æ¡£")
            else:
                # æ˜¾ç¤ºè¶…æ—¶æç¤ºï¼ˆå…¨å®½ï¼‰
                timeout_info = st.session_state.get('api_timeout', 60)
                retry_info = st.session_state.get('api_max_retries', 3)
                st.info(f"â±ï¸ è¶…æ—¶è®¾ç½®: {timeout_info}ç§’ | é‡è¯•æ¬¡æ•°: {retry_info}æ¬¡ | å¦‚é‡è¶…æ—¶å¯åœ¨ä¾§è¾¹æ è°ƒæ•´")
                
                with st.spinner(f"æ­£åœ¨æ€è€ƒ...ï¼ˆè¶…æ—¶æ—¶é—´: {timeout_info}ç§’ï¼‰"):
                    answer = answer_with_deepseek(
                        question, 
                        st.session_state.vectorstore, 
                        st.session_state.docs, 
                        api_key
                    )
                    
                    # ä¿å­˜åˆ°å†å²
                    st.session_state.chat_history.append((question, answer))
                    
                    # æ˜¾ç¤ºç­”æ¡ˆï¼ˆå…¨å®½ï¼‰
                    st.markdown("### ğŸ’¡ ç­”æ¡ˆ")
                    st.write(answer)
                    
                    # ä¿å­˜å•ä¸ªé—®ç­”
                    col_save_qa1, col_save_qa2 = st.columns(2)
                    timestamp_qa = datetime.now().strftime("%Y%m%d_%H%M%S")
                    
                    # ç”Ÿæˆé—®ç­”å†…å®¹
                    qa_text = f"# é—®ç­”è®°å½•\n\nç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n## é—®é¢˜\n\n{question}\n\n## å›ç­”\n\n{answer}\n"
                    
                    with col_save_qa1:
                        st.download_button(
                            label="ğŸ’¾ ä¿å­˜æ­¤é—®ç­”",
                            data=qa_text,
                            file_name=f"é—®ç­”_{timestamp_qa}.md",
                            mime="text/markdown",
                            use_container_width=True
                        )
                    
                    with col_save_qa2:
                        # è‡ªåŠ¨ä¿å­˜é€‰é¡¹
                        if st.checkbox("è‡ªåŠ¨ä¿å­˜", key=f"auto_save_{timestamp_qa}", value=False):
                            save_dir_qa = os.path.join(".", "saved_qa")
                            os.makedirs(save_dir_qa, exist_ok=True)
                            try:
                                qa_path = os.path.join(save_dir_qa, f"é—®ç­”_{timestamp_qa}.md")
                                with open(qa_path, 'w', encoding='utf-8') as f:
                                    f.write(qa_text)
                                st.success(f"âœ… å·²ä¿å­˜åˆ°: {save_dir_qa}")
                            except Exception as e:
                                st.error(f"ä¿å­˜å¤±è´¥: {str(e)}")
                    
                    # å¦‚æœç­”æ¡ˆåŒ…å«é”™è¯¯ä¿¡æ¯ï¼Œæä¾›è§£å†³å»ºè®®ï¼ˆä¸è‡ªåŠ¨å±•å¼€ï¼‰
                    if "è¶…æ—¶" in answer or "è¿æ¥" in answer or "ç½‘ç»œ" in answer:
                        with st.expander("ğŸ’¡ ç½‘ç»œé—®é¢˜è§£å†³å»ºè®®", expanded=False):
                            st.markdown("""
                            **å¦‚æœé‡åˆ°è¶…æ—¶æˆ–è¿æ¥é—®é¢˜ï¼Œå¯ä»¥å°è¯•ï¼š**
                            1. ğŸ“ˆ **å¢åŠ è¶…æ—¶æ—¶é—´**ï¼šåœ¨ä¾§è¾¹æ "é«˜çº§è®¾ç½®"ä¸­å¢åŠ è¶…æ—¶æ—¶é—´ï¼ˆå»ºè®®120-180ç§’ï¼‰
                            2. ğŸ”„ **å¢åŠ é‡è¯•æ¬¡æ•°**ï¼šåœ¨ä¾§è¾¹æ "é«˜çº§è®¾ç½®"ä¸­å¢åŠ é‡è¯•æ¬¡æ•°ï¼ˆå»ºè®®4-5æ¬¡ï¼‰
                            3. ğŸŒ **æ£€æŸ¥ç½‘ç»œ**ï¼šç¡®ä¿ç½‘ç»œè¿æ¥ç¨³å®šï¼Œå¯ä»¥è®¿é—® api.deepseek.com
                            4. ğŸ“ **å‡å°‘æ–‡æ¡£å†…å®¹**ï¼šå¦‚æœæ–‡æ¡£å¾ˆå¤§ï¼Œå°è¯•å‡å°‘åŠ è½½çš„æ–‡æ¡£æ•°é‡
                            5. â° **ç¨åé‡è¯•**ï¼šå¯èƒ½æ˜¯DeepSeekæœåŠ¡å™¨ç¹å¿™ï¼Œç¨åå†è¯•
                            """)
                    
                    # æ˜¾ç¤ºæ£€ç´¢æ¥æº
                    if st.session_state.vectorstore:
                        with st.expander("æŸ¥çœ‹å‚è€ƒæ¥æº"):
                            similar_docs = search_similar_documents(
                                st.session_state.vectorstore, 
                                question
                            )
                            for i, (content, source) in enumerate(similar_docs[:3], 1):
                                st.markdown(f"**æ¥æº {i} - {source}**")
                                st.caption(content[:300] + "...")
        
        # é«˜çº§åŠŸèƒ½ï¼ˆåœ¨col2å†…ï¼Œç¡®ä¿å¸ƒå±€æ­£ç¡®ï¼‰
        st.markdown("---")
        st.subheader("ğŸ¯ é«˜çº§åŠŸèƒ½")
        
        # æ•°æ®åˆ†ææŒ‰é’®ï¼ˆè¯­ä¹‰æœç´¢åŠŸèƒ½å·²ç§»é™¤ï¼Œå› ä¸ºä¸"æŸ¥çœ‹å‚è€ƒæ¥æº"åŠŸèƒ½é‡å¤ï¼‰
        data_analysis_clicked = st.button("ğŸ“Š æ•°æ®åˆ†æ", use_container_width=True, key="data_analysis_btn")
        
        # åˆå§‹åŒ–session_state
        if 'show_data_analysis' not in st.session_state:
            st.session_state.show_data_analysis = False
        
        if data_analysis_clicked:
            # å…ˆå…³é—­å…¶ä»–åŠŸèƒ½
            st.session_state.show_flowchart_gen = False
            st.session_state.show_gantt_gen = False
            st.session_state.show_data_analysis = True
            st.rerun()  # ç«‹å³åˆ·æ–°é¡µé¢ä»¥ç¡®ä¿çŠ¶æ€ç”Ÿæ•ˆ
        
        # å¤„ç†æ•°æ®åˆ†æï¼ˆåœ¨col2å†…ï¼Œä½¿ç”¨å®¹å™¨ç»„ç»‡ç»“æœï¼‰
        if st.session_state.show_data_analysis:
            if not st.session_state.docs:
                st.warning("è¯·å…ˆåŠ è½½æ–‡æ¡£")
            elif not api_key:
                st.error("è¯·è¾“å…¥DeepSeek APIå¯†é’¥")
            else:
                # åœ¨å¼¹çª—ä¸­æ˜¾ç¤ºæ¨¡ç‰ˆé€‰æ‹©å’Œç®¡ç†
                with st.expander("ğŸ“ æ•°æ®åˆ†æé…ç½®", expanded=True):
                    # åˆå§‹åŒ–session state
                    if 'selected_analysis_template' not in st.session_state:
                        st.session_state.selected_analysis_template = "default"
                    
                    # åŠ è½½æ¨¡ç‰ˆåˆ—è¡¨
                    analysis_templates = load_templates("analysis")
                    analysis_template_options = {f"{t['name']} ({tid})": tid for tid, t in analysis_templates.items()}
                    
                    col_analysis_template1, col_analysis_template1_btn, col_analysis_template2, col_analysis_template3 = st.columns([3, 1, 1, 1])
                    with col_analysis_template1:
                        selected_analysis_template_display = st.selectbox(
                            "é€‰æ‹©Promptæ¨¡ç‰ˆ",
                            options=list(analysis_template_options.keys()),
                            index=list(analysis_template_options.values()).index(st.session_state.selected_analysis_template) if st.session_state.selected_analysis_template in analysis_template_options.values() else 0,
                            help="é€‰æ‹©ç”¨äºæ•°æ®åˆ†æçš„Promptæ¨¡ç‰ˆ",
                            key="analysis_template_select"
                        )
                        st.session_state.selected_analysis_template = analysis_template_options[selected_analysis_template_display]
                    
                    with col_analysis_template1_btn:
                        # åˆ·æ–°æŒ‰é’®
                        st.markdown("<div style='height: 27px;'></div>", unsafe_allow_html=True)
                        if st.button("ğŸ”„ åˆ·æ–°", use_container_width=True, key="refresh_analysis_template_btn", help="åˆ·æ–°æ¨¡æ¿åˆ—è¡¨ä»¥è·å–æœ€æ–°æ¨¡æ¿"):
                            # é‡æ–°åŠ è½½æ¨¡æ¿
                            analysis_templates = load_templates("analysis")
                            analysis_template_options = {f"{t['name']} ({tid})": tid for tid, t in analysis_templates.items()}
                            # å¦‚æœå½“å‰é€‰ä¸­çš„æ¨¡æ¿ä¸å­˜åœ¨ï¼Œé‡ç½®ä¸ºdefault
                            if st.session_state.selected_analysis_template not in analysis_template_options.values():
                                st.session_state.selected_analysis_template = "default"
                            st.rerun()
                    
                    with col_analysis_template2:
                        # æ·»åŠ å ä½ç¬¦ä»¥å¯¹é½selectboxçš„labelå’Œhelp icon
                        st.markdown("<div style='height: 27px;'></div>", unsafe_allow_html=True)
                        if st.button("ğŸ‘ï¸ é¢„è§ˆ", use_container_width=True, key="preview_analysis_template"):
                            st.session_state.show_analysis_template_preview = True
                    
                    with col_analysis_template3:
                        # æ·»åŠ å ä½ç¬¦ä»¥å¯¹é½selectboxçš„labelå’Œhelp icon
                        st.markdown("<div style='height: 27px;'></div>", unsafe_allow_html=True)
                        # æ£€æŸ¥é€‰ä¸­çš„æ¨¡ç‰ˆæ˜¯å¦å¯ä»¥åˆ é™¤ï¼ˆé»˜è®¤æ¨¡ç‰ˆä¸å¯åˆ é™¤ï¼‰
                        can_delete_analysis = not is_default_template("analysis", st.session_state.selected_analysis_template)
                        if st.button("ğŸ—‘ï¸ åˆ é™¤", use_container_width=True, key="delete_analysis_template_btn", disabled=not can_delete_analysis):
                            if delete_template("analysis", st.session_state.selected_analysis_template):
                                st.success("âœ… æ¨¡ç‰ˆå·²åˆ é™¤")
                                st.session_state.selected_analysis_template = "default"
                                st.rerun()
                    
                    # æ¨¡ç‰ˆé¢„è§ˆ
                    if st.session_state.get('show_analysis_template_preview', False):
                        template_data = get_template("analysis", st.session_state.selected_analysis_template)
                        if template_data:
                            st.markdown("**æ¨¡ç‰ˆé¢„è§ˆ**")
                            st.markdown(f"**æ¨¡ç‰ˆåç§°**: {template_data.get('name', '')}")
                            st.markdown(f"**æ¨¡ç‰ˆæè¿°**: {template_data.get('description', '')}")
                            st.markdown("**æ¨¡ç‰ˆå†…å®¹**:")
                            st.code(template_data.get('template', ''), language='text')
                            if st.button("å…³é—­é¢„è§ˆ", key="close_preview_analysis"):
                                st.session_state.show_analysis_template_preview = False
                    
                    # æ¨¡ç‰ˆç®¡ç†ï¼ˆä»…ä¿ç•™åˆ›å»º/ç¼–è¾‘åŠŸèƒ½ï¼‰
                    with st.expander("âš™ï¸ æ¨¡ç‰ˆç®¡ç†", expanded=False):
                        st.markdown("**åˆ›å»º/ç¼–è¾‘æ¨¡ç‰ˆ**")
                        new_analysis_template_name = st.text_input("æ¨¡ç‰ˆåç§°", key="new_analysis_template_name")
                        new_analysis_template_desc = st.text_input("æ¨¡ç‰ˆæè¿°", key="new_analysis_template_desc")
                        new_analysis_template_content = st.text_area(
                            "æ¨¡ç‰ˆå†…å®¹ï¼ˆä½¿ç”¨ {doc_info} ä½œä¸ºæ–‡æ¡£ä¿¡æ¯å ä½ç¬¦ï¼‰",
                            height=200,
                            key="new_analysis_template_content",
                            help="ç¤ºä¾‹ï¼šè¯·åˆ†æä»¥ä¸‹æ–‡æ¡£é›†åˆï¼š\n\næ–‡æ¡£ä¿¡æ¯ï¼š\n{doc_info}\n\nåˆ†æï¼š"
                        )
                        if st.button("ğŸ’¾ ä¿å­˜æ¨¡ç‰ˆ", key="save_analysis_template"):
                            if new_analysis_template_name and new_analysis_template_content:
                                if save_template("analysis", "", new_analysis_template_name, new_analysis_template_desc, new_analysis_template_content):
                                    st.success("âœ… æ¨¡ç‰ˆå·²ä¿å­˜")
                                    st.rerun()
                            else:
                                st.warning("è¯·è¾“å…¥æ¨¡ç‰ˆåç§°å’Œå†…å®¹")
                    
                    # æ‰§è¡Œåˆ†ææŒ‰é’®
                    run_analysis_clicked = st.button("ğŸš€ æ‰§è¡Œæ•°æ®åˆ†æ", type="primary", use_container_width=True, key="run_analysis_btn")
                    
                    if run_analysis_clicked:
                        with st.spinner("æ­£åœ¨åˆ†ææ–‡æ¡£..."):
                            # åŠ è½½é€‰ä¸­çš„æ¨¡ç‰ˆ
                            template_data = get_template("analysis", st.session_state.selected_analysis_template)
                            
                            # å‡†å¤‡æ–‡æ¡£ä¿¡æ¯
                            doc_info = chr(10).join([f'{name}: {len(str(data["content"]))} å­—ç¬¦' for name, data in st.session_state.docs.items()])
                            
                            if template_data:
                                template_str = template_data.get("template", "")
                                # æ›¿æ¢æ¨¡ç‰ˆä¸­çš„å ä½ç¬¦
                                prompt = template_str.format(doc_info=doc_info)
                            else:
                                # å¦‚æœæ¨¡ç‰ˆä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤æ¨¡ç‰ˆ
                                prompt = f"""è¯·åˆ†æä»¥ä¸‹æ–‡æ¡£é›†åˆï¼Œæä¾›æ•°æ®åˆ†æ:

æ–‡æ¡£ä¿¡æ¯ï¼š
{doc_info}

è¯·æä¾›ï¼š
1. æ–‡æ¡£å†…å®¹åˆ†å¸ƒåˆ†æ
2. æ½œåœ¨çš„æ•°æ®æ¨¡å¼å’Œè¶‹åŠ¿
3. å»ºè®®çš„æ•°æ®å¯è§†åŒ–æ–¹å¼"""
                            
                            analysis = query_deepseek(prompt, api_key)
                            st.session_state.analysis_result = analysis
                            st.session_state.analysis_template_name = template_data.get('name', 'é»˜è®¤æ¨¡ç‰ˆ') if template_data else 'é»˜è®¤æ¨¡ç‰ˆ'
                
                # æ˜¾ç¤ºåˆ†æç»“æœ
                if 'analysis_result' in st.session_state and st.session_state.analysis_result:
                    st.markdown("---")
                    st.markdown(f"### ğŸ“Š æ•°æ®åˆ†æç»“æœï¼ˆä½¿ç”¨æ¨¡ç‰ˆï¼š{st.session_state.analysis_template_name}ï¼‰")
                    st.write(st.session_state.analysis_result)
        
        # æµç¨‹å›¾ç”ŸæˆåŠŸèƒ½
        flowchart_gen_clicked = st.button("ğŸ“ åˆ¶ä½œæµç¨‹å›¾æ–‡ä»¶", use_container_width=True, key="flowchart_gen_btn")
        
        # åˆå§‹åŒ–session_state
        if 'show_flowchart_gen' not in st.session_state:
            st.session_state.show_flowchart_gen = False
        
        if flowchart_gen_clicked:
            # å…ˆå…³é—­å…¶ä»–åŠŸèƒ½
            st.session_state.show_data_analysis = False
            st.session_state.show_gantt_gen = False
            st.session_state.show_flowchart_gen = True
            st.rerun()  # ç«‹å³åˆ·æ–°é¡µé¢ä»¥ç¡®ä¿çŠ¶æ€ç”Ÿæ•ˆ
        
        # å¤„ç†æµç¨‹å›¾ç”Ÿæˆï¼ˆåœ¨col2å†…ï¼‰
        if st.session_state.show_flowchart_gen:
            with st.expander("ğŸ“ åˆ¶ä½œæµç¨‹å›¾æ–‡ä»¶", expanded=True):
                st.markdown("""
                **ä½¿ç”¨è¯´æ˜ï¼š**
                1. ä»å·¦ä¾§"æ‰¹é‡æ€»ç»“"åŒºåŸŸçš„æ€»ç»“æŠ¥å‘Šä¸­å¤åˆ¶æµç¨‹å›¾éƒ¨åˆ†çš„æ–‡æœ¬
                2. å°†æ–‡æœ¬ç²˜è´´åˆ°ä¸‹æ–¹çš„æ–‡æœ¬æ¡†ä¸­
                3. ç‚¹å‡»"ç”Ÿæˆæµç¨‹å›¾"æŒ‰é’®
                4. ç³»ç»Ÿä¼šè‡ªåŠ¨ç”Ÿæˆå¹¶ä¸‹è½½ draw.io æ ¼å¼çš„æµç¨‹å›¾æ–‡ä»¶
                
                **æµç¨‹å›¾æ ¼å¼è¦æ±‚ï¼š**
                - ä¸»è¦é˜¶æ®µä½¿ç”¨æ–¹æ‹¬å· `[]` åŒ…è£¹ï¼Œé€šè¿‡å‘ä¸‹ç®­å¤´ `â†“` è¿æ¥
                - å­ä»»åŠ¡é€šè¿‡å‘å³ç®­å¤´ `â†’` è¿æ¥
                - æ”¯æŒç¼©è¿›è¡¨ç¤ºå±‚çº§å…³ç³»
                """)
                
                # æ–‡æœ¬è¾“å…¥åŒºåŸŸ
                flowchart_text = st.text_area(
                    "æµç¨‹å›¾æ–‡æœ¬",
                    height=300,
                    placeholder="è¯·ç²˜è´´æµç¨‹å›¾æ–‡æœ¬ï¼Œä¾‹å¦‚ï¼š\n\n[é˜¶æ®µä¸€]\nâ†“\n[é˜¶æ®µäºŒ]\nâ†’ å­ä»»åŠ¡1 â†’ å­ä»»åŠ¡2\nâ†“\n[é˜¶æ®µä¸‰]",
                    help="ä»æ‰¹é‡æ€»ç»“æ–‡æœ¬ä¸­å¤åˆ¶æµç¨‹å›¾éƒ¨åˆ†ï¼Œç²˜è´´åˆ°è¿™é‡Œ",
                    key="flowchart_text_input"
                )
                
                # ç”ŸæˆæŒ‰é’®
                generate_flowchart_clicked = st.button(
                    "ğŸš€ ç”Ÿæˆæµç¨‹å›¾", 
                    type="primary", 
                    use_container_width=True,
                    key="generate_flowchart_btn"
                )
                
                if generate_flowchart_clicked:
                    if not flowchart_text or not flowchart_text.strip():
                        st.warning("è¯·è¾“å…¥æµç¨‹å›¾æ–‡æœ¬")
                    else:
                        try:
                            # å¯¼å…¥æµç¨‹å›¾è½¬æ¢å‡½æ•°
                            from flowchart_to_drawio import convert_flowchart_to_drawio
                            
                            with st.spinner("æ­£åœ¨ç”Ÿæˆæµç¨‹å›¾..."):
                                # è½¬æ¢ä¸º draw.io XML
                                xml_content = convert_flowchart_to_drawio(flowchart_text, None)
                                
                                # ç”Ÿæˆæ–‡ä»¶å
                                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                                file_name = f"flowchart_{timestamp}.drawio"
                                
                                # æä¾›ä¸‹è½½æŒ‰é’®
                                st.success("âœ… æµç¨‹å›¾ç”ŸæˆæˆåŠŸï¼")
                                st.download_button(
                                    label="ğŸ“¥ ä¸‹è½½æµç¨‹å›¾æ–‡ä»¶",
                                    data=xml_content,
                                    file_name=file_name,
                                    mime="application/xml",
                                    use_container_width=True,
                                    key=f"download_flowchart_{timestamp}"
                                )
                                
                                # æ˜¾ç¤ºé¢„è§ˆæç¤º
                                st.info("ğŸ’¡ æç¤ºï¼šä¸‹è½½åå¯ä»¥ä½¿ç”¨ [draw.io](https://app.diagrams.net/) æˆ– [diagrams.net](https://www.diagrams.net/) æ‰“å¼€æ–‡ä»¶è¿›è¡Œç¼–è¾‘")
                                
                        except ImportError:
                            st.error("æ— æ³•å¯¼å…¥æµç¨‹å›¾è½¬æ¢æ¨¡å—ï¼Œè¯·ç¡®ä¿ flowchart_to_drawio.py æ–‡ä»¶å­˜åœ¨")
                        except Exception as e:
                            st.error(f"ç”Ÿæˆæµç¨‹å›¾æ—¶å‡ºé”™ï¼š{str(e)}")
                            import traceback
                            with st.expander("é”™è¯¯è¯¦æƒ…", expanded=False):
                                st.code(traceback.format_exc(), language='python')
        
        # ç”˜ç‰¹å›¾ç”ŸæˆåŠŸèƒ½
        gantt_gen_clicked = st.button("ğŸ“… åˆ¶ä½œç”˜ç‰¹å›¾æ–‡ä»¶", use_container_width=True, key="gantt_gen_btn")
        
        # åˆå§‹åŒ–session_state
        if 'show_gantt_gen' not in st.session_state:
            st.session_state.show_gantt_gen = False
        
        if gantt_gen_clicked:
            # å…ˆå…³é—­å…¶ä»–åŠŸèƒ½
            st.session_state.show_data_analysis = False
            st.session_state.show_flowchart_gen = False
            st.session_state.show_gantt_gen = True
            st.rerun()  # ç«‹å³åˆ·æ–°é¡µé¢ä»¥ç¡®ä¿çŠ¶æ€ç”Ÿæ•ˆ
        
        # å¤„ç†ç”˜ç‰¹å›¾ç”Ÿæˆï¼ˆåœ¨col2å†…ï¼‰
        if st.session_state.show_gantt_gen:
            with st.expander("ğŸ“… åˆ¶ä½œç”˜ç‰¹å›¾æ–‡ä»¶", expanded=True):
                st.markdown("""
                **ä½¿ç”¨è¯´æ˜ï¼š**
                1. å‡†å¤‡é¡¹ç›®è¿›åº¦ç”˜ç‰¹å›¾è¡¨æ•°æ®ï¼ˆè¡¨æ ¼æ ¼å¼ï¼‰
                2. å°†è¡¨æ ¼æ•°æ®ç²˜è´´åˆ°ä¸‹æ–¹çš„æ–‡æœ¬æ¡†ä¸­
                3. ç‚¹å‡»"ç”Ÿæˆç”˜ç‰¹å›¾"æŒ‰é’®
                4. ç³»ç»Ÿä¼šè‡ªåŠ¨ç”Ÿæˆå¹¶ä¸‹è½½ draw.io æ ¼å¼çš„ç”˜ç‰¹å›¾æ–‡ä»¶
                
                **ç”˜ç‰¹å›¾æ•°æ®æ ¼å¼è¦æ±‚ï¼š**
                - è¡¨æ ¼æ ¼å¼ï¼Œä½¿ç”¨åˆ¶è¡¨ç¬¦ï¼ˆTabï¼‰åˆ†éš”å„åˆ—
                - å¿…é¡»åŒ…å«è¡¨å¤´è¡Œï¼šä»»åŠ¡IDã€ä»»åŠ¡åç§°ã€å¼€å§‹æ—¶é—´ã€ç»“æŸæ—¶é—´ã€å·¥æœŸ(æœˆ)ã€å‰ç½®ä»»åŠ¡ã€è´£ä»»æ–¹/å¤‡æ³¨
                - æ—¶é—´æ ¼å¼ï¼šM0, M1, M1+0.5, M1.5 ç­‰
                - ä»»åŠ¡IDæ”¯æŒå±‚çº§ç»“æ„ï¼š1, 1.1, 1.2, 2.1 ç­‰
                
                **æç¤ºï¼š** å¯ä»¥ä½¿ç”¨AIç”Ÿæˆç”˜ç‰¹å›¾æ•°æ®ï¼Œåœ¨"æ‰¹é‡æ€»ç»“"åŠŸèƒ½ä¸­é€‰æ‹©"é¡¹ç›®è¿›åº¦ç”˜ç‰¹å›¾æ¨¡ç‰ˆ"ï¼Œç³»ç»Ÿä¼šæ ¹æ®æ–‡æ¡£å†…å®¹è‡ªåŠ¨ç”Ÿæˆç¬¦åˆæ ¼å¼è¦æ±‚çš„ç”˜ç‰¹å›¾è¡¨æ•°æ®
                """)
                
                # æ–‡æœ¬è¾“å…¥åŒºåŸŸ
                gantt_text = st.text_area(
                    "ç”˜ç‰¹å›¾è¡¨æ•°æ®",
                    height=400,
                    placeholder="ä»»åŠ¡ID	ä»»åŠ¡åç§°	å¼€å§‹æ—¶é—´	ç»“æŸæ—¶é—´	å·¥æœŸ(æœˆ)	å‰ç½®ä»»åŠ¡	è´£ä»»æ–¹/å¤‡æ³¨\n1	é¡¹ç›®å¯åŠ¨	M0	M1	2		\n1.1	é¡¹ç›®ç«‹é¡¹	M0	M0+0.5	0.5		ç”²æ–¹ã€ä¹™æ–¹\n1.2	éœ€æ±‚è°ƒç ”	M0+0.5	M1	0.5	1.1	ä¹™æ–¹",
                    help="ç²˜è´´ç”˜ç‰¹å›¾è¡¨æ•°æ®ï¼ˆè¡¨æ ¼æ ¼å¼ï¼‰ï¼Œæ”¯æŒåˆ¶è¡¨ç¬¦æˆ–ç©ºæ ¼åˆ†éš”",
                    key="gantt_text_input"
                )
                
                # ç”ŸæˆæŒ‰é’®
                generate_gantt_clicked = st.button(
                    "ğŸš€ ç”Ÿæˆç”˜ç‰¹å›¾", 
                    type="primary", 
                    use_container_width=True,
                    key="generate_gantt_btn"
                )
                
                if generate_gantt_clicked:
                    if not gantt_text or not gantt_text.strip():
                        st.warning("è¯·è¾“å…¥ç”˜ç‰¹å›¾è¡¨æ•°æ®")
                    else:
                        try:
                            # å¯¼å…¥ç”˜ç‰¹å›¾è½¬æ¢å‡½æ•°
                            from gantt_to_drawio import convert_gantt_to_drawio
                            
                            # è½¬æ¢ä¸º draw.io XML
                            with st.spinner("æ­£åœ¨ç”Ÿæˆç”˜ç‰¹å›¾..."):
                                xml_content = convert_gantt_to_drawio(gantt_text, None)
                            
                            # spinnerç»“æŸåå†æ˜¾ç¤ºæˆåŠŸä¿¡æ¯å’Œä¸‹è½½æŒ‰é’®
                            # ç”Ÿæˆæ–‡ä»¶å
                            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                            file_name = f"gantt_{timestamp}.drawio"
                            
                            # æä¾›ä¸‹è½½æŒ‰é’®
                            st.success("âœ… ç”˜ç‰¹å›¾ç”ŸæˆæˆåŠŸï¼")
                            st.download_button(
                                label="ğŸ“¥ ä¸‹è½½ç”˜ç‰¹å›¾æ–‡ä»¶",
                                data=xml_content,
                                file_name=file_name,
                                mime="application/xml",
                                use_container_width=True,
                                key=f"download_gantt_{timestamp}"
                            )
                            
                            # æ˜¾ç¤ºé¢„è§ˆæç¤º
                            st.info("ğŸ’¡ æç¤ºï¼šä¸‹è½½åå¯ä»¥ä½¿ç”¨ [draw.io](https://app.diagrams.net/) æˆ– [diagrams.net](https://www.diagrams.net/) æ‰“å¼€æ–‡ä»¶è¿›è¡Œç¼–è¾‘")
                                
                        except ImportError:
                            st.error("æ— æ³•å¯¼å…¥ç”˜ç‰¹å›¾è½¬æ¢æ¨¡å—ï¼Œè¯·ç¡®ä¿ gantt_to_drawio.py æ–‡ä»¶å­˜åœ¨")
                        except Exception as e:
                            st.error(f"ç”Ÿæˆç”˜ç‰¹å›¾æ—¶å‡ºé”™ï¼š{str(e)}")
                            import traceback
                            with st.expander("é”™è¯¯è¯¦æƒ…", expanded=False):
                                st.code(traceback.format_exc(), language='python')
        
        # æ˜¾ç¤ºç‰ˆæƒä¿¡æ¯
        show_footer()

# ç®€æ˜“ç‰ˆï¼ˆæ— å‘é‡æ•°æ®åº“ï¼‰
def simple_main():
    """ç®€æ˜“ç‰ˆæœ¬ï¼Œä¸ä½¿ç”¨å‘é‡æ•°æ®åº“"""
    st.set_page_config(
        page_title="ç®€æ˜“çŸ¥è¯†åº“æµè§ˆå™¨",
        page_icon="ğŸ“",
        layout="wide"
    )
    
    st.title("ğŸ“ ç®€æ˜“çŸ¥è¯†åº“æµè§ˆå™¨")
    
    # æ–‡ä»¶ä¸Šä¼ 
    uploaded_files = st.file_uploader(
        "ä¸Šä¼ æ–‡ä»¶ (æ”¯æŒtxt, docx, pdf, excel, md, js, json)",
        type=['txt', 'docx', 'pdf', 'xlsx', 'xls', 'md', 'js', 'json'],
        accept_multiple_files=True
    )
    
    if uploaded_files:
        docs = {}
        temp_dir = tempfile.mkdtemp()
        for uploaded_file in uploaded_files:
            # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶åˆ°ä¸´æ—¶ç›®å½•
            file_path = os.path.join(temp_dir, uploaded_file.name)
            with open(file_path, "wb") as f:
                f.write(uploaded_file.getbuffer())
            
            # è¯»å–æ–‡ä»¶
            filename = uploaded_file.name
            file_ext = filename.split('.')[-1].lower()
            
            try:
                if file_ext == 'txt':
                    content = read_text_file(file_path)
                elif file_ext == 'docx':
                    content = read_docx_file(file_path)
                elif file_ext == 'pdf':
                    content = read_pdf_file(file_path)
                elif file_ext in ['xlsx', 'xls']:
                    content = read_excel_file(file_path)
                elif file_ext == 'md':
                    content = read_markdown_file(file_path)
                elif file_ext == 'js':
                    content = read_javascript_file(file_path)
                elif file_ext == 'json':
                    content = read_json_file(file_path)
                else:
                    content = f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹"
                
                docs[filename] = {
                    'content': content,
                    'type': file_ext,
                    'path': file_path
                }
            except Exception as e:
                st.error(f"è¯»å–æ–‡ä»¶ {filename} å¤±è´¥: {str(e)}")
        
        # æ–‡ä»¶æµè§ˆå™¨
        if docs:
            selected_file = st.selectbox("é€‰æ‹©æ–‡ä»¶", list(docs.keys()))
            
            if selected_file in docs:
                content = docs[selected_file]['content']
                st.text_area("æ–‡ä»¶å†…å®¹", 
                           str(content) if not isinstance(content, dict) else str(content),
                           height=400)
        
        # ç®€å•é—®ç­”
        st.markdown("---")
        
        # å°è¯•åŠ è½½ä¿å­˜çš„ API key
        saved_api_key = load_api_key()
        default_key = saved_api_key if saved_api_key else ""
        
        col_simple_key1, col_simple_key2 = st.columns([3, 1])
        with col_simple_key1:
            api_key = st.text_input("DeepSeek APIå¯†é’¥", value=default_key, type="password")
        with col_simple_key2:
            if st.button("ğŸ’¾ ä¿å­˜", use_container_width=True):
                if api_key:
                    if save_api_key(api_key):
                        st.success("âœ… å·²ä¿å­˜")
                else:
                    st.warning("è¯·è¾“å…¥å¯†é’¥")
        
        question = st.text_input("è¾“å…¥é—®é¢˜")
        
        if st.button("è·å–ç­”æ¡ˆ") and api_key and question:
            # åˆå¹¶æ‰€æœ‰æ–‡æ¡£å†…å®¹
            all_content = ""
            for filename, data in docs.items():
                content = data['content']
                if isinstance(content, dict):
                    content = "\n".join([f"{k}: {v}" for k, v in content.items()])
                all_content += f"\n\næ–‡ä»¶: {filename}\n{content}"
            
            # è°ƒç”¨DeepSeek
            prompt = f"""åŸºäºä»¥ä¸‹æ–‡æ¡£å†…å®¹å›ç­”é—®é¢˜ï¼š

{all_content[:8000]}

é—®é¢˜ï¼š{question}

è¯·åŸºäºæ–‡æ¡£å†…å®¹å›ç­”ï¼Œå¦‚æœæ–‡æ¡£ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·æ˜ç¡®è¯´æ˜ã€‚"""
            
            with st.spinner("æ­£åœ¨æ€è€ƒ..."):
                answer = query_deepseek(prompt, api_key)
                st.write("**ç­”æ¡ˆï¼š**", answer)
        
        # æ˜¾ç¤ºç‰ˆæƒä¿¡æ¯
        show_footer()

if __name__ == "__main__":
    # é»˜è®¤ä½¿ç”¨å®Œæ•´ç‰ˆï¼Œå¯ä»¥é€šè¿‡ç¯å¢ƒå˜é‡æˆ–å‘½ä»¤è¡Œå‚æ•°åˆ‡æ¢
    import sys
    if len(sys.argv) > 1 and sys.argv[1] == "simple":
        simple_main()
    else:
        main()